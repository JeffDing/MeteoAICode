{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D89B0EAB542642F98900CCC4D4E49360",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# 机器学习如何助力气候变化预估：一个海温订正与预测案例\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "810CF482643D4985AFA558B9F60AF78D",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "624ef709c47d0200184a3cb9",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "工业革命以来，人类活动不断增加，全球气候不断增暖，1911-2011 年全球平均海表温度上升了 0.8℃左右，这对海洋生态系统和气候带来了较大威胁。因此，准确、合理地预估**未来百年全球平均海表温度**，不仅有利于我们理解未来气候变化，也有助于气候变化应对政策的制定。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4FC61B519BE24DD590C9913A15FBDA95",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**气候变化的模拟与预测预估**是当前海洋、大气领域世界性研究热点之一，备受公众和各国政府的关注。**海表温度**是海洋和大气相互作用的产物，既能反映整个气候系统的变化特征，也会影响大气活动和气候系统，因此我们可以利用海温模拟与预测未来气候。**传统的气候模式**作为研究气候变化的主要手段之一，尽管经历了半个世纪的发展但**仍有偏差**，这增加了我们预估未来海表温度的不确定性。因此，减少海温模拟偏差，进而提高模式预测预估结果的准确性具有重要的意义。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16BEDEF83DF24B65ABB0E52615CECDCB",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "近年来，随着人工智能的发展，**机器学习算法**越来越受到重视，已被广泛应用于地球系统科学的多个研究领域。气候模式的偏差不是线性那么简单，具有非线性的特征，而基于机器学习的订正模型可以帮助我们捕捉数值模式模拟结果与观测之间偏差的非线性变化，得到更精准的模式订正结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "808CC5E6A46D405F928E9D6128C6ED19",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dce7cd3915ed2e06c32896",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "本期，我们将基于和鲸 ModelWhale 平台，手把手教大家动手开展**气候模式预估全球平均海表面温度订正**，并对模式结果进行后处理。我们将采用**数据分解和机器学习结合**的方法来订正气候模式模拟和预估的全球平均海表温度偏差。我们将从以下几部分学习：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56EBAB1C345E4892B2FA646BCEE4C78F",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dce7cd3915ed2e06c32896",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "[1] 首先我们带领大家先来了解一下我们的研究背景，先从**气候模式**这一研究海洋与气候变化的重要工具出发，这里有两个主要要学习的问题：\n",
    "\n",
    "&emsp;&emsp; 1）什么是气候模式？我们能用气候模式做些什么？\n",
    "&emsp;&emsp; 2）气候模式现在有什么不足？\n",
    "\n",
    "同时，提出我们的研究对象——海表面温度数据的模式模拟预估情况，针对气候模式模拟海表面温度存在的不足，我们采用什么方法去弥补？从而介绍近年来表现出有巨大潜力的机器学习，用机器学习模型来订正模式偏差。这里的值得注意的地方就是**为什么用机器学习来订正气候模式的海温偏差。**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5A791546864D4274947367A2CDB8D736",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dce7cd3915ed2e06c32896",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "[2] 在大家了解了气候模式之后，我们选择自然资源部第一海洋研究所自主发展的[FIO-ESM v2.0模式](https://www.hanspub.org/journal/PaperInformation.aspx?paperID=34034) 模拟和预估的全球海表面温度数据作为研究对象，来带大家学习一些**数据预处理**的操作，主要包括：\n",
    "\n",
    "&emsp;&emsp; 1）数据格式是怎么样的？我们怎么读取这些数据？\n",
    "&emsp;&emsp; 2）对读进来的数据分辨率不统一的情况，我们怎么去做数据统一？也就是怎么去做**空间插值**？\n",
    "&emsp;&emsp; 3）对插值后的数据，我们最终要得到全球平均海表温度，那么我们怎么计算呢？这里就要到**区域平均**计算方法了。\n",
    "\n",
    "&emsp;&emsp; 4）上述计算完成后，我们怎么将计算结果可视化？也就是如何**绘图**？绘图完之后如何分析？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96B1E7014F2C40258C6B2B6F5CD24C66",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dce7cd3915ed2e06c32896",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "[3] 对数据做一个基本的预处理之后，然后我们基于模式偏差本身非线性非平稳增长的特征，直接订正未必效果好，这里先使用一个数据分解的方法——[**EEMD**](https://blog.csdn.net/liu_xiao_cheng/article/details/83897034)，目的就是为了对原始时间序列分解成不同频率的分量，再按照时间尺度组合时间序列，最后对每个组合时间序列订正。这里大家需要注意的地方有：\n",
    "\n",
    "&emsp;&emsp; 1）**EEMD方法的工作原理**是什么？它是怎么把一串时间序列分解成多串不同频率的时间序列的？\n",
    "&emsp;&emsp; 2）对分解完的时间序列，我们根据什么时间尺度来对它们进行**组合以满足物理约束**呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34BBF4303FCC4852868F43211EF0954C",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dce7cd3915ed2e06c32896",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "[4] 在得到组合后的EEMD分解时间序列，我们就可以对它们建立模型来订正了，这里我们选择了一个神经网络模型——[**BPNN**](https://blog.csdn.net/cufewxy1/article/details/80445023?ops_request_misc=&request_id=&biz_id=102&utm_term=BPNN%E6%A8%A1%E5%9E%8B&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-1-80445023.nonecase&spm=1018.2226.3001.4187)，这里大家要学习的地方有：\n",
    "\n",
    "&emsp;&emsp; 1）我们选择BPNN模型来订正海表温度的原因是什么？\n",
    "&emsp;&emsp; 2）我们的BPNN订正模型需要的数据要做哪些处理？模式历史偏差订正和未来预估的关系是什么？\n",
    "&emsp;&emsp; 3）我们如何评价订正结果？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A2DF2EEE31B24E1B8EF35CA11C2CDD08",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dce7cd3915ed2e06c32896",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "[5] 上述涵盖了我们这次教学的内容，在大家学习完这些内容后，我们还给大家留了两个作业来练习。作业分基础题目和拓展题目：\n",
    "\n",
    "&emsp;&emsp; 1） 本项目用到的BPNN模型哪些**参数**会明显影响订正效果？\n",
    "&emsp;&emsp; 2） 能否继续采用EEMD-BPNN模型**对其他模式数据做订正**呢？\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "250ECCACFBD048488A18FEAA91762DE5",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dce7cd3915ed2e06c32896",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "到这里，我们本次的项目前言就全部交代清楚了，希望通过这次的学习，可以带领大家进入学习气候模式和机器学习的大门并有所收获。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "810CF482643D4985AFA558B9F60AF78D",
    "mdEditEnable": false,
    "notebookId": "624ef709c47d0200184a3cb9",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# 背景介绍\n",
    "在学习我们的项目之前，我们需要先了解一下我们的研究背景，包括以下几个部分：\n",
    "&emsp;&emsp;  1）什么是气候模式？我们能用气候模式做些什么？\n",
    "&emsp;&emsp;  2）气候模式现在有什么不足？\n",
    "\n",
    "随后我们根据气候模式对海温模拟的偏差情况提出机器学习订正的方法，包括为什么用神经网络来订正气候模式的海温偏差。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EF16A19BE0BF42329525931FB044F29F",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dcea1c3915ed2e06c33f00",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "\n",
    "## 1.1 什么是气候模式？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E497676ED9E9453586F39276BF73AA4C",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dcea1c3915ed2e06c33f00",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "\n",
    "气候模式，简单理解就是一组大的计算机程序，它基于描述我们生存的地球气候系统（下图1）现象及其变化规律的数学物理方程组，采用数值积分的方式在计算机上实现求解。地球系统模式则是在气候模式的基础上，增加了复杂的生物地球化学循环过程。严格意义上的气候模式与地球系统模式存在上述区别，但是这里，我们均称两者为“气候模式”。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9A41E99E8E3E44568F11558A42FF88FA",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dcea1c3915ed2e06c33f00",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/rfmdqe1aq5.png?imageView2/0/w/960/h/960)\n",
    "&emsp;&emsp;  &emsp;&emsp; &emsp;&emsp; &emsp;&emsp;  &emsp;&emsp; &emsp;&emsp; 图1. 地球气候系统是一个复杂的系统，包括大气圈、水圈、冰冻圈、岩石圈和生物圈\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A3CA112E45774A5D8CA953CBB02E3136",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dcea1c3915ed2e06c33f00",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "气候模式是气候系统研究三大手段之一[^1]，是研究海洋和气候变化科学的重要工具，有助于增强人们对地球各个圈层及其相互作用的科学理解和认知，提高人们对地球系统和气候变化的理解和预测水平，特别是在如今气候变暖的大背景下，建立、发展和使用气候模式的作用极为重要，影响极为深远。\n",
    "\n",
    "\n",
    "[^1]:气候系统研究的三大研究手段是观测、理论和数值模式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "571E1E3FCA0848958430CA69DF7599E9",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dcea1c3915ed2e06c33f00",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/rfmem2nyh5.jpg?imageView2/0/w/960/h/960)\n",
    "&emsp;&emsp;  &emsp;&emsp; &emsp;&emsp; &emsp;&emsp;  &emsp;&emsp; &emsp;&emsp;  &emsp;&emsp;  &emsp;&emsp; &emsp;&emsp; &emsp;&emsp; &emsp;&emsp; &emsp;&emsp; &emsp;&emsp;图2. 观测、理论和数模三者之间的关系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACE2D08A2B694D53949AB4DB29E90541",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dcea1c3915ed2e06c33f00",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 1.2 气候模式的发展现状及不足"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7E2AF6E0B8D242538FD128231385D214",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dcea1c3915ed2e06c33f00",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "\n",
    "气候模式最早可追溯到1969年，Manabe和Bryan建立起了世界上第一个海气耦合模式，五十年来，气候模式已经取得了极大的发展和进步，从海气耦合环流模式到气候模式再到包含生物地球化学过程的地球系统模式。模式的分辨率已经越来越高、包含的过程已经越来越复杂，模拟准确率也在逐步提高，成为气候变化科学研究的核心工具。\n",
    "\n",
    "然而，由于模式的分辨率不是无限精细的，不能完美刻画气候系统中各种过程的发生，加上人们对气候系统的很多过程都尚未认识清楚等原因，现在气候模式仍然存在模拟和预测偏差。拿海表面温度来说，就存在如东太平洋年平均存在暖偏差，中太平洋存在冷偏差等问题。这些海表面温度偏差会影响未来的精准预测，因此对模式结果开展偏差订正就格外有必要。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0877042249B745E981DFB19F1094C147",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dcea1c3915ed2e06c33f00",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "\n",
    "海表温度（Sea Surface Temperature, SST）是海洋和大气相互作用的产物，既能反映整个气候系统的变化特征，也会影响大气活动和气候系统，因此我们可以利用海温模拟与预测未来气候。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1BE68F0E1A63416F8143A30C616D5D46",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dcea1c3915ed2e06c33f00",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 1.3 为何选择机器学习订正气候模式偏差？\n",
    "\n",
    "确定完了研究对象，我们接下来就要确定方法了。传统上，人们很多是拿到模式数据直接用于分析，或者**基于模式数据—>选择传统上的机器学习方法如决策树、支持向量机来订正模式结果。**\n",
    "近年来，以**神经网络**为代表的机器学习特别是深度学习在近些年来已经被广泛地应用到气象、海洋领域，并展露出了强大能力和潜力，如识别海洋涡旋、降水预测等。气候模式模拟的海温偏差时间序列本身并不是线性变化那么简单，而是具有非线性的特征。神经网络作为有强大的非线性表达能力的模型，能够挖掘模式与观测之间偏差的规律特征，实现偏差订正的目的。这里我们考虑模式海温偏差的非线性特征，建立一个三层的神经网络，来完成我们的项目。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E90B561CA5814F8CB319EA25A2CF9042",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dcea1c3915ed2e06c33f00",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 小结\n",
    "本章我们交代了项目的背景，包含气候模式的概念、气候模式存在的不足，同时确定了我们研究对象海温，和订正气候模式模拟海温选择的方法。\n",
    "\n",
    "接下来，让我们开启本次项目的第一步，先从海温数据预处理开始。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D89B0EAB542642F98900CCC4D4E49360",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# SST数据预处理\n",
    "对我们的研究对象和方法有了大致的了解之后，我们就可以开始我们的项目了，首先就是对**SST数据预处理**了。\n",
    "\n",
    "如前言所述，我们在这一章需要注意：\n",
    "\n",
    "   1）数据格式是怎么样的？我们怎么读取这些数据？\n",
    "   2）对读进来的数据分辨率不统一的情况，我们怎么去做数据统一？也就是怎么去做空间插值？\n",
    "   3）对插值后的数据，我们最终要得到全球平均SST，那么我们怎么计算来得到最终的全球平均值？这里就要用到海表面温度的区域平均计算方法了。\n",
    "   4）上述计算完成后，我们怎么将计算结果可视化？也就是如何绘图？对绘图结果我们怎么分析？\n",
    "\t \n",
    "注：\n",
    "&emsp;&emsp;   1）数据处理这里我们计算资源选择2核8G CPU资源即可，使用镜像为【octave 测试镜像-song-v1】，Kernel类型为Python3。\n",
    "&emsp;&emsp;   2）教案中涉及跑循环的部分时，可能会弹出“内存使用已超过80%”之类的注意字样，不影响实操，大家可忽略。\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F0880A0064EF47229730395A2EC2C476",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 2.1 数据简介\n",
    "\n",
    "对SST数据预处理之前，我们需要先对数据有一个大致的了解。\n",
    "本章节我们选用的数据是自然资源部第一海洋研究所自主发展的第二代气候模式FIO-ESM v2.0模拟和预估的全球SST以及观测值，模式和观测的数据格式都是**nc格式**。\n",
    "\n",
    "选用的数据为：\n",
    "\n",
    "1） 观测数据：选用的是第5代扩展重构SST数据[ERSST v5](https://climatedataguide.ucar.edu/climate-data/sst-data-noaa-extended-reconstruction-ssts-version-5-ersstv5) ，空间覆盖全球海洋，分辨率为2°×2°，时间范围从1854年1月到2019年12月，时间间隔是1个月，共166年的数据。          \n",
    "\n",
    "2） [模式数据](https://esgf-node.llnl.gov/search/cmip6/)：包含**历史时期模拟数据和未来情景预估数据**。FIO-ESM v2.0历史时期数据，空间覆盖全球海洋，高纬度地区1.1°，赤道地区加密为0.3°—0.5°，时间范围从1850年1月到2014年12月，时间间隔是1个月，共165年的数据; **3种未来不同温室气体排放程度预估**[^1]的数据，空间覆盖全球海洋，分辨率和历史数据相同，时间范围从2015年1月到2100年12月，时间间隔是1个月，共86年的数据。\n",
    "\n",
    "\n",
    "\n",
    "[^1]: 为了展现不同政策选择带来的气候影响和社会经济风险，科学家们提出了不同的预估情景，简单说是设置不同的温室气体排放试验（用'SSPa-b'表示，SSP代表Shared Socioeconomic Pathways，共享社会经济路径，a代表我们经济上走的不同未来发展路径，b代表2100年气候系统的辐射强迫值），看气候系统在未来会如何变化。我们这次用到的三种未来预估数据分别代表着低排放（SSP1-2.6）、中等排放（SSP2-4.5）和高排放情景（SSP5-8.5）。详情可见[CMIP6情景模式比较计划概述文章](http://www.climatechange.cn/CN/10.12006/j.issn.1673-1719.2019.082)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "810CF482643D4985AFA558B9F60AF78D",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "624ef709c47d0200184a3cb9",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 2.2 数据处理\n",
    "了解完要用到的数据之后，我们就可以开始对数据的处理过程了。\n",
    "\n",
    " 数据处理可分以下几个部分：\n",
    " &emsp;&emsp;  1）读取数据\n",
    " &emsp;&emsp;  2）数据空间插值\n",
    " &emsp;&emsp;  3）计算全球平均SST\n",
    " &emsp;&emsp;  4）绘图\n",
    " \n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4FC61B519BE24DD590C9913A15FBDA95",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 2.2.1 读取数据\n",
    "这里需要先导入工具包，这里我们要特别注意的是读取数据要用到的**netCDF4包以及其中的Dataset**功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "id": "16BEDEF83DF24B65ABB0E52615CECDCB",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "from netCDF4 import Dataset  # 读取nc文件用到的包\n",
    "from scipy.interpolate import griddata  # 对SST空间插值用到的函数\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as io\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "741E2442956E4834861034BE5CCABA03",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "导包结束后，我们就要开始读取观测数据和模式数据了。数据已经挂载到公开社区数据集**《CMIP6气候模式模拟和预估海表面温度》**中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F28E8F748E7D480FA6F4327298B7B0FB",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 2.2.1.1 读取观测数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93EA03A58722491184426772495CB0FD",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "查看文件信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "id": "D672A6DA22044421924584DCEFE45A4F",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4_CLASSIC data model, file format HDF5):\n",
      "    climatology: Climatology is based on 1971-2000 SST, Xue, Y., T. M. Smith, and R. W. Reynolds, 2003: Interdecadal changes of 30-yr SST normals during 1871.2000. Journal of Climate, 16, 1601-1612.\n",
      "    description: In situ data: ICOADS2.5 before 2007 and NCEP in situ data from 2008 to present. Ice data: HadISST ice before 2010 and NCEP ice after 2010.\n",
      "    keywords_vocabulary: NASA Global Change Master Directory (GCMD) Science Keywords\n",
      "    keywords: Earth Science > Oceans > Ocean Temperature > Sea Surface Temperature >\n",
      "    instrument: Conventional thermometers\n",
      "    source_comment: SSTs were observed by conventional thermometers in Buckets (insulated or un-insulated canvas and wooded buckets) or Engine Room Intaker\n",
      "    geospatial_lon_min: -1.0\n",
      "    geospatial_lon_max: 359.0\n",
      "    geospatial_laty_max: 89.0\n",
      "    geospatial_laty_min: -89.0\n",
      "    geospatial_lat_max: 89.0\n",
      "    geospatial_lat_min: -89.0\n",
      "    geospatial_lat_units: degrees_north\n",
      "    geospatial_lon_units: degrees_east\n",
      "    cdm_data_type: Grid\n",
      "    project: NOAA Extended Reconstructed Sea Surface Temperature (ERSST)\n",
      "    original_publisher_url: http://www.ncdc.noaa.gov\n",
      "    References: https://www.ncdc.noaa.gov/data-access/marineocean-data/extended-reconstructed-sea-surface-temperature-ersst-v5 at NCEI and http://www.esrl.noaa.gov/psd/data/gridded/data.noaa.ersst.v5.html\n",
      "    source: In situ data: ICOADS R3.0 before 2015, NCEP in situ GTS from 2016 to present, and Argo SST from 1999 to present. Ice data: HadISST2 ice before 2015, and NCEP ice after 2015\n",
      "    title: NOAA ERSSTv5 (in situ only)\n",
      "    history: created 07/2017 by PSD data using NCEI's ERSST V5 NetCDF values\n",
      "    institution: This version written at NOAA/ESRL PSD: obtained from NOAA/NESDIS/National Centers for Environmental Information and time aggregated. Original Full Source: NOAA/NESDIS/NCEI/CCOG\n",
      "    citation: Huang et al, 2017: Extended Reconstructed Sea Surface Temperatures Version 5 (ERSSTv5): Upgrades, Validations, and Intercomparisons. Journal of Climate, https://doi.org/10.1175/JCLI-D-16-0836.1\n",
      "    platform: Ship and Buoy SSTs from ICOADS R3.0 and NCEP GTS\n",
      "    standard_name_vocabulary: CF Standard Name Table (v40, 25 January 2017)\n",
      "    processing_level: NOAA Level 4\n",
      "    Conventions: CF-1.6, ACDD-1.3\n",
      "    metadata_link: :metadata_link = https://doi.org/10.7289/V5T72FNM (original format)\n",
      "    creator_name: Boyin Huang (original)\n",
      "    date_created: 2017-06-30T12:18:00Z (original)\n",
      "    product_version: Version 5\n",
      "    creator_url_original: https://www.ncei.noaa.gov\n",
      "    license: No constraints on data access or use\n",
      "    comment: SSTs were observed by conventional thermometers in Buckets (insulated or un-insulated canvas and wooded buckets), Engine Room Intakers, or floats and drifters\n",
      "    summary: ERSST.v5 is developed based on v4 after revisions of 8 parameters using updated data sets and advanced knowledge of ERSST analysis\n",
      "    dataset_title: NOAA Extended Reconstructed SST V5\n",
      "    data_modified: 2020-01-03\n",
      "    dimensions(sizes): lat(89), lon(180), time(1992), nbnds(2)\n",
      "    variables(dimensions): float32 lat(lat), float32 lon(lon), float64 time_bnds(time, nbnds), float64 time(time), float32 sst(time, lat, lon)\n",
      "    groups: \n"
     ]
    }
   ],
   "source": [
    "Path_Data = './dataset/CMIP6/'  # 读取数据路径\n",
    "NC_ERSST = Dataset(Path_Data + 'sst.mnmean.nc') # 读取数据\n",
    "print(NC_ERSST)  # 打印查看文件信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2399F524A66A40BAA08E990EBB59CDA3",
    "jupyter": {},
    "mdEditEnable": true,
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "上述打印输出的文件信息比较详细，我们不需要都看都了解，我们关心的主要包含：\n",
    "\n",
    "1）这套观测数据是怎么产生的，也就是**description**部分，我们可以知道数据是原位观测数据和海冰数据等组合产生；\n",
    "2）经纬度的范围，给出了最大最小值；\n",
    "3）数据的下载网址和版本信息，大家也可以参照网址去网站看到更详细的信息；\n",
    "4）这套数据的维度信息，一共有4个维度，我们只需关注纬度lat，经度lon和时间time。\n",
    "\n",
    "后面大家在打印模式数据文件信息时同样只需要关注上述4条信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "id": "22A2577D689140078B780DA166A9DC78",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['lat', 'lon', 'time_bnds', 'time', 'sst'])\n"
     ]
    }
   ],
   "source": [
    "print(NC_ERSST.variables.keys()) # 查看一下有哪些变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "id": "A971831CAAC543369D18E5B1DF1A61B1",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-9.96921e+36\n"
     ]
    }
   ],
   "source": [
    "print(NC_ERSST.variables['sst'].missing_value ) # 查看一下变量缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "id": "35959A49733847D6993CFF0938104EDC",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float64 time(time)\n",
      "    units: days since 1800-1-1 00:00:00\n",
      "    long_name: Time\n",
      "    delta_t: 0000-01-00 00:00:00\n",
      "    avg_period: 0000-01-00 00:00:00\n",
      "    prev_avg_period: 0000-00-07 00:00:00\n",
      "    standard_name: time\n",
      "    axis: T\n",
      "    actual_range: [19723. 80322.]\n",
      "unlimited dimensions: time\n",
      "current shape = (1992,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n"
     ]
    }
   ],
   "source": [
    "print(NC_ERSST.variables['time']) # 查看一下变量时间信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "id": "14691F95F83A47088DAE81891C942B4C",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89,) (180,) (1992, 89, 180) 1992\n"
     ]
    }
   ],
   "source": [
    "Lat_ERSST = NC_ERSST.variables['lat'][:].data  # 纬度，维度是1维的，范围是88 到 -88，即(89,)\n",
    "Lon_ERSST = NC_ERSST.variables['lon'][:].data  # 经度，,维度是1维的，范围是0 到 358,即(180,)\n",
    "# SST，维度是3维的，分别是(时间, 纬度, 经度)，即(1992, 89, 180)\n",
    "SST_ERSST = NC_ERSST.variables['sst'][:].data\n",
    "Time_ERSST0 = NC_ERSST.variables['time'][:]  # 时间，维度是1维的，即(1992,)\n",
    "Time_ERSST0 = nc.num2date(\n",
    "    Time_ERSST0,\n",
    "    'days since 1800-1-1 00:00:00').data  # 185401-201912,共1992个元素\n",
    "print(\n",
    "    Lat_ERSST.shape,\n",
    "    Lon_ERSST.shape,\n",
    "    SST_ERSST.shape,\n",
    "    len(Time_ERSST0))  # 打印各个变量的尺寸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "id": "603E200A025E40C88E10F73C9FD5A692",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1992\n",
      "[185401, 185402, 185403, 185404, 185405] [201908, 201909, 201910, 201911, 201912]\n"
     ]
    }
   ],
   "source": [
    "# 自己造一个日期列表\n",
    "Time_ERSST = [int(Time_ERSST0[i].year*100) + int(Time_ERSST0[i].month)\n",
    "              for i in range(Time_ERSST0.shape[0])]  # 185401-201912, 共1992个元素\n",
    "print(len(Time_ERSST))  # 查看Time_ERSST长度\n",
    "print(Time_ERSST[0:5], Time_ERSST[-5:])  # 打印时间列表头尾5个内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3BE5B852D9934FB882DF1221CF90439B",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 2.2.1.2 读取模式数据：历史数据\n",
    "读取操作都与观测数据相似"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6CF3CA02AF674BB9AC4BD4353876AE78",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "查看文件信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "id": "B2B1776E27D24E458519974FA4E323B8",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4_CLASSIC data model, file format HDF5):\n",
      "    Conventions: CF-1.7 CMIP-6.2\n",
      "    activity_id: CMIP\n",
      "    branch_method: standard\n",
      "    branch_time_in_child: 59400.0\n",
      "    branch_time_in_parent: 59400.0\n",
      "    contact: songroy@fio.org.cn\n",
      "    creation_date: 2019-11-22T07:16:56Z\n",
      "    data_specs_version: 01.00.31\n",
      "    experiment: all-forcing simulation of the recent past\n",
      "    experiment_id: historical\n",
      "    external_variables: areacello\n",
      "    forcing_index: 1\n",
      "    frequency: mon\n",
      "    further_info_url: https://furtherinfo.es-doc.org/CMIP6.FIO-QLNM.FIO-ESM-2-0.historical.none.r1i1p1f1\n",
      "    grid: native atmosphere regular grid (192x288 latxlon)\n",
      "    grid_label: gn\n",
      "    history: 2019-11-22T07:16:56Z ;rewrote data to be consistent with CMIP for variable tos found in table Omon.\n",
      "    initialization_index: 1\n",
      "    institution: FIO (First Institute of Oceanography, State Oceanic Administration, Qingdao 266061, China), QNLM (Qingdao National Laboratory for Marine Science and Technology, Qingdao 266237, China)\n",
      "    institution_id: FIO-QLNM\n",
      "    mip_era: CMIP6\n",
      "    nominal_resolution: 100 km\n",
      "    parent_activity_id: CMIP\n",
      "    parent_experiment_id: piControl\n",
      "    parent_mip_era: CMIP6\n",
      "    parent_source_id: FIO-ESM-2-0\n",
      "    parent_time_units: days since 1850-01-01 00:00:00\n",
      "    parent_variant_label: r1i1p1f1\n",
      "    physics_index: 1\n",
      "    product: model-output\n",
      "    realization_index: 1\n",
      "    realm: ocean\n",
      "    run_variant: 1rd realization\n",
      "    source: FIO-ESM 2.0 (2018): \n",
      "aerosol: Prescribed monthly fields\n",
      "atmos: CAM4 (0.9x1.25 finite volume grid; 192 x 288 longitude/latitude; 26 levels; top level ~2 hPa)\n",
      "atmosChem: none\n",
      "land: CLM4.0 (same grid at atmos)\n",
      "landIce: none\n",
      "ocean: POP2-W (POP2 coupled with MASNUM surface wave model, Displaced Pole; 320 x 384 longitude/latitude; 60 levels; top grid cell 0-10 m)\n",
      "ocnBgchem: none\n",
      "seaIce: CICE4.0 (same grid as ocean)\n",
      "    source_id: FIO-ESM-2-0\n",
      "    source_type: AOGCM\n",
      "    sub_experiment: none\n",
      "    sub_experiment_id: none\n",
      "    table_id: Omon\n",
      "    table_info: Creation Date:(24 July 2019) MD5:206ddb8ba334b371d2d0b8010adc7910\n",
      "    title: FIO-ESM-2-0 output prepared for CMIP6\n",
      "    tracking_id: hdl:21.14100/a0a30525-15fa-404b-9a5b-c4c35eb4223b\n",
      "    variable_id: tos\n",
      "    variant_label: r1i1p1f1\n",
      "    license: CMIP6 model data produced by Lawrence Livermore PCMDI is licensed under a Creative Commons Attribution ShareAlike 4.0 International License (https://creativecommons.org/licenses). Consult https://pcmdi.llnl.gov/CMIP6/TermsOfUse for terms of use governing CMIP6 output, including citation requirements and proper acknowledgment. Further information about this data, including some limitations, can be found via the further_info_url (recorded as a global attribute in this file) and at https:///pcmdi.llnl.gov/. The data producers and data providers make no warranty, either express or implied, including, but not limited to, warranties of merchantability and fitness for a particular purpose. All liabilities arising from the supply of the information (including any liability arising in negligence) are excluded to the fullest extent permitted by law.\n",
      "    cmor_version: 3.5.0\n",
      "    dimensions(sizes): time(1980), j(384), i(320), bnds(2), vertices(4)\n",
      "    variables(dimensions): float64 time(time), float64 time_bnds(time, bnds), int32 j(j), int32 i(i), float64 latitude(j, i), float64 longitude(j, i), float64 vertices_latitude(j, i, vertices), float64 vertices_longitude(j, i, vertices), float32 tos(time, j, i)\n",
      "    groups: \n"
     ]
    }
   ],
   "source": [
    "NC_Historical = Dataset(Path_Data + 'tos_Omon_FIO-ESM-2-0_historical_r1i1p1f1_gn_185001-201412.nc')\n",
    "print(NC_Historical) # 打印查看文件信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "id": "011D476430E84BD589638A54B2880E20",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['time', 'time_bnds', 'j', 'i', 'latitude', 'longitude', 'vertices_latitude', 'vertices_longitude', 'tos'])\n"
     ]
    }
   ],
   "source": [
    "print(NC_Historical.variables.keys())  # 查看一下有哪些变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "id": "1E8AE0AF72DE4D5F940C96646CFEBA31",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e+20\n"
     ]
    }
   ],
   "source": [
    "print(NC_Historical.variables['tos'].missing_value ) # 查看一下变量缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "id": "546755B3EB524DBC846ABA5773792592",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float64 time(time)\n",
      "    bounds: time_bnds\n",
      "    units: days since 0001-01-01\n",
      "    calendar: 365_day\n",
      "    axis: T\n",
      "    long_name: time\n",
      "    standard_name: time\n",
      "unlimited dimensions: time\n",
      "current shape = (1980,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n"
     ]
    }
   ],
   "source": [
    "print(NC_Historical.variables['time'])   # 查看一下变量时间信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "id": "1ED57DD14A7141F58851E3586F664629",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(384, 320) (384, 320) (1980, 384, 320) 1980\n"
     ]
    }
   ],
   "source": [
    "# 纬度，是2维的网格，按照(纬度,经度)排列数组大小是(384, 320)\n",
    "Lat_Historical = NC_Historical.variables['latitude'][:].data\n",
    "# 经度，是2维的网格，按照(纬度,经度)排列数组大小是(384, 320)\n",
    "Lon_Historical = NC_Historical.variables['longitude'][:].data\n",
    "# SST，3维，按照(时间, 纬度, 经度)排列数组大小是(1980, 384, 320)\n",
    "SST_Historical = NC_Historical.variables['tos'][:].data\n",
    "# 自己造一个日期列表,185001-201412,共1980个元素。\n",
    "Time_Historical = [int(i*100) + int(j) for i in range(1850, 2015)\n",
    "                   for j in range(1, 13)]  # 185001-201412,共1980个元素。\n",
    "print(\n",
    "    Lat_Historical.shape,\n",
    "    Lon_Historical.shape,\n",
    "    SST_Historical.shape,\n",
    "    len(Time_Historical))  # 打印各个变量的尺寸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91E1C9706E8642A98B3F60B4AA7D1992",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 2.2.1.3 读取模式数据：未来预估数据\n",
    "同样地，我们来读取3种未来情景预估数据，分别是SSP1-2.6、SSP2-4.5和SSP5-8.5。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "id": "BB90D7FEDA704172BAFB1E3FCC343478",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4_CLASSIC data model, file format HDF5):\n",
      "    Conventions: CF-1.7 CMIP-6.2\n",
      "    activity_id: ScenarioMIP\n",
      "    branch_method: standard\n",
      "    branch_time_in_child: 59400.0\n",
      "    branch_time_in_parent: 59400.0\n",
      "    contact: songroy@fio.org.cn\n",
      "    creation_date: 2019-12-27T13:38:05Z\n",
      "    data_specs_version: 01.00.31\n",
      "    experiment: update of RCP2.6 based on SSP1\n",
      "    experiment_id: ssp126\n",
      "    external_variables: areacello\n",
      "    forcing_index: 1\n",
      "    frequency: mon\n",
      "    further_info_url: https://furtherinfo.es-doc.org/CMIP6.FIO-QLNM.FIO-ESM-2-0.ssp126.none.r1i1p1f1\n",
      "    grid: native atmosphere regular grid (384x320 latxlon)\n",
      "    grid_label: gn\n",
      "    history: 2019-12-27T13:38:05Z ;rewrote data to be consistent with ScenarioMIP for variable tos found in table Omon.\n",
      "    initialization_index: 1\n",
      "    institution: FIO (First Institute of Oceanography, State Oceanic Administration, Qingdao 266061, China), QNLM (Qingdao National Laboratory for Marine Science and Technology, Qingdao 266237, China)\n",
      "    institution_id: FIO-QLNM\n",
      "    mip_era: CMIP6\n",
      "    nominal_resolution: 100 km\n",
      "    parent_activity_id: CMIP\n",
      "    parent_experiment_id: historical\n",
      "    parent_mip_era: CMIP6\n",
      "    parent_source_id: FIO-ESM-2-0\n",
      "    parent_time_units: days since 1850-01-01 00:00:00\n",
      "    parent_variant_label: r1i1p1f1\n",
      "    physics_index: 1\n",
      "    product: model-output\n",
      "    realization_index: 1\n",
      "    realm: ocean\n",
      "    run_variant: 1rd realization\n",
      "    source: FIO-ESM 2.0 (2018): \n",
      "aerosol: Prescribed monthly fields\n",
      "atmos: CAM4 (0.9x1.25 finite volume grid; 192 x 288 longitude/latitude; 26 levels; top level ~2 hPa)\n",
      "atmosChem: none\n",
      "land: CLM4.0 (same grid at atmos)\n",
      "landIce: none\n",
      "ocean: POP2-W (POP2 coupled with MASNUM surface wave model, Displaced Pole; 320 x 384 longitude/latitude; 60 levels; top grid cell 0-10 m)\n",
      "ocnBgchem: none\n",
      "seaIce: CICE4.0 (same grid as ocean)\n",
      "    source_id: FIO-ESM-2-0\n",
      "    source_type: AOGCM\n",
      "    sub_experiment: none\n",
      "    sub_experiment_id: none\n",
      "    table_id: Omon\n",
      "    table_info: Creation Date:(24 July 2019) MD5:206ddb8ba334b371d2d0b8010adc7910\n",
      "    title: FIO-ESM-2-0 output prepared for CMIP6\n",
      "    tracking_id: hdl:21.14100/715ef6f7-b761-41df-91a2-8b551351a0a3\n",
      "    variable_id: tos\n",
      "    variant_label: r1i1p1f1\n",
      "    license: CMIP6 model data produced by Lawrence Livermore PCMDI is licensed under a Creative Commons Attribution ShareAlike 4.0 International License (https://creativecommons.org/licenses). Consult https://pcmdi.llnl.gov/CMIP6/TermsOfUse for terms of use governing CMIP6 output, including citation requirements and proper acknowledgment. Further information about this data, including some limitations, can be found via the further_info_url (recorded as a global attribute in this file) and at https:///pcmdi.llnl.gov/. The data producers and data providers make no warranty, either express or implied, including, but not limited to, warranties of merchantability and fitness for a particular purpose. All liabilities arising from the supply of the information (including any liability arising in negligence) are excluded to the fullest extent permitted by law.\n",
      "    cmor_version: 3.5.0\n",
      "    dimensions(sizes): time(1032), j(384), i(320), bnds(2), vertices(4)\n",
      "    variables(dimensions): float64 time(time), float64 time_bnds(time, bnds), int32 j(j), int32 i(i), float64 latitude(j, i), float64 longitude(j, i), float64 vertices_latitude(j, i, vertices), float64 vertices_longitude(j, i, vertices), float32 tos(time, j, i)\n",
      "    groups: \n"
     ]
    }
   ],
   "source": [
    "## 未来预估低排放情景：SSP1-2.6\n",
    "NC_SSP126 = Dataset(Path_Data + 'tos_Omon_FIO-ESM-2-0_ssp126_r1i1p1f1_gn_201501-210012.nc')\n",
    "print(NC_SSP126) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "id": "98E2B5DAAC434C6C8C28BF2762658E74",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['time', 'time_bnds', 'j', 'i', 'latitude', 'longitude', 'vertices_latitude', 'vertices_longitude', 'tos'])\n"
     ]
    }
   ],
   "source": [
    "print(NC_SSP126.variables.keys()) # 查看一下有哪些变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "id": "C63478F8D2714D1A95F2212A0FED0BF7",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e+20\n"
     ]
    }
   ],
   "source": [
    "print(NC_SSP126.variables['tos'].missing_value )  # 查看一下变量缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "id": "3855D79F634B41ABA6E45BAE3D7DC8FD",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float64 time(time)\n",
      "    bounds: time_bnds\n",
      "    units: days since 0001-01-01\n",
      "    calendar: 365_day\n",
      "    axis: T\n",
      "    long_name: time\n",
      "    standard_name: time\n",
      "unlimited dimensions: time\n",
      "current shape = (1032,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n"
     ]
    }
   ],
   "source": [
    "print(NC_SSP126.variables['time'])   # 查看一下变量时间信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "id": "228D45E31F53422B97FFFBAF9759C5A6",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 纬度，同历史数据，是2维的网格，按照(纬度,经度)排列数组大小是(384, 320)\n",
    "Lat_SSP = NC_SSP126.variables['latitude'][:].data\n",
    "# 经度，同历史数据，是2维的网格，按照(纬度,经度)排列数组大小是(384, 320)\n",
    "Lon_SSP = NC_SSP126.variables['longitude'][:].data\n",
    "# SST，3维，按照(时间, 纬度, 经度)排列数组大小是(1032, 384, 320)\n",
    "SST_SSP126 = NC_SSP126.variables['tos'][:].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "id": "23211E9B0AF14C4182EAF21B3E734327",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(384, 320) (384, 320) (1032, 384, 320) 1032\n"
     ]
    }
   ],
   "source": [
    "# 自己造一个日期列表\n",
    "Time_SSP = [int(i*100) + int(j) for i in range(2015, 2101)\n",
    "            for j in range(1, 13)]  # 201501-210012,(1032,)\n",
    "print(Lat_SSP.shape, Lon_SSP.shape, SST_SSP126.shape, len(Time_SSP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "id": "EFDB8189D8FE4988A2C617653210FEC5",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 未来预估中等排放情景：SSP245，除了SST不同，其他都相同，我们只需读取SST即可\n",
    "NC_SSP245 = Dataset(\n",
    "    Path_Data +\n",
    "    'tos_Omon_FIO-ESM-2-0_ssp245_r1i1p1f1_gn_201501-210012.nc')\n",
    "SST_SSP245 = NC_SSP245.variables['tos'][:].data   # (1032, 384, 320)\n",
    "# 未来预估高排放情景：SSP585，除了SST不同，其他都相同，我们只需读取SST即可\n",
    "NC_SSP585 = Dataset(\n",
    "    Path_Data +\n",
    "    'tos_Omon_FIO-ESM-2-0_ssp585_r1i1p1f1_gn_201501-210012.nc')\n",
    "SST_SSP585 = NC_SSP585.variables['tos'][:].data   # (1032, 384, 320)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CFCBB6C9F98E4EA894AECC104025D799",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 2.2.2 数据空间插值\n",
    "从上面的数据读取操作，相信大家也都看到观测和模式数据的分辨是不同的。正是由于观测数据和模式数据的网格分辨率不相同，特别是模式数据还是不均匀的网格，所以不利于我们后面对其计算全球平均，所以我们为了统一，先将观测和模式数据进行空间插值到相同网格下，方便后面的计算。\n",
    "\n",
    "这里，我们使用griddata函数对数据进行插值，具体插值方法介绍可见[python的griddata插值](https://blog.csdn.net/weixin_44052055/article/details/118752091?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522165873149216782350830959%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=165873149216782350830959&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~baidu_landing_v2~default-2-118752091-null-null.142^v33^pc_rank_34,185^v2^control&utm_term=python%20griddata&spm=1018.2226.3001.4187)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "992EA44E34564946B265F91EBF67E442",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 2.2.2.1 观测数据插值\n",
    "先对插值前后的经纬度打个网格，主要用到了[meshgrid函数](https://lixiaoqian.blog.csdn.net/article/details/81532855?spm=1001.2101.3001.6661.1&utm_medium=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1-81532855-blog-84628976.pc_relevant_aa&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1-81532855-blog-84628976.pc_relevant_aa&utm_relevant_index=1)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "id": "543464402C6545B7B6EBE26ABBC39D9E",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180, 89) (180, 89)\n"
     ]
    }
   ],
   "source": [
    "# 设置经纬度最大最小值\n",
    "Min_Lat_ERSST = -88\n",
    "Max_Lat_ERSST = 88\n",
    "Min_Lon_ERSST = 0\n",
    "Max_Lon_ERSST = 359\n",
    "# 插值前后的经纬度间隔\n",
    "Step_LatLon_Before = 2\n",
    "Step_LatLon_After = 1\n",
    "# 给经纬度打网格\n",
    "# 用到了meshgrid，将1维的经纬度信息生成二维的网格点坐标矩阵，插值处理和画图常用到。\n",
    "Lat_ERSST_mgrid, Lon_ERSST_mgrid = np.meshgrid(Lat_ERSST, Lon_ERSST)\n",
    "print(Lat_ERSST_mgrid.shape, Lon_ERSST_mgrid.shape)\n",
    "# 经纬度的维度信息，按照（纬度，经度）的顺序排列\n",
    "Lat_ERSST_mgrid = Lat_ERSST_mgrid.T\n",
    "Lon_ERSST_mgrid = Lon_ERSST_mgrid.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "id": "C1059827D7F648168145BAF1020C5F9C",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 177) (360, 177)\n"
     ]
    }
   ],
   "source": [
    "# 插值前的经纬度, 维度是(180*89,2)\n",
    "LatLon_ERSST_Before = np.hstack(\n",
    "    (Lat_ERSST_mgrid.reshape(-1, 1), Lon_ERSST_mgrid.reshape(-1, 1)))  # 按水平方向进行叠加，形成两列，\n",
    "# 插值前的SST，维度是(180*89,1)\n",
    "SST_ERSST_Before = SST_ERSST.reshape((SST_ERSST.shape[0], -1, 1))\n",
    "# 插值前的经纬度和SST有了，我们还需要给出插值后的经纬度信息\n",
    "Lat_ERSST_After_1D = np.arange(\n",
    "    Max_Lat_ERSST, Min_Lat_ERSST-1, -Step_LatLon_After)  # 生成插值后的纬度\n",
    "Lon_ERSST_After_1D = np.arange(\n",
    "    Min_Lon_ERSST,\n",
    "    Max_Lon_ERSST+1,\n",
    "    Step_LatLon_After)  # 生成插值后的经度\n",
    "Lat_ERSST_After_2D, Lon_ERSST_After_2D = np.meshgrid(\n",
    "    Lat_ERSST_After_1D, Lon_ERSST_After_1D)  # 打网格\n",
    "print(Lat_ERSST_After_2D.shape, Lon_ERSST_After_2D.shape)\n",
    "Lat_ERSST_After_2D = Lat_ERSST_After_2D.T  # 转置一下，为了和变量维度匹配\n",
    "Lon_ERSST_After_2D = Lon_ERSST_After_2D.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "id": "21FE659D48684D9E86A1771561EAD5B1",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "84.58050012588501s\n"
     ]
    }
   ],
   "source": [
    "# 使用griddata函数对SST插值\n",
    "SST_ERSST_After = np.zeros([SST_ERSST.shape[0],\n",
    "                            Lat_ERSST_After_2D.shape[0],\n",
    "                            Lat_ERSST_After_2D.shape[1]])\n",
    "# 对每一个月的全球观测资料插值，并⏲计时\n",
    "start_time = time.time()\n",
    "for t in range(SST_ERSST.shape[0]):\n",
    "    # griddata函数插值，需要输入插值前的经纬度信息，插值前的变量，插值后的经纬度，插值方法，这里插值方法选择'nearest'方法。\n",
    "    SST_ERSST_After_Now = griddata(LatLon_ERSST_Before,\n",
    "                                   SST_ERSST_Before[t,\n",
    "                                                    :,\n",
    "                                                    :],\n",
    "                                   (Lat_ERSST_After_2D,\n",
    "                                    Lon_ERSST_After_2D),\n",
    "                                   method='nearest').squeeze()\n",
    "    SST_ERSST_After[t, :, :] = SST_ERSST_After_Now\n",
    "    if t % 100 == 0:  # 每100个数打印显示一下\n",
    "        print(t)\n",
    "end_time = time.time()\n",
    "print(str(end_time - start_time) + \"s\")  # 打印看一下循环计算的用时\n",
    "\n",
    "# 清空一下无关变量，后面不再用了\n",
    "del LatLon_ERSST_Before\n",
    "del SST_ERSST_Before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4427904F0378498A8952DA9672D7021D",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 2.2.2.2 模式的历史数据插值\n",
    "插值操作与上述观测数据一样。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "id": "B7E2F4BB8319436B87C07D1E8DB8E5E1",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 177) (360, 177)\n"
     ]
    }
   ],
   "source": [
    "## 设置经纬度最大最小值\n",
    "Min_Lat_Historical = -88\n",
    "Max_Lat_Historical = 88\n",
    "Min_Lon_Historical = 0\n",
    "## 插值前后的经纬度间隔\n",
    "Max_Lon_Historical = 359\n",
    "Step_LatLon_After = 1\n",
    "## 给经纬度打网格\n",
    "Lat_Historical_mgrid = Lat_Historical  \n",
    "Lon_Historical_mgrid = Lon_Historical\n",
    "## 插值前的经纬度, 维度是(384*320,2)\n",
    "LatLon_Historical_Before = np.hstack( ( Lat_Historical_mgrid.reshape(-1,1), Lon_Historical_mgrid.reshape(-1,1) ) ) \n",
    "SST_Historical_Before = SST_Historical.reshape( (SST_Historical.shape[0],-1,1) ) \n",
    "Lat_Historical_After_1D = np.arange(Max_Lat_Historical,Min_Lat_Historical-1,-Step_LatLon_After)\n",
    "Lon_Historical_After_1D = np.arange(Min_Lon_Historical,Max_Lon_Historical+1,Step_LatLon_After)\n",
    "Lat_Historical_After_2D, Lon_Historical_After_2D = np.meshgrid(Lat_Historical_After_1D, Lon_Historical_After_1D)\n",
    "print(Lat_Historical_After_2D.shape, Lon_Historical_After_2D.shape)\n",
    "Lat_Historical_After_2D = Lat_Historical_After_2D.T \n",
    "Lon_Historical_After_2D = Lon_Historical_After_2D.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "id": "35F2BD4C1E3A4FB98617B255C75EA302",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "174.06292486190796s\n"
     ]
    }
   ],
   "source": [
    "# 使用griddata函数对SST插值\n",
    "SST_Historical_After = np.zeros([SST_Historical.shape[0],\n",
    "                                 Lat_Historical_After_2D.shape[0],\n",
    "                                 Lat_Historical_After_2D.shape[1]])\n",
    "# 开始循环计算并计时\n",
    "start_time = time.time()\n",
    "for t in range(SST_Historical.shape[0]):\n",
    "    # griddata函数插值，需要输入插值前的经纬度信息，插值前的变量，插值后的经纬度，插值方法，这里插值方法选择'nearest'方法。\n",
    "    SST_Historical_After_Now = griddata(LatLon_Historical_Before,\n",
    "                                        SST_Historical_Before[t,\n",
    "                                                              :,\n",
    "                                                              :],\n",
    "                                        (Lat_Historical_After_2D,\n",
    "                                         Lon_Historical_After_2D),\n",
    "                                        method='nearest').squeeze()\n",
    "    SST_Historical_After_Now[np.where(\n",
    "        abs(SST_Historical_After_Now) >= 50)] == np.nan  # 大于50的值赋成nan值\n",
    "    SST_Historical_After[t, :, :] = SST_Historical_After_Now\n",
    "    if t % 100 == 0:  # 每100个数打印显示一下\n",
    "        print(t)\n",
    "end_time = time.time()\n",
    "print(str(end_time - start_time) + \"s\")  # 打印用时\n",
    "\n",
    "# 清空一下无关变量，后面不再用了\n",
    "del LatLon_Historical_Before\n",
    "del SST_Historical_Before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86474C9B8121498E85B3A33635ED056F",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 2.2.2.3 模式的未来预估数据插值\n",
    "同样地，我们采用同样的插值操作对未来预估数据插值。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "id": "865CD6654BE84DB9ACC264FB44DB4B27",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 177) (360, 177)\n"
     ]
    }
   ],
   "source": [
    "# 设置经纬度最大最小值\n",
    "Min_Lat_SSP = -88\n",
    "Max_Lat_SSP = 88\n",
    "Min_Lon_SSP = 0\n",
    "Max_Lon_SSP = 359\n",
    "# 插值前后的经纬度间隔\n",
    "Step_LatLon_After = 1\n",
    "# 给经纬度打网格\n",
    "Lat_SSP_mgrid = Lat_SSP\n",
    "Lon_SSP_mgrid = Lon_SSP\n",
    "# 插值前的经纬度, 维度是(384*320,2)\n",
    "LatLon_SSP_Before = np.hstack(\n",
    "    (Lat_SSP_mgrid.reshape(-1, 1), Lon_SSP_mgrid.reshape(-1, 1)))\n",
    "SST_SSP126_Before = SST_SSP126.reshape((SST_SSP126.shape[0], -1, 1))\n",
    "SST_SSP245_Before = SST_SSP245.reshape((SST_SSP245.shape[0], -1, 1))\n",
    "SST_SSP585_Before = SST_SSP585.reshape((SST_SSP585.shape[0], -1, 1))\n",
    "Lat_SSP_After_1D = np.arange(Max_Lat_SSP, Min_Lat_SSP-1, -Step_LatLon_After)\n",
    "Lon_SSP_After_1D = np.arange(Min_Lon_SSP, Max_Lon_SSP+1, Step_LatLon_After)\n",
    "Lat_SSP_After_2D, Lon_SSP_After_2D = np.meshgrid(\n",
    "    Lat_SSP_After_1D, Lon_SSP_After_1D)\n",
    "print(Lat_SSP_After_2D.shape, Lon_SSP_After_2D.shape)\n",
    "Lat_SSP_After_2D = Lat_SSP_After_2D.T\n",
    "Lon_SSP_After_2D = Lon_SSP_After_2D.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "id": "51E9C88175604EFF96646D11A5D5FC00",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "258.7564148902893s\n"
     ]
    }
   ],
   "source": [
    "# 使用griddata函数对SST插值\n",
    "SST_SSP126_After = np.zeros(\n",
    "    [SST_SSP126.shape[0], Lat_SSP_After_2D.shape[0],  Lat_SSP_After_2D.shape[1]])\n",
    "SST_SSP245_After = np.zeros(\n",
    "    [SST_SSP245.shape[0], Lat_SSP_After_2D.shape[0],  Lat_SSP_After_2D.shape[1]])\n",
    "SST_SSP585_After = np.zeros(\n",
    "    [SST_SSP585.shape[0], Lat_SSP_After_2D.shape[0],  Lat_SSP_After_2D.shape[1]])\n",
    "# 开始循环计算并计时\n",
    "start_time = time.time()\n",
    "for t in range(SST_SSP126.shape[0]):\n",
    "    # griddata函数插值，需要输入插值前的经纬度信息，插值前的变量，插值后的经纬度，插值方法，这里插值方法选择'nearest'方法。\n",
    "    # SSP1-2.6\n",
    "    SST_SSP126_After_Now = griddata(LatLon_SSP_Before,\n",
    "                                    SST_SSP126_Before[t,\n",
    "                                                      :,\n",
    "                                                      :],\n",
    "                                    (Lat_SSP_After_2D,\n",
    "                                     Lon_SSP_After_2D),\n",
    "                                    method='nearest')\n",
    "    SST_SSP126_After[t, :, :] = SST_SSP126_After_Now.squeeze()\n",
    "    # SSP2-4.5\n",
    "    SST_SSP245_After_Now = griddata(LatLon_SSP_Before,\n",
    "                                    SST_SSP245_Before[t,\n",
    "                                                      :,\n",
    "                                                      :],\n",
    "                                    (Lat_SSP_After_2D,\n",
    "                                     Lon_SSP_After_2D),\n",
    "                                    method='nearest')\n",
    "    SST_SSP245_After[t, :, :] = SST_SSP245_After_Now.squeeze()\n",
    "    # SSP5-8.5\n",
    "    SST_SSP585_After_Now = griddata(LatLon_SSP_Before,\n",
    "                                    SST_SSP585_Before[t,\n",
    "                                                      :,\n",
    "                                                      :],\n",
    "                                    (Lat_SSP_After_2D,\n",
    "                                     Lon_SSP_After_2D),\n",
    "                                    method='nearest')\n",
    "    SST_SSP585_After[t, :, :] = SST_SSP585_After_Now.squeeze()\n",
    "    if t % 100 == 0:\n",
    "        print(t)\n",
    "end_time = time.time()\n",
    "print(str(end_time - start_time) + \"s\")\n",
    "\n",
    "# 清空一下无关变量，后面不再用了\n",
    "del LatLon_SSP_Before\n",
    "del SST_SSP126_Before\n",
    "del SST_SSP245_Before\n",
    "del SST_SSP585_Before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3330165B50C54FE89110D2B3D932CC0C",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 2.2.3 计算全球平均SST\n",
    "插值得到均匀网格下的数据后，再计算一下全球平均的SST就能得到最终结果了。这里计算全球平均我们要注意不同纬度下的网格面积是不一样的，所以需要采用加权平均，不能用算术平均，否则会带来较大误差。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "18BFEF3C52DB4D4B84A82D3DA359C4D9",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### 2.2.3.1 区域平均函数的定义\n",
    "\n",
    "我们先来定义一个计算变量区域平均的函数，方便后续直接调用。关于区域平均计算的推导公示参见[魏萌的博文](https://blog.sciencenet.cn/blog-907194-687322.html)。\n",
    "这个插值函数areamean2D，我们在调用时只需要输入以下三个变量：\n",
    "&emsp;&emsp;  X: 待求区域平均的变量，这里就是SST;\n",
    "&emsp;&emsp;  lat: 纬度，1维；\n",
    "&emsp;&emsp;  lon: 经度，1维。\n",
    "\t\t\t\t就能得到输入变量X的区域平均值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "id": "3EA599FBDE084BD4BAE7C5D31CCE53AB",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义求区域平均函数\n",
    "def areamean2D(X, lat, lon):\n",
    "    \"\"\"\n",
    "    本函数计算经纬度网格下某变量区域平均值。\n",
    "\n",
    "    输入：\n",
    "        X: 待求区域平均的变量，如SST;\n",
    "        lat: 纬度；\n",
    "        lon: 经度。\n",
    "    输出：\n",
    "        X_AreaMean: 输入变量X的区域平均值\n",
    "\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    Len_lat = lat.shape[0]\n",
    "    Len_lon = lon.shape[0]\n",
    "    lat_2D = lat.repeat(Len_lon).reshape((Len_lat, Len_lon))\n",
    "    Weight = np.cos(np.pi/180*lat_2D)  # 关键是要计算不同纬度对应的权重\n",
    "    # 设置一个较大的较为合理的值，小于这个值才是正常的SST值\n",
    "    Weight_Ocean = Weight[np.where(abs(X) < 50)]\n",
    "    X_Ocean = X[np.where(abs(X) < 50)]  # 取出是海洋的点\n",
    "    X_AreaMean = sum(X_Ocean * Weight_Ocean) / sum(Weight_Ocean)  # 区域平均计算公式\n",
    "\n",
    "    return X_AreaMean  # 返回计算结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3F933A483AF544CDAC3B49376A0448FF",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### 2.2.3.2 计算观测的全球平均SST\n",
    "定义好计算区域平均函数后，我们就可以调用它来计算全球平均SST了。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "id": "5D9C67F1D2294B1D99AB0CBF430C0532",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "28.827313899993896s\n"
     ]
    }
   ],
   "source": [
    "SST_ERSST_AreaMean = np.zeros(\n",
    "    SST_ERSST_After.shape[0])  # 预定义一个空数组，以储存观测的全球平均SST。\n",
    "# 开始对观测SST逐月计算全球平均值\n",
    "start_time = time.time()\n",
    "for t in range(SST_ERSST_After.shape[0]):\n",
    "    # 调用函数areamean2D\n",
    "    SST_ERSST_AreaMean[t] = areamean2D(\n",
    "        SST_ERSST_After[t, :, :], Lat_ERSST_After_1D, Lon_ERSST_After_1D)\n",
    "    if t % 100 == 0:  # 每100个数打印显示一下\n",
    "        print(t)\n",
    "end_time = time.time()\n",
    "print(str(end_time - start_time) + \"s\")\n",
    "del SST_ERSST_After\n",
    "del Lat_ERSST_After_1D\n",
    "del Lon_ERSST_After_1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1B73ECC17E72459699C46A25FF676E9D",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### 2.2.3.3 计算模式历史的全球平均SST\n",
    "与观测数据计算类似，我们调用函数计算即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "id": "82CD73E893BE4568886930118D5A6459",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "27.72053289413452s\n"
     ]
    }
   ],
   "source": [
    "SST_Historical_AreaMean = np.zeros(SST_Historical_After.shape[0])\n",
    "# 开始对模式的历史SST逐月计算全球平均值\n",
    "start_time = time.time()\n",
    "for t in range(SST_Historical_After.shape[0]):\n",
    "    SST_Historical_AreaMean[t] = areamean2D(\n",
    "        SST_Historical_After[t, :, :], Lat_Historical_After_1D, Lon_Historical_After_1D)\n",
    "    if t % 100 == 0:  # 每100个数打印显示一下\n",
    "        print(t)\n",
    "end_time = time.time()\n",
    "print(str(end_time - start_time) + \"s\")\n",
    "del SST_Historical_After\n",
    "del Lat_Historical_After_1D\n",
    "del Lon_Historical_After_1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0D4F846166E145F688E1BE3AAB1C9C11",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### 2.2.3.4  计算模式未来预估的全球平均SST\n",
    "与观测和模式历史数据操作类似。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "id": "BCE885A064FF46EE8527027F7FEEF2A7",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "42.439735412597656s\n"
     ]
    }
   ],
   "source": [
    "SST_SSP126_AreaMean = np.zeros(SST_SSP126_After.shape[0])\n",
    "SST_SSP245_AreaMean = np.zeros(SST_SSP245_After.shape[0])\n",
    "SST_SSP585_AreaMean = np.zeros(SST_SSP585_After.shape[0])\n",
    "start_time = time.time()\n",
    "for t in range(SST_SSP126_After.shape[0]):\n",
    "    SST_SSP126_AreaMean[t] = areamean2D(\n",
    "        SST_SSP126_After[t, :, :], Lat_SSP_After_1D, Lon_SSP_After_1D)\n",
    "    SST_SSP245_AreaMean[t] = areamean2D(\n",
    "        SST_SSP245_After[t, :, :], Lat_SSP_After_1D, Lon_SSP_After_1D)\n",
    "    SST_SSP585_AreaMean[t] = areamean2D(\n",
    "        SST_SSP585_After[t, :, :], Lat_SSP_After_1D, Lon_SSP_After_1D)\n",
    "    if t % 100 == 0:\n",
    "        print(t)\n",
    "end_time = time.time()\n",
    "print(str(end_time - start_time) + \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FEDD8CA0815E4E0DB1FD409B8CC59F8A",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### 2.2.3.5 保存数据\n",
    "算出最终结果，我们就要记得把计算得到的全球平均SST的观测值和模式值保存下来。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "id": "3C1C10F614264C27B2285F4DF9CFD5D8",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./project/SaveData/Original/ successfully build!\n"
     ]
    }
   ],
   "source": [
    "# 设置一下保存路径以及文件夹存在与否的判断\n",
    "Path_Pre = './project/'\n",
    "Path_SaveData = Path_Pre + 'SaveData/Original/'\n",
    "isExists = os.path.exists(Path_SaveData)\n",
    "if not isExists:\n",
    "    os.makedirs(Path_Pre + 'SaveData/Original')   # 创建文件夹\n",
    "    # 创建文件夹，打印 ' successfully build!'\n",
    "    print(Path_SaveData + ' successfully build!')\n",
    "else:\n",
    "    # 如果文件夹已经建立，打印 ‘has been existed!’\n",
    "    print(Path_SaveData + ' has been existed!')\n",
    "\n",
    "# 保存成npy文件\n",
    "Num_Year = 2014-1854+1\n",
    "Num_Sample_SST = Num_Year*12\n",
    "SST_ERSST_AreaMean = SST_ERSST_AreaMean[0:Num_Sample_SST]\n",
    "SST_Historical_AreaMean = SST_Historical_AreaMean[-Num_Sample_SST::]\n",
    "Time_ERSST = Time_ERSST[0:Num_Sample_SST]\n",
    "np.save(Path_SaveData + 'SST_ERSST_AreaMean.npy', SST_ERSST_AreaMean)\n",
    "np.save(Path_SaveData + 'SST_Historical_AreaMean.npy', SST_Historical_AreaMean)\n",
    "np.save(Path_SaveData + 'SST_SSP126_AreaMean.npy', SST_SSP126_AreaMean)\n",
    "np.save(Path_SaveData + 'SST_SSP245_AreaMean.npy', SST_SSP245_AreaMean)\n",
    "np.save(Path_SaveData + 'SST_SSP585_AreaMean.npy', SST_SSP585_AreaMean)\n",
    "np.save(Path_SaveData + 'Time_ERSST.npy', Time_ERSST)\n",
    "np.save(Path_SaveData + 'Time_SSP.npy', Time_SSP)\n",
    "\n",
    "# 保存成mat文件，留作后续octave环境下eemd数据分解使用\n",
    "io.savemat(Path_SaveData + 'SST_ERSST_AreaMean.mat',\n",
    "           {'SST_ERSST_AreaMean': SST_ERSST_AreaMean})\n",
    "io.savemat(Path_SaveData + 'SST_Historical_AreaMean.mat',\n",
    "           {'SST_Historical_AreaMean': SST_Historical_AreaMean})\n",
    "io.savemat(Path_SaveData + 'SST_SSP126_AreaMean.mat',\n",
    "           {'SST_SSP126_AreaMean': SST_SSP126_AreaMean})\n",
    "io.savemat(Path_SaveData + 'SST_SSP245_AreaMean.mat',\n",
    "           {'SST_SSP245_AreaMean': SST_SSP245_AreaMean})\n",
    "io.savemat(Path_SaveData + 'SST_SSP585_AreaMean.mat',\n",
    "           {'SST_SSP585_AreaMean': SST_SSP585_AreaMean})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F972A0C4936B4614B5F133CB357473BC",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 2.2.4 绘图\n",
    "我们可以通过画图查看观测与模式的全球SST随时间的变化序列，包括历史时期的和模式未来预估的时间序列。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "87ADB1A892BB4D328EC641854472F46E",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "同样地，我们要设置保存路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "id": "08317997600948568EE8C836DE49DCBB",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./project/Figures/Original/ successfully build!\n"
     ]
    }
   ],
   "source": [
    "Path_Pre = './project/'\n",
    "Path_SaveFigures = Path_Pre + 'Figures/Original/'\n",
    "isExists = os.path.exists(Path_SaveFigures)\n",
    "if not isExists:\n",
    "    os.makedirs(Path_Pre + 'Figures/Original')\n",
    "    print(Path_SaveFigures + ' successfully build!')\n",
    "else:\n",
    "    print(Path_SaveFigures + ' has been existed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EA6711ED05D04DA18FCE8ED6746300EA",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### 2.2.4.1 历史时期全球平均SST的观测、模式和模式偏差的时间序列（模式减观测）\n",
    "我们先看一下历史时期的时间序列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "id": "26314E2D816A40AD8C094FFD86D49D65",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 240, 480, 720, 960, 1200, 1440, 1680, 1920]\n",
      "[16.0, 16.5, 17.0, 17.5, 18.0, 18.5, 19.0]\n",
      "['16.0', '16.5', '17.0', '17.5', '18.0', '18.5', '19.0']\n",
      "[-1.0, -0.5, 0.0, 0.5, 1.0]\n",
      "['-1.0', '-0.5', '0.0', '0.5', '1.0']\n"
     ]
    }
   ],
   "source": [
    "# 先预设一下画图的设置\n",
    "markersizenum = 4  # 标记大小\n",
    "Num_Year = 2014-1854+1\n",
    "Num_Sample_SST = Num_Year*12\n",
    "X_Time = np.arange(0, Num_Sample_SST)  # 生成时间数组\n",
    "Time_SST = np.array(Time_Historical[-Num_Sample_SST::])\n",
    "xtick_SST_interval = 20*12  # 画图横坐标的刻度间隔\n",
    "# SST\n",
    "SST_Historical_AreaMean = SST_Historical_AreaMean[-Num_Sample_SST::]\n",
    "SST_ERSST_AreaMean = SST_ERSST_AreaMean[0:Num_Sample_SST]\n",
    "xticklabel_SST = list(range(0, Num_Sample_SST, xtick_SST_interval))\n",
    "print(xticklabel_SST)\n",
    "xticklabels_SST = Time_SST[xticklabel_SST[0::]].astype('str').tolist()\n",
    "ylim_sst_max = 19\n",
    "ylim_sst_min = 16\n",
    "delta_ylim_sst = ylim_sst_max - ylim_sst_min\n",
    "yticklabel_SST = np.linspace(ylim_sst_min, ylim_sst_max, num=7).tolist()\n",
    "yticklabel_SST = [round(i, 1) for i in yticklabel_SST]\n",
    "print(yticklabel_SST)\n",
    "yticklabels_SST = [str(i) for i in yticklabel_SST]\n",
    "print(yticklabels_SST)\n",
    "# SST偏差\n",
    "SST_Bias_AreaMean = SST_Historical_AreaMean - SST_ERSST_AreaMean\n",
    "xticklabel_Bias = xticklabel_SST\n",
    "xticklabels_Bias = xticklabels_SST\n",
    "ylim_bias_max = 1\n",
    "ylim_bias_min = -1\n",
    "delta_ylim_bias = ylim_bias_max - ylim_bias_min\n",
    "yticklabel_Bias = np.linspace(-1, 1, num=5).tolist()\n",
    "yticklabel_Bias = [round(i, 1) for i in yticklabel_Bias]\n",
    "print(yticklabel_Bias)\n",
    "yticklabels_Bias = [str(i) for i in yticklabel_Bias]\n",
    "print(yticklabels_Bias)\n",
    "str_panels = ['a)ERSST ', 'b)Historical', 'c)SST Bias ']\n",
    "# 画图\n",
    "fig, ax = plt.subplots(3, 1, figsize=(16, 9), dpi=600)\n",
    "# 观测：ERSST\n",
    "ax = plt.subplot(3, 1, 1)\n",
    "ax.plot(\n",
    "    X_Time,\n",
    "    SST_ERSST_AreaMean,\n",
    "    'k-',\n",
    "    linewidth=2,\n",
    "    marker='.',\n",
    "    markersize=markersizenum,\n",
    "    mfc='black')\n",
    "ax.set_xlim(0, Num_Sample_SST)\n",
    "ax.set_ylim(ylim_sst_min, ylim_sst_max)\n",
    "ax.set_xticks(xticklabel_SST)\n",
    "ax.set_yticks(yticklabel_SST)\n",
    "ax.set_xticklabels(xticklabels_SST)\n",
    "ax.set_yticklabels(yticklabels_SST)\n",
    "ax.text(1, ylim_sst_min + 0.9*delta_ylim_sst, str_panels[0])\n",
    "ax.set_ylabel('SST(℃)')\n",
    "ax.grid(linestyle='-.')\n",
    "# 模式：历史时期\n",
    "ax = plt.subplot(3, 1, 2)\n",
    "ax.plot(\n",
    "    X_Time,\n",
    "    SST_Historical_AreaMean,\n",
    "    'b-',\n",
    "    linewidth=2,\n",
    "    marker='.',\n",
    "    markersize=markersizenum,\n",
    "    mfc='blue')\n",
    "ax.set_xlim(0, Num_Sample_SST)\n",
    "ax.set_ylim(ylim_sst_min, ylim_sst_max)\n",
    "ax.set_xticks(xticklabel_SST)\n",
    "ax.set_yticks(yticklabel_SST)\n",
    "ax.set_xticklabels(xticklabels_SST)\n",
    "ax.set_yticklabels(yticklabels_SST)\n",
    "ax.text(1, ylim_sst_min + 0.9*delta_ylim_sst, str_panels[1])\n",
    "ax.set_ylabel('SST(℃)')\n",
    "ax.grid(linestyle='-.')\n",
    "# 模式偏差：模式减观测\n",
    "ax = plt.subplot(3, 1, 3)\n",
    "ax.plot(\n",
    "    X_Time,\n",
    "    SST_Bias_AreaMean,\n",
    "    'b-',\n",
    "    linewidth=2,\n",
    "    marker='.',\n",
    "    markersize=markersizenum,\n",
    "    mfc='blue')\n",
    "ax.set_xlim(0, Num_Sample_SST)\n",
    "ax.set_ylim(ylim_bias_min, ylim_bias_max)\n",
    "ax.set_xticks(xticklabel_Bias)\n",
    "ax.set_yticks(yticklabel_Bias)\n",
    "ax.set_xticklabels(xticklabels_Bias)\n",
    "ax.set_yticklabels(yticklabels_Bias)\n",
    "ax.text(1, ylim_bias_min + 0.9*delta_ylim_bias, str_panels[2])\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('SST Bias(℃)')\n",
    "ax.grid(linestyle='-.')\n",
    "# 保存图片\n",
    "fns = os.path.join(Path_SaveFigures, 'SST_ERSST_Historical_Bias.png')\n",
    "plt.savefig(fns, dpi=600, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10F5B34F74444EDAADE115DBC1A5C78F",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "上图自上到下依次是：a）观测SST，b）模式SST，c）模式模拟的SST偏差（模式减去观测）在185401-201412的全球平均时间序列，可以看出观测和模式的全球平均SST随着时间均呈现增长的趋势，但是模式相对观测还存在正负1度之间的偏差，且偏差时间序列有着非线性非平稳的特征。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D80B9CDB62174977A44C4EA88E19973E",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### 2.2.4.2 模式预估全球平均SST的3种未来情景试验的时间序列\n",
    "画完历史时期的，我们再来看一下模式对未来预估的全球平均SST时间序列。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "id": "438996497DD1432E8B1A97701A906416",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 144, 288, 432, 576, 720, 864, 1008]\n",
      "[18.0, 19.0, 20.0, 21.0, 22.0]\n",
      "['18.0', '19.0', '20.0', '21.0', '22.0']\n",
      "[18.0, 19.0, 20.0, 21.0, 22.0]\n",
      "['18.0', '19.0', '20.0', '21.0', '22.0']\n",
      "[18.0, 19.0, 20.0, 21.0, 22.0]\n",
      "['18.0', '19.0', '20.0', '21.0', '22.0']\n"
     ]
    }
   ],
   "source": [
    "# 同上，预设画图参数\n",
    "markersizenum = 4\n",
    "Num_Year = 2100-2015+1\n",
    "Num_Sample_SSP = Num_Year*12\n",
    "X_Time = np.arange(0, Num_Sample_SSP)\n",
    "Time_SSP = np.array(Time_SSP)\n",
    "xtick_SSP_interval = 12*12\n",
    "# SSP126\n",
    "xticklabel_SSP = list(range(0, Num_Sample_SSP, xtick_SSP_interval))\n",
    "print(xticklabel_SSP)\n",
    "xticklabels_SSP = Time_SSP[xticklabel_SSP[0::]].astype('str').tolist()\n",
    "ylim_ssp126_max = 22\n",
    "ylim_ssp126_min = 18\n",
    "delta_ylim_ssp126 = ylim_ssp126_max - ylim_ssp126_min\n",
    "yticklabel_SSP126 = np.linspace(\n",
    "    ylim_ssp126_min,\n",
    "    ylim_ssp126_max,\n",
    "    num=5).tolist()\n",
    "yticklabel_SSP126 = [round(i, 1) for i in yticklabel_SSP126]\n",
    "print(yticklabel_SSP126)\n",
    "yticklabels_SSP126 = [str(i) for i in yticklabel_SSP126]\n",
    "print(yticklabels_SSP126)\n",
    "# SSP245\n",
    "ylim_ssp245_max = 22\n",
    "ylim_ssp245_min = 18\n",
    "delta_ylim_ssp245 = ylim_ssp245_max - ylim_ssp245_min\n",
    "yticklabel_SSP245 = np.linspace(\n",
    "    ylim_ssp245_min,\n",
    "    ylim_ssp245_max,\n",
    "    num=5).tolist()\n",
    "yticklabel_SSP245 = [round(i, 1) for i in yticklabel_SSP245]\n",
    "print(yticklabel_SSP245)\n",
    "yticklabels_SSP245 = [str(i) for i in yticklabel_SSP245]\n",
    "print(yticklabels_SSP245)\n",
    "# SSP585\n",
    "ylim_ssp585_max = 22\n",
    "ylim_ssp585_min = 18\n",
    "delta_ylim_ssp585 = ylim_ssp585_max - ylim_ssp585_min\n",
    "yticklabel_SSP585 = np.linspace(\n",
    "    ylim_ssp585_min,\n",
    "    ylim_ssp585_max,\n",
    "    num=5).tolist()\n",
    "yticklabel_SSP585 = [round(i, 1) for i in yticklabel_SSP585]\n",
    "print(yticklabel_SSP585)\n",
    "yticklabels_SSP585 = [str(i) for i in yticklabel_SSP585]\n",
    "print(yticklabels_SSP585)\n",
    "str_panels = ['a)SSP1-2.6 ', 'b)SSP2-4.5', 'c)SSP5-8.5']\n",
    "# 绘图\n",
    "fig, ax = plt.subplots(3, 1, figsize=(4, 3), dpi=600)\n",
    "# SSP126\n",
    "ax = plt.subplot(3, 1, 1)\n",
    "ax.plot(\n",
    "    X_Time,\n",
    "    SST_SSP126_AreaMean,\n",
    "    'b-',\n",
    "    linewidth=2,\n",
    "    marker='.',\n",
    "    markersize=markersizenum,\n",
    "    mfc='blue')\n",
    "ax.set_xlim(0, Num_Sample_SSP)\n",
    "ax.set_ylim(ylim_ssp126_min, ylim_ssp126_max)\n",
    "ax.set_xticks(xticklabel_SSP)\n",
    "ax.set_yticks(yticklabel_SSP126)\n",
    "ax.set_xticklabels(xticklabels_SSP)\n",
    "ax.set_yticklabels(yticklabels_SSP126)\n",
    "ax.text(1, ylim_ssp126_min + 0.9*delta_ylim_ssp126, str_panels[0])\n",
    "ax.set_ylabel('SST(℃)')\n",
    "ax.grid(linestyle='-.')\n",
    "# SSP245\n",
    "ax = plt.subplot(3, 1, 2)\n",
    "ax.plot(\n",
    "    X_Time,\n",
    "    SST_SSP245_AreaMean,\n",
    "    'b-',\n",
    "    linewidth=2,\n",
    "    marker='.',\n",
    "    markersize=markersizenum,\n",
    "    mfc='blue')\n",
    "ax.set_xlim(0, Num_Sample_SSP)\n",
    "ax.set_ylim(ylim_ssp245_min, ylim_ssp245_max)\n",
    "ax.set_xticks(xticklabel_SSP)\n",
    "ax.set_yticks(yticklabel_SSP245)\n",
    "ax.set_xticklabels(xticklabels_SSP)\n",
    "ax.set_yticklabels(yticklabels_SSP245)\n",
    "ax.text(1, ylim_ssp245_min + 0.9*delta_ylim_ssp245, str_panels[1])\n",
    "ax.set_ylabel('SST(℃)')\n",
    "ax.grid(linestyle='-.')\n",
    "# SSP585\n",
    "ax = plt.subplot(3, 1, 3)\n",
    "ax.plot(\n",
    "    X_Time,\n",
    "    SST_SSP585_AreaMean,\n",
    "    'b-',\n",
    "    linewidth=2,\n",
    "    marker='.',\n",
    "    markersize=markersizenum,\n",
    "    mfc='blue')\n",
    "ax.set_xlim(0, Num_Sample_SSP)\n",
    "ax.set_ylim(ylim_ssp585_min, ylim_ssp585_max)\n",
    "ax.set_xticks(xticklabel_SSP)\n",
    "ax.set_yticks(yticklabel_SSP585)\n",
    "ax.set_xticklabels(xticklabels_SSP)\n",
    "ax.set_yticklabels(yticklabels_SSP585)\n",
    "ax.text(1, ylim_ssp585_min + 0.9*delta_ylim_ssp585, str_panels[2])\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('SST(℃)')\n",
    "ax.grid(linestyle='-.')\n",
    "# 保存图片\n",
    "fns = os.path.join(Path_SaveFigures, 'SST_SSP126_245_585.png')\n",
    "plt.savefig(fns, dpi=600, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A90EFDE2C72C4FBE83905869CD0BD59D",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "上图自上到下依次是：a）低排放预估，b）中等排放预估，c）高排放预估在201501-210012的全球平均时间序列，三种排放预估结果都显示未来全球平均SST将随时间逐渐升高，排放越高，上升的越快，到本世纪末温度越高。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24C6DDBCFD504EDE8091B6122B45E9E7",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd0f2bb4f9f8adf2a46f4f",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 小结\n",
    "本章我们带领大家认识了用到的SST数据，并对数据做了基本的读取、插值、计算全球平均和画图展示的操作，得到全球平均SST数据之后，我们就可以进行下一步：对SST数据进行EEMD分解了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EEMD分解部分参考EEMD.ipynb文件（该部分使用Octave实现）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D89B0EAB542642F98900CCC4D4E49360",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# EEMD后处理\n",
    "\n",
    "上一章得到经过EEMD分解后数据后，我们需要对不同频率的分解时间序列确定周期，再按照特定时间尺度来做一个组合，这样等于给SST施加了物理约束。\n",
    "我们在这一章就是要对上一章分解出来的SST结果画图展示一下，然后计算各个分量的平均周期，最后做一个组合，以便用到最后的订正上。\n",
    "\n",
    "**大家需要注意的是，我们主要使用的环境还是Python3环境，上一章的海表面温度数据EEMD分解是在Octave环境下完成的，也就是说只有EEMD分解这一步需要Octave环境，其他步骤都在Python3环境下完成。**\n",
    "**这里计算资源建议大家选择2核8G CPU资源，使用镜像为octave 测试镜像-song-v1，Kernel类型为Python3。**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "810CF482643D4985AFA558B9F60AF78D",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "624ef709c47d0200184a3cb9",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 4.1 导包、导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "id": "4FC61B519BE24DD590C9913A15FBDA95",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "id": "16BEDEF83DF24B65ABB0E52615CECDCB",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 原始数据\n",
    "Path_Data_Original = './project/SaveData/Original/'\n",
    "Time_ERSST = np.load(Path_Data_Original + 'Time_ERSST.npy')\n",
    "Time_SSP = np.load(Path_Data_Original + 'Time_SSP.npy')\n",
    "Num_Year = 86  # 1929-2014\n",
    "Num_Sample_SST = Num_Year*12\n",
    "Time_SST = np.arange(0,Num_Sample_SST)\n",
    "Time_ERSST = Time_ERSST[-Num_Sample_SST::]\n",
    "# EEMD分解的数据\n",
    "Path_Data_EEMD = './project/SaveData/EEMD/'\n",
    "IMFs_ERSST = sio.loadmat(Path_Data_EEMD + 'IMFs_ERSST.mat'); IMFs_ERSST = IMFs_ERSST['IMFs_ERSST']\n",
    "IMFs_Historical = sio.loadmat(Path_Data_EEMD + 'IMFs_Historical.mat'); IMFs_Historical = IMFs_Historical['IMFs_Historical']\n",
    "IMFs_SSP126 = sio.loadmat(Path_Data_EEMD + 'IMFs_SSP126.mat'); IMFs_SSP126 = IMFs_SSP126['IMFs_SSP126']\n",
    "IMFs_SSP245 = sio.loadmat(Path_Data_EEMD + 'IMFs_SSP245.mat'); IMFs_SSP245 = IMFs_SSP245['IMFs_SSP245']\n",
    "IMFs_SSP585 = sio.loadmat(Path_Data_EEMD + 'IMFs_SSP585.mat'); IMFs_SSP585 = IMFs_SSP585['IMFs_SSP585']\n",
    "# 保存成npy文件\n",
    "np.save(Path_Data_EEMD + 'IMFs_ERSST.npy', IMFs_ERSST)\n",
    "np.save(Path_Data_EEMD + 'IMFs_Historical.npy', IMFs_Historical)\n",
    "np.save(Path_Data_EEMD + 'IMFs_SSP126.npy', IMFs_SSP126)\n",
    "np.save(Path_Data_EEMD + 'IMFs_SSP245.npy', IMFs_SSP245)\n",
    "np.save(Path_Data_EEMD + 'IMFs_SSP585.npy', IMFs_SSP585)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69C089D4AC794E78BA13684DC13B183B",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dde5c53915ed2e06c82102",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 4.2 画图：画出观测和模式历史和未来的各个IMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BCB1058B527549F989CF0E01DA9A8E55",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dde5c53915ed2e06c82102",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**设置保存路径**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "id": "B125A8E855CF472285A08D74F2986B8A",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dde5c53915ed2e06c82102",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./project/Figures/EEMD/ successfully build!\n"
     ]
    }
   ],
   "source": [
    "Path_Pre = './project/Figures/'\n",
    "Path_SaveFigures =  Path_Pre + 'EEMD/'\n",
    "isExists = os.path.exists(Path_SaveFigures)\n",
    "if not isExists:\n",
    "    os.makedirs(Path_Pre + 'EEMD/')\n",
    "    print( Path_SaveFigures +  ' successfully build!')\n",
    "else:\n",
    "    print( Path_SaveFigures + ' has been existed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8F4A25C2943742C180399B4AD21CCBF7",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dde5c53915ed2e06c82102",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 4.2.1 画观测SST的IMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "id": "8F7D8576D2B944D2A42D5FBBC6970D20",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dde5c53915ed2e06c82102",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-0.3', '-0.0', '0.2']\n",
      "['-0.2', '0.0', '0.2']\n",
      "['-0.1', '0.0', '0.2']\n",
      "['-0.2', '0.0', '0.2']\n",
      "['-0.1', '0.0', '0.1']\n",
      "['-0.1', '0.0', '0.2']\n",
      "['-0.1', '0.0', '0.1']\n",
      "['-0.1', '-0.0', '0.0']\n",
      "['-0.1', '0.0', '0.1']\n",
      "['17.6', '18.0', '18.4']\n"
     ]
    }
   ],
   "source": [
    "NIMFs_ERSST = IMFs_ERSST.shape[0]\n",
    "Max_IMFs_ERSST = np.max(IMFs_ERSST, 1)\n",
    "Min_IMFs_ERSST = np.min(IMFs_ERSST, 1)\n",
    "# 预设\n",
    "fontsizenum = 16\n",
    "Num_Year = 86\n",
    "Num_Sample_SST = Num_Year*12\n",
    "X_Time = np.arange(0, Num_Sample_SST)\n",
    "Time_SST = np.array(Time_SST[-Num_Sample_SST::])\n",
    "xtick_SST_interval = 7*12\n",
    "xticklabel_SST = list(range(0, Num_Sample_SST, xtick_SST_interval))\n",
    "xticklabels_SST = Time_ERSST[xticklabel_SST[0::]].astype('str').tolist()\n",
    "# 画图\n",
    "fig, ax = plt.subplots(NIMFs_ERSST, 1, figsize=(15, 18), dpi=600)\n",
    "for n in range(NIMFs_ERSST):\n",
    "    ax = plt.subplot(NIMFs_ERSST, 1, n + 1)\n",
    "    ax.plot(X_Time, IMFs_ERSST[n, :], 'k-', linewidth=2)\n",
    "    ax.set_xlim(0, Num_Sample_SST)\n",
    "    ax.set_xticks(xticklabel_SST)\n",
    "    ax.set_xticklabels([])\n",
    "    yticks_all = np.round(ax.get_yticks(), 1)\n",
    "    if yticks_all[0] == yticks_all[-1]:\n",
    "        yticks_all[0] = -0.1\n",
    "        yticks_all[-1] = 0.1\n",
    "    yticks_end = np.array((yticks_all[0], np.round(\n",
    "        (yticks_all[0] + yticks_all[-1]) / 2, 1), yticks_all[-1]))\n",
    "    yticklabels_end = [str(i) for i in yticks_end]\n",
    "    print(yticklabels_end)\n",
    "    ax.set_yticks(yticks_end)\n",
    "    ax.set_yticklabels(yticklabels_end, fontsize=fontsizenum)\n",
    "    ax.set_ylabel('IMF' + str(n+1), fontsize=fontsizenum)\n",
    "ax.set_xticks(xticklabel_SST)\n",
    "ax.set_xticklabels(xticklabels_SST, fontsize=fontsizenum)\n",
    "ax.set_xlabel('Time', fontsize=fontsizenum)\n",
    "# 保存图片，先保存再显示。\n",
    "fns = os.path.join(Path_SaveFigures, 'IMFs_ERSST.png')\n",
    "plt.savefig(fns, dpi=600, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F28FE73832364742B5536909C09EC1A4",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dde5c53915ed2e06c82102",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "上图是观测SST在192901-201412的10个IMF时间序列，自上到下依次是IMF1到IMF10。其中IMF1到IMF9频率依次降低，IMF10是趋势项，可以看出近百年来，我们生存的地球平均SST呈现逐年升温的趋势。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9168DF32CB954C5F8F677ADA3222ED5F",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dde5c53915ed2e06c82102",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 4.2.2 画模式的历史SST的IMF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "id": "D672A6DA22044421924584DCEFE45A4F",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-0.2', '0.0', '0.2']\n",
      "['-0.4', '0.0', '0.4']\n",
      "['-0.1', '0.0', '0.1']\n",
      "['-0.1', '0.0', '0.1']\n",
      "['-0.1', '0.0', '0.1']\n",
      "['-0.1', '0.0', '0.1']\n",
      "['-0.2', '0.0', '0.2']\n",
      "['-0.1', '0.0', '0.1']\n",
      "['-0.1', '0.0', '0.1']\n",
      "['17.5', '18.0', '18.5']\n"
     ]
    }
   ],
   "source": [
    "NIMFs_Historical = IMFs_Historical.shape[0]\n",
    "Max_IMFs_Historical = np.max(IMFs_Historical, 1)\n",
    "Min_IMFs_Historical = np.min(IMFs_Historical, 1)\n",
    "# 预设\n",
    "fontsizenum = 16  \n",
    "Num_Year = 86\n",
    "Num_Sample_SST = Num_Year*12\n",
    "X_Time = np.arange(0, Num_Sample_SST )\n",
    "Time_SST = np.array(Time_SST[-Num_Sample_SST::])\n",
    "xtick_SST_interval = 7*12\n",
    "xticklabel_SST = list(range(0, Num_Sample_SST, xtick_SST_interval))\n",
    "xticklabels_SST = Time_ERSST[xticklabel_SST[0::]].astype('str').tolist()\n",
    "# 画图\n",
    "fig, ax = plt.subplots(NIMFs_Historical, 1, figsize = (15,18), dpi = 600)\n",
    "for n in range(NIMFs_Historical):\n",
    "    ax = plt.subplot(NIMFs_Historical, 1, n + 1)\n",
    "    ax.plot(X_Time, IMFs_Historical[n,:], 'b-', linewidth = 2)\n",
    "    ax.set_xlim(0, Num_Sample_SST)\n",
    "    ax.set_xticks(xticklabel_SST)\n",
    "    ax.set_xticklabels([])\n",
    "    yticks_all = np.round(ax.get_yticks(), 1)\n",
    "    if yticks_all[0] == yticks_all[-1]:\n",
    "        yticks_all[0] = -0.1\n",
    "        yticks_all[-1] = 0.1\n",
    "    yticks_end = np.array((yticks_all[0], np.round((yticks_all[0] + yticks_all[-1]) / 2, 1), yticks_all[-1]))\n",
    "    yticklabels_end = [str(i) for i in yticks_end]\n",
    "    print(yticklabels_end)\n",
    "    ax.set_yticks(yticks_end)\n",
    "    ax.set_yticklabels(yticklabels_end, fontsize = fontsizenum)\n",
    "    ax.set_ylabel('IMF' + str(n+1), fontsize = fontsizenum)\n",
    "ax.set_xticks(xticklabel_SST)\n",
    "ax.set_xticklabels(xticklabels_SST, fontsize = fontsizenum)\n",
    "ax.set_xlabel('Time', fontsize = fontsizenum)\n",
    "# 保存图片，先保存再显示。\n",
    "fns = os.path.join(Path_SaveFigures, 'IMFs_Historical.png')\n",
    "plt.savefig(fns, dpi = 600, bbox_inches = 'tight') \n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8E3F132F4B1D40759027068FBF03C996",
    "jupyter": {},
    "mdEditEnable": true,
    "notebookId": "62dde5c53915ed2e06c82102",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "上图是模式SST在192901-201412的10个IMF时间序列，自上到下依次是IMF1到IMF10。其中IMF1到IMF9频率依次降低，IMF10是趋势项，可以看出近百年来，模式也能模拟出全球平均SST呈现逐年升温的趋势。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "175C20F9607048BE90B266AE8AE36107",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dde5c53915ed2e06c82102",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 4.2.3 画模式的未来预估SST的IMF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0B166C81C3D64C4781F7A352D53D3623",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dde5c53915ed2e06c82102",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**SSP126**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "id": "74C264FEB64F41A38FEB5738AFBB305B",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dde5c53915ed2e06c82102",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-0.2', '0.0', '0.2']\n",
      "['-0.4', '0.0', '0.4']\n",
      "['-0.1', '0.0', '0.1']\n",
      "['-0.1', '0.0', '0.1']\n",
      "['-0.1', '0.0', '0.1']\n",
      "['-0.1', '0.0', '0.1']\n",
      "['-0.1', '0.0', '0.1']\n",
      "['-0.1', '0.0', '0.1']\n",
      "['-0.1', '0.0', '0.1']\n",
      "['18.4', '18.8', '19.2']\n"
     ]
    }
   ],
   "source": [
    "NIMFs_SSP = IMFs_SSP126.shape[0]\n",
    "Max_IMFs_SSP126 = np.max(IMFs_SSP126, 1)\n",
    "Min_IMFs_SSP126 = np.min(IMFs_SSP126, 1)\n",
    "# 预设\n",
    "fontsizenum = 16  \n",
    "Num_Year = 86\n",
    "Num_Sample_SST = Num_Year*12\n",
    "X_Time = np.arange(0, Num_Sample_SST )\n",
    "Time_SST = np.array(Time_SST[-Num_Sample_SST::])\n",
    "xtick_SST_interval = 7*12\n",
    "xticklabel_SST = list(range(0, Num_Sample_SST, xtick_SST_interval))\n",
    "xticklabels_SST = Time_SSP[xticklabel_SST[0::]].astype('str').tolist()\n",
    "# 画图\n",
    "fig, ax = plt.subplots(NIMFs_SSP, 1, figsize = (15,18), dpi = 600)\n",
    "for n in range(NIMFs_SSP):\n",
    "    ax = plt.subplot(NIMFs_SSP, 1, n + 1)\n",
    "    ax.plot(X_Time, IMFs_SSP126[n,:], 'b-', linewidth = 2)\n",
    "    ax.set_xlim(0, Num_Sample_SST)\n",
    "    ax.set_xticks(xticklabel_SST)\n",
    "    ax.set_xticklabels([])\n",
    "    yticks_all = np.round(ax.get_yticks(), 1)\n",
    "    if yticks_all[0] == yticks_all[-1]:\n",
    "        yticks_all[0] = -0.1\n",
    "        yticks_all[-1] = 0.1\n",
    "    yticks_end = np.array( (yticks_all[0], np.round((yticks_all[0] + yticks_all[-1]) / 2, 1), yticks_all[-1]) )\n",
    "    yticklabels_end = [str(i) for i in yticks_end]\n",
    "    print(yticklabels_end)\n",
    "    ax.set_yticks(yticks_end)\n",
    "    ax.set_yticklabels(yticklabels_end, fontsize = fontsizenum)\n",
    "    ax.set_ylabel('IMF' + str(n+1), fontsize = fontsizenum)\n",
    "ax.set_xticks(xticklabel_SST)\n",
    "ax.set_xticklabels(xticklabels_SST, fontsize = fontsizenum)\n",
    "ax.set_xlabel('Time', fontsize = fontsizenum)\n",
    "# 保存图片，先保存再显示。\n",
    "fns = os.path.join(Path_SaveFigures, 'IMFs_SSP126.png')\n",
    "plt.savefig(fns, dpi = 600, bbox_inches = 'tight') \n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AB152B9EA3914766AE4ED25009AC48F2",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dde5c53915ed2e06c82102",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "上图是模式在未来低排放情景下预估SST在201501-210012的10个IMF时间序列，自上到下依次是IMF1到IMF10。其中IMF1到IMF9频率依次降低，IMF10是趋势项，预估结果显示，未来近百年全球平均SST呈现继续升温趋势。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0D2894335D84442998B271146D820D92",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dde5c53915ed2e06c82102",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**SSP245**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "id": "4CDB171E13D7414F92D3F27C6BE1F506",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dde5c53915ed2e06c82102",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-0.2', '-0.0', '0.1']\n",
      "['-0.4', '0.0', '0.4']\n",
      "['-0.2', '0.0', '0.2']\n",
      "['-0.1', '0.0', '0.2']\n",
      "['-0.1', '0.0', '0.1']\n",
      "['-0.1', '0.0', '0.1']\n",
      "['-0.1', '-0.0', '0.0']\n",
      "['-0.1', '0.0', '0.1']\n",
      "['-0.1', '0.0', '0.1']\n",
      "['18.0', '19.0', '20.0']\n"
     ]
    }
   ],
   "source": [
    "Max_IMFs_SSP245 = np.max(IMFs_SSP245, 1)\n",
    "Min_IMFs_SSP245 = np.min(IMFs_SSP245, 1)\n",
    "# 画图\n",
    "fig, ax = plt.subplots(NIMFs_SSP, 1, figsize = (15,18), dpi = 600)\n",
    "for n in range(NIMFs_SSP):\n",
    "    ax = plt.subplot(NIMFs_SSP, 1, n + 1)\n",
    "    ax.plot(X_Time, IMFs_SSP245[n,:], 'b-', linewidth = 2)\n",
    "    ax.set_xlim(0, Num_Sample_SST)\n",
    "    ax.set_xticks(xticklabel_SST)\n",
    "    ax.set_xticklabels([])\n",
    "    yticks_all = np.round(ax.get_yticks(), 1)\n",
    "    if yticks_all[0] == yticks_all[-1]:\n",
    "        yticks_all[0] = -0.1\n",
    "        yticks_all[-1] = 0.1\n",
    "    yticks_end = np.array( (yticks_all[0], np.round((yticks_all[0] + yticks_all[-1]) / 2, 1), yticks_all[-1]) )\n",
    "    yticklabels_end = [str(i) for i in yticks_end]\n",
    "    print(yticklabels_end)\n",
    "    ax.set_yticks(yticks_end)\n",
    "    ax.set_yticklabels(yticklabels_end, fontsize = fontsizenum)\n",
    "    ax.set_ylabel('IMF' + str(n+1), fontsize = fontsizenum)\n",
    "ax.set_xticks(xticklabel_SST)\n",
    "ax.set_xticklabels(xticklabels_SST, fontsize = fontsizenum)\n",
    "ax.set_xlabel('Time', fontsize = fontsizenum)\n",
    "# 保存图片，先保存再显示。\n",
    "fns = os.path.join(Path_SaveFigures, 'IMFs_SSP245.png')\n",
    "plt.savefig(fns, dpi = 600, bbox_inches = 'tight') \n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7155B7366E0242E18FC174129DEBFBA4",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dde5c53915ed2e06c82102",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "上图是模式在未来中等排放情景下预估SST在201501-210012的10个IMF时间序列，自上到下依次是IMF1到IMF10。其中IMF1到IMF9频率依次降低，IMF10是趋势项，预估结果显示，未来近百年全球平均SST呈现继续升温趋势，升温幅度比低排放更大。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BB431635209B4D02833F8B9B6C2117A3",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dde5c53915ed2e06c82102",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**SSP585**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "id": "1066DB01C6C24715A084FE30CE2FF065",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dde5c53915ed2e06c82102",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-0.2', '0.0', '0.2']\n",
      "['-0.2', '0.0', '0.2']\n",
      "['-0.2', '0.0', '0.2']\n",
      "['-0.1', '0.0', '0.1']\n",
      "['-0.1', '0.0', '0.1']\n",
      "['-0.1', '0.0', '0.1']\n",
      "['-0.1', '0.0', '0.1']\n",
      "['-0.1', '0.0', '0.1']\n",
      "['-0.2', '0.0', '0.2']\n",
      "['18.0', '20.0', '22.0']\n"
     ]
    }
   ],
   "source": [
    "Max_IMFs_SSP585 = np.max(IMFs_SSP585, 1)\n",
    "Min_IMFs_SSP585 = np.min(IMFs_SSP585, 1)\n",
    "# 画图\n",
    "fig, ax = plt.subplots(NIMFs_SSP, 1, figsize = (15,18), dpi = 600)\n",
    "for n in range(NIMFs_SSP):\n",
    "    ax = plt.subplot(NIMFs_SSP, 1, n + 1)\n",
    "    ax.plot(X_Time, IMFs_SSP585[n,:], 'b-', linewidth = 2)\n",
    "    ax.set_xlim(0, Num_Sample_SST)\n",
    "    ax.set_xticks(xticklabel_SST)\n",
    "    ax.set_xticklabels([])\n",
    "    yticks_all = np.round(ax.get_yticks(), 1)\n",
    "    if yticks_all[0] == yticks_all[-1]:\n",
    "        yticks_all[0] = -0.1\n",
    "        yticks_all[-1] = 0.1\n",
    "    yticks_end = np.array( (yticks_all[0], np.round((yticks_all[0] + yticks_all[-1]) / 2, 1), yticks_all[-1]) )\n",
    "    yticklabels_end = [str(i) for i in yticks_end]\n",
    "    print(yticklabels_end)\n",
    "    ax.set_yticks(yticks_end)\n",
    "    ax.set_yticklabels(yticklabels_end, fontsize = fontsizenum)\n",
    "    ax.set_ylabel('IMF' + str(n+1), fontsize = fontsizenum)\n",
    "ax.set_xticks(xticklabel_SST)\n",
    "ax.set_xticklabels(xticklabels_SST, fontsize = fontsizenum)\n",
    "ax.set_xlabel('Time', fontsize = fontsizenum)\n",
    "# 保存图片，先保存再显示。\n",
    "fns = os.path.join(Path_SaveFigures, 'IMFs_SSP585.png')\n",
    "plt.savefig(fns, dpi = 600, bbox_inches = 'tight') \n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9FF033DDA644FF08494EE2B2CC508BD",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dde5c53915ed2e06c82102",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "上图是模式在未来高排放情景下预估SST在201501-210012的10个IMF时间序列，自上到下依次是IMF1到IMF10。其中IMF1到IMF9频率依次降低，IMF10是趋势项，预估结果显示，未来近百年全球平均SST呈现继续升温趋势，升温幅度在三种排放情景中最大，本世纪末较2015年升高近4°C。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2CA19A513F24C0EB445CD44E9E0984C",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dde5c53915ed2e06c82102",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 4.3 计算EEMD分解数据平均周期\n",
    "**计算各个IMF的平均周期，这里我们根据跨零点的个数计算平均周期。大家要特别注意最后两个IMF，计算公式可能带来较大误差**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "id": "EC475A0FD1104FAF868188AA89D1155E",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dde5c53915ed2e06c82102",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.49002849  0.88659794  1.14666667  3.51020408  6.61538462 13.23076923\n",
      " 34.4        43.         86.        ]\n",
      "[ 0.47645429  1.00584795  1.4214876   4.0952381   7.47826087 19.11111111\n",
      " 43.         43.         86.        ]\n",
      "[ 0.48725212  1.00584795  1.4214876   4.77777778  6.88       15.63636364\n",
      " 43.         86.         86.        ]\n",
      "[ 0.46112601  0.89119171  1.00584795  3.51020408  4.91428571 10.11764706\n",
      " 24.57142857 43.         86.        ]\n",
      "[ 0.37310195  0.57718121  1.00584795  2.6875      4.91428571 10.11764706\n",
      " 43.         86.         86.        ]\n"
     ]
    }
   ],
   "source": [
    "# ERSST\n",
    "Num_CrossZero_ERSST = np.zeros(NIMFs_ERSST - 1)\n",
    "MeanPeriod_IMFs_ERSST = np.zeros(NIMFs_ERSST - 1)\n",
    "MeanYearPeriod_IMFs_ERSST = np.zeros(NIMFs_ERSST - 1)\n",
    "for n in range(NIMFs_ERSST - 1):\n",
    "    k = 0\n",
    "    for i in range(len(Time_SST) - 1):\n",
    "        if IMFs_ERSST[n,i] * IMFs_ERSST[n,i + 1] < 0:  # 数跨零点的个数\n",
    "            k = k + 1\n",
    "    Num_CrossZero_ERSST[n] = k\n",
    "    MeanPeriod_IMFs_ERSST[n] = len(Time_SST) * 2 / k  # 根据跨零点的个数计算平均周期，单位是月\n",
    "    MeanYearPeriod_IMFs_ERSST[n] = len(Time_SST) * 2 / k / 12  # 单位转换成年\n",
    "# 打印观测的SST各个imf的平均周期\n",
    "print(MeanYearPeriod_IMFs_ERSST)\n",
    "\n",
    "# Historical\n",
    "NIMFs_Historical = IMFs_Historical.shape[0]\n",
    "Num_CrossZero_Historical = np.zeros(NIMFs_Historical - 1)\n",
    "MeanPeriod_IMFs_Historical = np.zeros(NIMFs_Historical - 1)\n",
    "MeanYearPeriod_IMFs_Historical = np.zeros(NIMFs_Historical - 1)\n",
    "for n in range(NIMFs_Historical - 1):\n",
    "    k = 0\n",
    "    for i in range(len(Time_SST)-1):\n",
    "        if IMFs_Historical[n,i] * IMFs_Historical[n,i + 1] < 0:\n",
    "            k = k + 1\n",
    "    Num_CrossZero_Historical[n] = k\n",
    "    MeanPeriod_IMFs_Historical[n] = len(Time_SST) * 2 / k\n",
    "    MeanYearPeriod_IMFs_Historical[n] = len(Time_SST) * 2 / k / 12\n",
    "# 打印模式的历史SST各个imf的平均周期\n",
    "print(MeanYearPeriod_IMFs_Historical)\n",
    "\n",
    "# SSP126/SSP245/SSP585\n",
    "NIMFs_SSP = IMFs_SSP126.shape[0]\n",
    "Num_CrossZero_SSP126 = np.zeros(NIMFs_SSP - 1)\n",
    "Num_CrossZero_SSP245 = np.zeros(NIMFs_SSP - 1)\n",
    "Num_CrossZero_SSP585 = np.zeros(NIMFs_SSP - 1)\n",
    "MeanPeriod_IMFs_SSP126 = np.zeros(NIMFs_SSP - 1)\n",
    "MeanPeriod_IMFs_SSP245 = np.zeros(NIMFs_SSP - 1)\n",
    "MeanPeriod_IMFs_SSP585 = np.zeros(NIMFs_SSP - 1)\n",
    "MeanYearPeriod_IMFs_SSP126 = np.zeros(NIMFs_SSP - 1)\n",
    "MeanYearPeriod_IMFs_SSP245 = np.zeros(NIMFs_SSP - 1)\n",
    "MeanYearPeriod_IMFs_SSP585 = np.zeros(NIMFs_SSP - 1)\n",
    "for n in range(NIMFs_SSP - 1):\n",
    "    # SSP126\n",
    "    k = 0\n",
    "    for i in range(len(Time_SST)-1):\n",
    "        if IMFs_SSP126[n,i] * IMFs_SSP126[n,i + 1] < 0:\n",
    "            k = k + 1\n",
    "    Num_CrossZero_SSP126[n] = k\n",
    "    MeanPeriod_IMFs_SSP126[n] = len(Time_SST) * 2 / k\n",
    "    MeanYearPeriod_IMFs_SSP126[n] = len(Time_SST) * 2 / k / 12\n",
    "\n",
    "    # SSP245\n",
    "    k = 0\n",
    "    for i in range(len(Time_SST) - 1):\n",
    "        if IMFs_SSP245[n, i] * IMFs_SSP245[n, i + 1] < 0:\n",
    "            k = k + 1\n",
    "    Num_CrossZero_SSP245[n] = k\n",
    "    MeanPeriod_IMFs_SSP245[n] = len(Time_SST) * 2 / k\n",
    "    MeanYearPeriod_IMFs_SSP245[n] = len(Time_SST) * 2 / k / 12\n",
    "\n",
    "    # SSP585\n",
    "    k = 0\n",
    "    for i in range(len(Time_SST) - 1):\n",
    "        if IMFs_SSP585[n, i] * IMFs_SSP585[n, i + 1] < 0:\n",
    "            k = k + 1\n",
    "    Num_CrossZero_SSP585[n] = k\n",
    "    MeanPeriod_IMFs_SSP585[n] = len(Time_SST) * 2 / k\n",
    "    MeanYearPeriod_IMFs_SSP585[n] = len(Time_SST) * 2 / k / 12\n",
    "# 打印模式的未来预估SST各个imf的平均周期\n",
    "print(MeanYearPeriod_IMFs_SSP126)\n",
    "print(MeanYearPeriod_IMFs_SSP245)\n",
    "print(MeanYearPeriod_IMFs_SSP585)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BF3BDB37AAFF42F0801BD263B61876DB",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dde5c53915ed2e06c82102",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 4.4. 根据平均周期组合IMF\n",
    "\n",
    "#### &emsp;&emsp; 我们依据的时间尺度有以下6个:\n",
    "#### &emsp;&emsp; &emsp;&emsp; 1) 季节：3个月~12个月\n",
    "#### &emsp;&emsp; &emsp;&emsp; 2) 年：12个月左右\n",
    "#### &emsp;&emsp; &emsp;&emsp; 3) 年际：1年~10年\n",
    "#### &emsp;&emsp; &emsp;&emsp; 4) 十年：10年左右\n",
    "#### &emsp;&emsp; &emsp;&emsp; 5) 年代际：大于10年\n",
    "#### &emsp;&emsp; &emsp;&emsp; 6) 年代际：>80年"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "id": "123333D05C1346728670143FBC353C50",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dde5c53915ed2e06c82102",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ERSST\n",
    "IMFs_ERSST_Compose = np.zeros( (6, Num_Sample_SST) )\n",
    "IMFs_ERSST_Compose[0,:] = IMFs_ERSST[0,:]  # 第1个imf\n",
    "IMFs_ERSST_Compose[1,:] = np.sum( IMFs_ERSST[1:3,:], 0 )  # 第2-3个imf\n",
    "IMFs_ERSST_Compose[2,:] = np.sum( IMFs_ERSST[3:5,:], 0 )  # 第4-5个imf\n",
    "IMFs_ERSST_Compose[3,:] = IMFs_ERSST[5,:]  # 第6个imf\n",
    "IMFs_ERSST_Compose[4,:] = np.sum( IMFs_ERSST[6:8,:], 0 )  # 第7-8个imf\n",
    "IMFs_ERSST_Compose[5,:] = np.sum( IMFs_ERSST[8:10,:], 0 ) # 第9个imf和最后一个趋势项\n",
    "# Historical\n",
    "IMFs_Historical_Compose = np.zeros( (6, Num_Sample_SST) )\n",
    "IMFs_Historical_Compose[0,:] = IMFs_Historical[0,:] \n",
    "IMFs_Historical_Compose[1,:] = np.sum( IMFs_Historical[1:3,:], 0 )  \n",
    "IMFs_Historical_Compose[2,:] = np.sum( IMFs_Historical[3:5,:], 0 )  \n",
    "IMFs_Historical_Compose[3,:] = IMFs_Historical[5,:]  \n",
    "IMFs_Historical_Compose[4,:] = np.sum( IMFs_Historical[6:8,:], 0 )\n",
    "IMFs_Historical_Compose[5,:] = np.sum( IMFs_Historical[8:10,:], 0 )  \n",
    "\n",
    "## SSP126/SSP245/SSP585\n",
    "# SSP126\n",
    "IMFs_SSP126_Compose = np.zeros( (6, Num_Sample_SST) )\n",
    "IMFs_SSP126_Compose[0,:] = IMFs_SSP126[0,:]  \n",
    "IMFs_SSP126_Compose[1,:] = np.sum( IMFs_SSP126[1:3,:], 0 ) \n",
    "IMFs_SSP126_Compose[2,:] = np.sum( IMFs_SSP126[3:5,:], 0 )  \n",
    "IMFs_SSP126_Compose[3,:] = IMFs_SSP126[5,:]  \n",
    "IMFs_SSP126_Compose[4,:] = np.sum( IMFs_SSP126[6:8,:], 0 )  \n",
    "IMFs_SSP126_Compose[5,:] = np.sum( IMFs_SSP126[8:10,:], 0 )  \n",
    "# SSP245\n",
    "IMFs_SSP245_Compose = np.zeros( (6, Num_Sample_SST) )\n",
    "IMFs_SSP245_Compose[0,:] = IMFs_SSP245[0,:] \n",
    "IMFs_SSP245_Compose[1,:] = np.sum( IMFs_SSP245[1:3,:], 0 )  \n",
    "IMFs_SSP245_Compose[2,:] = np.sum( IMFs_SSP245[3:5,:], 0 )  \n",
    "IMFs_SSP245_Compose[3,:] = IMFs_SSP245[5,:]  \n",
    "IMFs_SSP245_Compose[4,:] = np.sum( IMFs_SSP245[6:8,:], 0 )  \n",
    "IMFs_SSP245_Compose[5,:] = np.sum( IMFs_SSP245[8:10,:], 0 )  \n",
    "# SSP585\n",
    "IMFs_SSP585_Compose = np.zeros( (6, Num_Sample_SST) )\n",
    "IMFs_SSP585_Compose[0,:] = IMFs_SSP585[0,:]  \n",
    "IMFs_SSP585_Compose[1,:] = np.sum( IMFs_SSP585[1:3,:], 0 )  \n",
    "IMFs_SSP585_Compose[2,:] = np.sum( IMFs_SSP585[3:5,:], 0 )  \n",
    "IMFs_SSP585_Compose[3,:] = IMFs_SSP585[5,:]  \n",
    "IMFs_SSP585_Compose[4,:] = np.sum( IMFs_SSP585[6:8,:], 0 )  \n",
    "IMFs_SSP585_Compose[5,:] = np.sum( IMFs_SSP585[8:10,:], 0 )  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0A42AC1725474B368BBA6236323749C3",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dde5c53915ed2e06c82102",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**保存数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "id": "38BC33B6BA624B928965EAFD70E68D79",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dde5c53915ed2e06c82102",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Path_SaveData = './project/SaveData/EEMD/'\n",
    "np.save(Path_SaveData + 'IMFs_ERSST_Compose.npy', IMFs_ERSST_Compose)\n",
    "np.save(Path_SaveData + 'IMFs_Historical_Compose.npy', IMFs_Historical_Compose)\n",
    "np.save(Path_SaveData + 'IMFs_SSP126_Compose.npy', IMFs_SSP126_Compose)\n",
    "np.save(Path_SaveData + 'IMFs_SSP245_Compose.npy', IMFs_SSP245_Compose)\n",
    "np.save(Path_SaveData + 'IMFs_SSP585_Compose.npy', IMFs_SSP585_Compose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32EEDE9A06D643168576760B080932EE",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dde5c53915ed2e06c82102",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 小结\n",
    "本章我们带领大家学习绘制了观测和模式的imf分图，并计算了各个imf的平均周期，并根据特定时间尺度来对imf组合得到最终的6个组合时间序列。之后，我们就可以开始下一步使用机器学习模型对SST订正的部分了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D89B0EAB542642F98900CCC4D4E49360",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# SST订正及预估\n",
    "对EEMD分解数据后处理之后，我们就可以用来做下一步的订正了。\n",
    "本章我们要关注的问题有：\n",
    "&emsp;&emsp; 1）我们选择BPNN模型来订正海表温度的原因是什么？\n",
    "&emsp;&emsp; 2）我们的BPNN订正模型需要的数据要做哪些处理？模式历史偏差订正和未来预估的关系是什么？\n",
    "&emsp;&emsp; 3）我们如何评价订正结果？\n",
    "\n",
    "**这里，我们计算资源选择2核8G CPU资源即可，使用镜像为octave 测试镜像-song-v1，Kernel类型为Python3。**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "810CF482643D4985AFA558B9F60AF78D",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "624ef709c47d0200184a3cb9",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 5.1 BPNN机器学习模型简介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4FC61B519BE24DD590C9913A15FBDA95",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "[BPNN（Back Propagation Neural Network）](https://blog.csdn.net/cufewxy1/article/details/80445023?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522165906166016781685332684%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=165906166016781685332684&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-2-80445023-null-null.142^v35^new_blog_fixed_pos&utm_term=bpnn%E6%A8%A1%E5%9E%8B&spm=1018.2226.3001.4187)一般包括输入层、隐含层和输出层。一般地，输入层和输出层只有一层，隐含层则至少有一层。网络的每一层都有一定数量的神经元，不同数量的神经元组成的多层网络有很强大的非线性表达能力。以三层BPNN为例，其网络结构如下图所示。如背景所述和前两章我们画的海温偏差图也可以看出，，模式海温偏差本身并不是线性变化那么简单，而是具有非线性的变化特征，BPNN正有强大的非线性表达能力，能够挖掘模式与观测之间偏差的规律特征，实现偏差订正的目的。因此，我们选择了这个模型来做后续的订正。\n",
    "\n",
    "![Image Name](https://cdn.kesci.com/upload/image/rfj5o9e7hp.png?imageView2/0/w/960/h/960)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "85D13AA48A494808B372D1FF723946BA",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "&emsp;&emsp; &emsp;&emsp; &emsp;&emsp; &emsp;&emsp; &emsp;&emsp; &emsp;&emsp; &emsp;&emsp; &emsp;&emsp; &emsp;&emsp; &emsp;&emsp; &emsp;&emsp; &emsp;&emsp; &emsp;&emsp; &emsp;&emsp; &emsp;&emsp; &emsp;&emsp; &emsp;&emsp; &emsp;&emsp; 三层神经网络示意图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D672A6DA22044421924584DCEFE45A4F",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 5.2 BPNN 模型订正历史全球平均SST数据\n",
    "了解了我们需要的BPNN模型之后，接下来就要用模型来订正SST了，具体可分为以下几个部分：\n",
    "&emsp;&emsp; 1）导入工具包：我们要用到Sklearn库，包括归一化函数和模型包。\n",
    "&emsp;&emsp; 2）导入数据：把组合后的模式和观测数据导进来使用。\n",
    "&emsp;&emsp; 3）划分数据集：按照机器学习常用的划分数据集方法，我们对数据随机划分成训练集、验证集和测试集，以满足数据集的均匀分布。\n",
    "&emsp;&emsp; 4）预定义归一化数组。对后面需要归一化的数组进行预分配。\n",
    "&emsp;&emsp; 5）建立并训练模型：建模使用到了Sklearn库中MLPRegressor的包，并根据验证集的误差表现来调整隐层参数。\n",
    "&emsp;&emsp; 6）处理模型输出数据并保存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1C6B818A3906402C914F5AF25A0276C3",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 5.2.1 导入工具包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "id": "36202E20F22041EC84CDC4AF9BF575CB",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler  # 最大最小归一化函数\n",
    "from sklearn.neural_network import MLPRegressor # 多层感知器回归，这里等于BPNN\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression # 线性回归函数用于最后的海温增加量\n",
    " \n",
    "# 定义均方根误差rmse函数\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt( ( (predictions - targets)**2 ).mean() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9F5E65476CE34689B179913E57633530",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 5.2.2 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "id": "BBF835A563984D469957288EFE0E72D8",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EEMD分解后的组合数据\n",
    "Path_EEMDData = './project/SaveData/EEMD/'\n",
    "IMFs_ERSST_Compose = np.load(Path_EEMDData + 'IMFs_ERSST_Compose.npy')\n",
    "IMFs_Historical_Compose = np.load(Path_EEMDData + 'IMFs_Historical_Compose.npy')\n",
    "IMFs_SSP126_Compose = np.load(Path_EEMDData + 'IMFs_SSP126_Compose.npy')\n",
    "IMFs_SSP245_Compose = np.load(Path_EEMDData + 'IMFs_SSP245_Compose.npy')\n",
    "IMFs_SSP585_Compose = np.load(Path_EEMDData + 'IMFs_SSP585_Compose.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CAE2824D851D41459AD0889F6AA1D0EB",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 4.2.3 划分数据集\n",
    "按照年份**随机划分训练集、验证集和测试集**，这里我们训练集，验证集和测试集的数目分别取70、8和8。划分好数据集之后，我们再对三个数据集的数组变换一下维度，也就是变成（组合数，年份数，12）的维度，为后面输入模型准备。\n",
    "\n",
    "这里组合数就是我们用EEMD分解后按照特定时间尺度得到的IMF组合，我们后面建立模型要对每个IMF组合分别建模订正，最后将所有组合相加得到最终的订正结果。\n",
    "\n",
    "**模型的输入输出设置为：输入12个神经元，每个神经元输入同一月份组成的多年的模式向量，输出12个神经元，同样地，每个神经元输出同一月份组成的多年的观测向量。隐藏层的数目作为超参数，我们可以设置多个不同的数目去调参，观察验证集误差，最后取误差最小时对应的神经元数作为最终网络结构。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "id": "5560DD8AACDE49949C0CD46310F2FD71",
    "jupyter": {
     "outputs_hidden": false
    },
    "mdEditEnable": false,
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 随机划分数据集\n",
    "# 3个集合的年份数分配\n",
    "Num_Year= 86\n",
    "Num_Year_Train = 70\n",
    "Num_Year_Validate = 8\n",
    "Num_Year_Test = 8\n",
    "# 设置随机数种子，使每次实验结果一致\n",
    "random.seed(1)\n",
    "Index_Year = list( range(Num_Year) )\n",
    "Index_Year_Random = list( range(Num_Year) )\n",
    "random.shuffle(Index_Year_Random) # 打乱年序号，后面根据年序号随机划分训练集、验证集和测试集\n",
    "Index_Year_Train = Index_Year_Random[0:Num_Year_Train] # 训练集的序号\n",
    "Index_Year_Validate = Index_Year_Random[Num_Year_Train:Num_Year_Train + Num_Year_Validate] # 验证集的序号\n",
    "Index_Year_Test = Index_Year_Random[-Num_Year_Test::]  # 测试集的序号\n",
    "## 数据集：变换成3维数组，即（组合数，年份数，12）\n",
    "IMFs_ERSST_Compose_3D = IMFs_ERSST_Compose.reshape((6, Num_Year, 12)) \n",
    "IMFs_Historical_Compose_3D = IMFs_Historical_Compose.reshape((6, Num_Year, 12))\n",
    "IMFs_SSP126_Compose_3D = IMFs_SSP126_Compose.reshape((6, Num_Year, 12))\n",
    "IMFs_SSP245_Compose_3D = IMFs_SSP245_Compose.reshape((6, Num_Year, 12))\n",
    "IMFs_SSP585_Compose_3D = IMFs_SSP585_Compose.reshape((6, Num_Year, 12))\n",
    "# 对观测数据ERSST划分三个数据集合\n",
    "IMFs_ERSST_Compose_3D_Train = IMFs_ERSST_Compose_3D[:,Index_Year_Train, :]\n",
    "IMFs_ERSST_Compose_3D_Validate = IMFs_ERSST_Compose_3D[:,Index_Year_Validate, :]\n",
    "IMFs_ERSST_Compose_3D_Test = IMFs_ERSST_Compose_3D[:,Index_Year_Test, :]\n",
    "IMFs_ERSST_Compose_2D_Train = IMFs_ERSST_Compose_3D_Train.reshape((6,-1)) # 训练集 变成2维，方便计算每个组合的误差\n",
    "IMFs_ERSST_Compose_2D_Validate = IMFs_ERSST_Compose_3D_Validate.reshape((6,-1)) # 验证集 变成2维，方便计算每个组合的误差\n",
    "IMFs_ERSST_Compose_2D_Test = IMFs_ERSST_Compose_3D_Test.reshape((6,-1)) # 测试集 变成2维，方便计算每个组合的误差\n",
    "# 模式的历史时期数据，同观测\n",
    "IMFs_Historical_Compose_3D_Train = IMFs_Historical_Compose_3D[:,Index_Year_Train, :]\n",
    "IMFs_Historical_Compose_3D_Validate = IMFs_Historical_Compose_3D[:,Index_Year_Validate, :]\n",
    "IMFs_Historical_Compose_3D_Test = IMFs_Historical_Compose_3D[:,Index_Year_Test, :]\n",
    "IMFs_Historical_Compose_2D_Train = IMFs_Historical_Compose_3D_Train.reshape((6,-1))\n",
    "IMFs_Historical_Compose_2D_Validate = IMFs_Historical_Compose_3D_Validate.reshape((6,-1))\n",
    "IMFs_Historical_Compose_2D_Test = IMFs_Historical_Compose_3D_Test.reshape((6,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C18CB46AC4CA440C82F51C76E6F51A1A",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 5.2.4 预定义归一化数组\n",
    "这里给归一化需要的数组预分配空间，真正归一化的步骤我们把它放在4.2.5建立模型的循环中了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "id": "F08991D0699A447B8FEDF7F517FDB297",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./project/Model/ successfully build!\n"
     ]
    }
   ],
   "source": [
    "# 归一化：预分配变量空间\n",
    "Input_Train_Scaler = np.zeros(IMFs_Historical_Compose_3D_Train.shape)\n",
    "Output_Train_Scaler = np.zeros(IMFs_ERSST_Compose_3D_Train.shape)\n",
    "Input_Validate_Scaler = np.zeros(IMFs_Historical_Compose_3D_Validate.shape)\n",
    "Input_Test_Scaler = np.zeros(IMFs_Historical_Compose_3D_Test.shape)\n",
    "Input_Forecast126_Scaler = np.zeros(IMFs_SSP126_Compose_3D.shape)\n",
    "Input_Forecast245_Scaler = np.zeros(IMFs_SSP245_Compose_3D.shape)\n",
    "Input_Forecast585_Scaler = np.zeros(IMFs_SSP585_Compose_3D.shape)\n",
    "# 预设相关统计量和变量\n",
    "RMSE_Predict_Train_All = np.zeros((6,9))  # (IMF的组合数, 待测试的隐层神经元数)\n",
    "RMSE_Predict_Validate_All =  np.zeros((6,9))  # (IMF的组合数, 待测试的隐层神经元数)\n",
    "RMSE_Predict_Test_All =  np.zeros((6,9))  # (IMF的组合数, 待测试的隐层神经元数)\n",
    "Neuron_Predict_All = np.zeros(6)  # 储存每个组合验证集修正后误差最小时对应的隐层神经元数目\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt( ( (predictions - targets)**2 ).mean() )\n",
    "BP_Output_Train = np.zeros(IMFs_ERSST_Compose_3D_Train.shape)  # 反归一化后的原始值\n",
    "BP_Output_Validate = np.zeros(IMFs_ERSST_Compose_3D_Validate.shape)\n",
    "BP_Output_Test = np.zeros(IMFs_ERSST_Compose_3D_Test.shape)\n",
    "BP_Output_SSP126 = np.zeros(IMFs_SSP126_Compose_3D.shape)\n",
    "BP_Output_SSP245 = np.zeros(IMFs_SSP245_Compose_3D.shape)\n",
    "BP_Output_SSP585 = np.zeros(IMFs_SSP585_Compose_3D.shape)\n",
    " \n",
    "# 保存模型路径 \n",
    "Path_Pre = './project/'\n",
    "Path_SaveModel =  Path_Pre + 'Model/'\n",
    "isExists = os.path.exists(Path_SaveModel)\n",
    "if not isExists:\n",
    "    os.makedirs(Path_Pre + 'Model/')\n",
    "    print( Path_SaveModel +  ' successfully build!')\n",
    "else:\n",
    "    print( Path_SaveModel + ' has been existed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6EC347C7516A434984C63F89A89DC221",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 5.2.5 建立并训练模型\n",
    "我们建立模型采用的是[sklearn.neural_network 模块中MLPRegressor类](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html?highlight=mlp#sklearn.neural_network.MLPRegressor)，中文链接[点这](https://scikit-learn.org.cn/view/714.html)，建立3层神经网络，1层隐藏层。\n",
    "这里，我们在对历史全球海温数据订正的同时，也已经把未来预估的结果进行了订正，最后根据最佳隐藏层神经元数的订正结果选择最终的历史和未来预估的订正结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "id": "7B06EF42FCDC409B87D2D904C61DEC9A",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMF number is:  1 , neuron number is:  6 , RMSE_Train:  0.044241979267417554 ,RMSE_Predict_Train:  0.025645057571702753\n",
      "IMF number is:  1 , neuron number is:  6 , RMSE_Validate:  0.05155530181593175 ,RMSE_Predict_Validate:  0.03468478565846921\n",
      "IMF number is:  1 , neuron number is:  6 , RMSE_Test:  0.04100331926996361 ,RMSE_Predict_Test:  0.022841334361694537\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "IMF number is:  1 , neuron number is:  6 , RMSE_Predict_Validate_Min:  0.03468478565846921\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "IMF number is:  1 , neuron number is:  7 , RMSE_Train:  0.044241979267417554 ,RMSE_Predict_Train:  0.02555725822336281\n",
      "IMF number is:  1 , neuron number is:  7 , RMSE_Validate:  0.05155530181593175 ,RMSE_Predict_Validate:  0.03667097236547388\n",
      "IMF number is:  1 , neuron number is:  7 , RMSE_Test:  0.04100331926996361 ,RMSE_Predict_Test:  0.023574363167551536\n",
      "IMF number is:  1 , neuron number is:  8 , RMSE_Train:  0.044241979267417554 ,RMSE_Predict_Train:  0.025464049253806856\n",
      "IMF number is:  1 , neuron number is:  8 , RMSE_Validate:  0.05155530181593175 ,RMSE_Predict_Validate:  0.0359021101370316\n",
      "IMF number is:  1 , neuron number is:  8 , RMSE_Test:  0.04100331926996361 ,RMSE_Predict_Test:  0.02463356295419165\n",
      "IMF number is:  1 , neuron number is:  9 , RMSE_Train:  0.044241979267417554 ,RMSE_Predict_Train:  0.024711690864612758\n",
      "IMF number is:  1 , neuron number is:  9 , RMSE_Validate:  0.05155530181593175 ,RMSE_Predict_Validate:  0.03303791129297583\n",
      "IMF number is:  1 , neuron number is:  9 , RMSE_Test:  0.04100331926996361 ,RMSE_Predict_Test:  0.027064327013136238\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "IMF number is:  1 , neuron number is:  9 , RMSE_Predict_Validate_Min:  0.03303791129297583\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "IMF number is:  1 , neuron number is:  10 , RMSE_Train:  0.044241979267417554 ,RMSE_Predict_Train:  0.025440961867950355\n",
      "IMF number is:  1 , neuron number is:  10 , RMSE_Validate:  0.05155530181593175 ,RMSE_Predict_Validate:  0.03325570878889029\n",
      "IMF number is:  1 , neuron number is:  10 , RMSE_Test:  0.04100331926996361 ,RMSE_Predict_Test:  0.02295726472866514\n",
      "IMF number is:  1 , neuron number is:  11 , RMSE_Train:  0.044241979267417554 ,RMSE_Predict_Train:  0.024519552399082867\n",
      "IMF number is:  1 , neuron number is:  11 , RMSE_Validate:  0.05155530181593175 ,RMSE_Predict_Validate:  0.03361572480825616\n",
      "IMF number is:  1 , neuron number is:  11 , RMSE_Test:  0.04100331926996361 ,RMSE_Predict_Test:  0.025049912204142512\n",
      "IMF number is:  1 , neuron number is:  12 , RMSE_Train:  0.044241979267417554 ,RMSE_Predict_Train:  0.025197038197647025\n",
      "IMF number is:  1 , neuron number is:  12 , RMSE_Validate:  0.05155530181593175 ,RMSE_Predict_Validate:  0.03484421240016884\n",
      "IMF number is:  1 , neuron number is:  12 , RMSE_Test:  0.04100331926996361 ,RMSE_Predict_Test:  0.023776620755965264\n",
      "IMF number is:  1 , neuron number is:  13 , RMSE_Train:  0.044241979267417554 ,RMSE_Predict_Train:  0.02444472571703512\n",
      "IMF number is:  1 , neuron number is:  13 , RMSE_Validate:  0.05155530181593175 ,RMSE_Predict_Validate:  0.03417128090059045\n",
      "IMF number is:  1 , neuron number is:  13 , RMSE_Test:  0.04100331926996361 ,RMSE_Predict_Test:  0.023458089705129175\n",
      "IMF number is:  1 , neuron number is:  14 , RMSE_Train:  0.044241979267417554 ,RMSE_Predict_Train:  0.0245440096094453\n",
      "IMF number is:  1 , neuron number is:  14 , RMSE_Validate:  0.05155530181593175 ,RMSE_Predict_Validate:  0.03874456707278906\n",
      "IMF number is:  1 , neuron number is:  14 , RMSE_Test:  0.04100331926996361 ,RMSE_Predict_Test:  0.023845895518404197\n",
      "IMF number is:  2 , neuron number is:  6 , RMSE_Train:  0.14884765205342124 ,RMSE_Predict_Train:  0.036809045296943135\n",
      "IMF number is:  2 , neuron number is:  6 , RMSE_Validate:  0.13942235843603729 ,RMSE_Predict_Validate:  0.03882441277403164\n",
      "IMF number is:  2 , neuron number is:  6 , RMSE_Test:  0.1421657923108667 ,RMSE_Predict_Test:  0.04444172461871018\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "IMF number is:  2 , neuron number is:  6 , RMSE_Predict_Validate_Min:  0.03882441277403164\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "IMF number is:  2 , neuron number is:  7 , RMSE_Train:  0.14884765205342124 ,RMSE_Predict_Train:  0.036951306230122466\n",
      "IMF number is:  2 , neuron number is:  7 , RMSE_Validate:  0.13942235843603729 ,RMSE_Predict_Validate:  0.03798120810509224\n",
      "IMF number is:  2 , neuron number is:  7 , RMSE_Test:  0.1421657923108667 ,RMSE_Predict_Test:  0.043786398264984705\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "IMF number is:  2 , neuron number is:  7 , RMSE_Predict_Validate_Min:  0.03798120810509224\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "IMF number is:  2 , neuron number is:  8 , RMSE_Train:  0.14884765205342124 ,RMSE_Predict_Train:  0.036745202975012874\n",
      "IMF number is:  2 , neuron number is:  8 , RMSE_Validate:  0.13942235843603729 ,RMSE_Predict_Validate:  0.039133185238988275\n",
      "IMF number is:  2 , neuron number is:  8 , RMSE_Test:  0.1421657923108667 ,RMSE_Predict_Test:  0.04372515972184131\n",
      "IMF number is:  2 , neuron number is:  9 , RMSE_Train:  0.14884765205342124 ,RMSE_Predict_Train:  0.03577056415076857\n",
      "IMF number is:  2 , neuron number is:  9 , RMSE_Validate:  0.13942235843603729 ,RMSE_Predict_Validate:  0.038718228270634314\n",
      "IMF number is:  2 , neuron number is:  9 , RMSE_Test:  0.1421657923108667 ,RMSE_Predict_Test:  0.04217569205260248\n",
      "IMF number is:  2 , neuron number is:  10 , RMSE_Train:  0.14884765205342124 ,RMSE_Predict_Train:  0.0372009351949985\n",
      "IMF number is:  2 , neuron number is:  10 , RMSE_Validate:  0.13942235843603729 ,RMSE_Predict_Validate:  0.03894847034653248\n",
      "IMF number is:  2 , neuron number is:  10 , RMSE_Test:  0.1421657923108667 ,RMSE_Predict_Test:  0.04307966989501853\n",
      "IMF number is:  2 , neuron number is:  11 , RMSE_Train:  0.14884765205342124 ,RMSE_Predict_Train:  0.0352443111710615\n",
      "IMF number is:  2 , neuron number is:  11 , RMSE_Validate:  0.13942235843603729 ,RMSE_Predict_Validate:  0.039271297786302284\n",
      "IMF number is:  2 , neuron number is:  11 , RMSE_Test:  0.1421657923108667 ,RMSE_Predict_Test:  0.042960631234096235\n",
      "IMF number is:  2 , neuron number is:  12 , RMSE_Train:  0.14884765205342124 ,RMSE_Predict_Train:  0.03549033933269839\n",
      "IMF number is:  2 , neuron number is:  12 , RMSE_Validate:  0.13942235843603729 ,RMSE_Predict_Validate:  0.03932669882671721\n",
      "IMF number is:  2 , neuron number is:  12 , RMSE_Test:  0.1421657923108667 ,RMSE_Predict_Test:  0.0425903715127451\n",
      "IMF number is:  2 , neuron number is:  13 , RMSE_Train:  0.14884765205342124 ,RMSE_Predict_Train:  0.03498714130897002\n",
      "IMF number is:  2 , neuron number is:  13 , RMSE_Validate:  0.13942235843603729 ,RMSE_Predict_Validate:  0.040185442913259574\n",
      "IMF number is:  2 , neuron number is:  13 , RMSE_Test:  0.1421657923108667 ,RMSE_Predict_Test:  0.04331698821505026\n",
      "IMF number is:  2 , neuron number is:  14 , RMSE_Train:  0.14884765205342124 ,RMSE_Predict_Train:  0.03513026034278204\n",
      "IMF number is:  2 , neuron number is:  14 , RMSE_Validate:  0.13942235843603729 ,RMSE_Predict_Validate:  0.039407235405137915\n",
      "IMF number is:  2 , neuron number is:  14 , RMSE_Test:  0.1421657923108667 ,RMSE_Predict_Test:  0.043924748867733655\n",
      "IMF number is:  3 , neuron number is:  6 , RMSE_Train:  0.08699102232413476 ,RMSE_Predict_Train:  0.06390498050098645\n",
      "IMF number is:  3 , neuron number is:  6 , RMSE_Validate:  0.0716012790126711 ,RMSE_Predict_Validate:  0.07191295878064824\n",
      "IMF number is:  3 , neuron number is:  6 , RMSE_Test:  0.07201361675463558 ,RMSE_Predict_Test:  0.055581341788576925\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "IMF number is:  3 , neuron number is:  6 , RMSE_Predict_Validate_Min:  0.07191295878064824\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "IMF number is:  3 , neuron number is:  7 , RMSE_Train:  0.08699102232413476 ,RMSE_Predict_Train:  0.06331733051562444\n",
      "IMF number is:  3 , neuron number is:  7 , RMSE_Validate:  0.0716012790126711 ,RMSE_Predict_Validate:  0.07350419824016007\n",
      "IMF number is:  3 , neuron number is:  7 , RMSE_Test:  0.07201361675463558 ,RMSE_Predict_Test:  0.05667608982274726\n",
      "IMF number is:  3 , neuron number is:  8 , RMSE_Train:  0.08699102232413476 ,RMSE_Predict_Train:  0.06344912727235585\n",
      "IMF number is:  3 , neuron number is:  8 , RMSE_Validate:  0.0716012790126711 ,RMSE_Predict_Validate:  0.07249713311374541\n",
      "IMF number is:  3 , neuron number is:  8 , RMSE_Test:  0.07201361675463558 ,RMSE_Predict_Test:  0.05557854731265653\n",
      "IMF number is:  3 , neuron number is:  9 , RMSE_Train:  0.08699102232413476 ,RMSE_Predict_Train:  0.0635841567140715\n",
      "IMF number is:  3 , neuron number is:  9 , RMSE_Validate:  0.0716012790126711 ,RMSE_Predict_Validate:  0.07203574943729578\n",
      "IMF number is:  3 , neuron number is:  9 , RMSE_Test:  0.07201361675463558 ,RMSE_Predict_Test:  0.05557823383028252\n",
      "IMF number is:  3 , neuron number is:  10 , RMSE_Train:  0.08699102232413476 ,RMSE_Predict_Train:  0.06338207015162124\n",
      "IMF number is:  3 , neuron number is:  10 , RMSE_Validate:  0.0716012790126711 ,RMSE_Predict_Validate:  0.0758757948108661\n",
      "IMF number is:  3 , neuron number is:  10 , RMSE_Test:  0.07201361675463558 ,RMSE_Predict_Test:  0.05766346435458527\n",
      "IMF number is:  3 , neuron number is:  11 , RMSE_Train:  0.08699102232413476 ,RMSE_Predict_Train:  0.06339914954608732\n",
      "IMF number is:  3 , neuron number is:  11 , RMSE_Validate:  0.0716012790126711 ,RMSE_Predict_Validate:  0.07440530820092951\n",
      "IMF number is:  3 , neuron number is:  11 , RMSE_Test:  0.07201361675463558 ,RMSE_Predict_Test:  0.05608722364464923\n",
      "IMF number is:  3 , neuron number is:  12 , RMSE_Train:  0.08699102232413476 ,RMSE_Predict_Train:  0.06384446825213458\n",
      "IMF number is:  3 , neuron number is:  12 , RMSE_Validate:  0.0716012790126711 ,RMSE_Predict_Validate:  0.07220052970803106\n",
      "IMF number is:  3 , neuron number is:  12 , RMSE_Test:  0.07201361675463558 ,RMSE_Predict_Test:  0.055838563601879186\n",
      "IMF number is:  3 , neuron number is:  13 , RMSE_Train:  0.08699102232413476 ,RMSE_Predict_Train:  0.06347591247868176\n",
      "IMF number is:  3 , neuron number is:  13 , RMSE_Validate:  0.0716012790126711 ,RMSE_Predict_Validate:  0.07332811746148613\n",
      "IMF number is:  3 , neuron number is:  13 , RMSE_Test:  0.07201361675463558 ,RMSE_Predict_Test:  0.05558056029644047\n",
      "IMF number is:  3 , neuron number is:  14 , RMSE_Train:  0.08699102232413476 ,RMSE_Predict_Train:  0.06308153426854535\n",
      "IMF number is:  3 , neuron number is:  14 , RMSE_Validate:  0.0716012790126711 ,RMSE_Predict_Validate:  0.07421209664652081\n",
      "IMF number is:  3 , neuron number is:  14 , RMSE_Test:  0.07201361675463558 ,RMSE_Predict_Test:  0.05654914863298152\n",
      "IMF number is:  4 , neuron number is:  6 , RMSE_Train:  0.05385710886902144 ,RMSE_Predict_Train:  0.03738166247159664\n",
      "IMF number is:  4 , neuron number is:  6 , RMSE_Validate:  0.06684103053584656 ,RMSE_Predict_Validate:  0.04324662549513336\n",
      "IMF number is:  4 , neuron number is:  6 , RMSE_Test:  0.06112589063336275 ,RMSE_Predict_Test:  0.0378319479653236\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "IMF number is:  4 , neuron number is:  6 , RMSE_Predict_Validate_Min:  0.04324662549513336\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "IMF number is:  4 , neuron number is:  7 , RMSE_Train:  0.05385710886902144 ,RMSE_Predict_Train:  0.03683425350656739\n",
      "IMF number is:  4 , neuron number is:  7 , RMSE_Validate:  0.06684103053584656 ,RMSE_Predict_Validate:  0.04162305536971459\n",
      "IMF number is:  4 , neuron number is:  7 , RMSE_Test:  0.06112589063336275 ,RMSE_Predict_Test:  0.036832629702241264\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "IMF number is:  4 , neuron number is:  7 , RMSE_Predict_Validate_Min:  0.04162305536971459\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "IMF number is:  4 , neuron number is:  8 , RMSE_Train:  0.05385710886902144 ,RMSE_Predict_Train:  0.036440343890369736\n",
      "IMF number is:  4 , neuron number is:  8 , RMSE_Validate:  0.06684103053584656 ,RMSE_Predict_Validate:  0.038811205828380664\n",
      "IMF number is:  4 , neuron number is:  8 , RMSE_Test:  0.06112589063336275 ,RMSE_Predict_Test:  0.03601133488028817\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "IMF number is:  4 , neuron number is:  8 , RMSE_Predict_Validate_Min:  0.038811205828380664\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "IMF number is:  4 , neuron number is:  9 , RMSE_Train:  0.05385710886902144 ,RMSE_Predict_Train:  0.03655604593171161\n",
      "IMF number is:  4 , neuron number is:  9 , RMSE_Validate:  0.06684103053584656 ,RMSE_Predict_Validate:  0.039505266534922645\n",
      "IMF number is:  4 , neuron number is:  9 , RMSE_Test:  0.06112589063336275 ,RMSE_Predict_Test:  0.03598162498664319\n",
      "IMF number is:  4 , neuron number is:  10 , RMSE_Train:  0.05385710886902144 ,RMSE_Predict_Train:  0.036852788629389066\n",
      "IMF number is:  4 , neuron number is:  10 , RMSE_Validate:  0.06684103053584656 ,RMSE_Predict_Validate:  0.04294078226324113\n",
      "IMF number is:  4 , neuron number is:  10 , RMSE_Test:  0.06112589063336275 ,RMSE_Predict_Test:  0.036331936433178696\n",
      "IMF number is:  4 , neuron number is:  11 , RMSE_Train:  0.05385710886902144 ,RMSE_Predict_Train:  0.036386799825961616\n",
      "IMF number is:  4 , neuron number is:  11 , RMSE_Validate:  0.06684103053584656 ,RMSE_Predict_Validate:  0.04012585981524704\n",
      "IMF number is:  4 , neuron number is:  11 , RMSE_Test:  0.06112589063336275 ,RMSE_Predict_Test:  0.03453710506853119\n",
      "IMF number is:  4 , neuron number is:  12 , RMSE_Train:  0.05385710886902144 ,RMSE_Predict_Train:  0.0363539747180844\n",
      "IMF number is:  4 , neuron number is:  12 , RMSE_Validate:  0.06684103053584656 ,RMSE_Predict_Validate:  0.039778258831315624\n",
      "IMF number is:  4 , neuron number is:  12 , RMSE_Test:  0.06112589063336275 ,RMSE_Predict_Test:  0.033038236011099335\n",
      "IMF number is:  4 , neuron number is:  13 , RMSE_Train:  0.05385710886902144 ,RMSE_Predict_Train:  0.03624807061688797\n",
      "IMF number is:  4 , neuron number is:  13 , RMSE_Validate:  0.06684103053584656 ,RMSE_Predict_Validate:  0.03892356972427744\n",
      "IMF number is:  4 , neuron number is:  13 , RMSE_Test:  0.06112589063336275 ,RMSE_Predict_Test:  0.034354329134290554\n",
      "IMF number is:  4 , neuron number is:  14 , RMSE_Train:  0.05385710886902144 ,RMSE_Predict_Train:  0.036320802212665926\n",
      "IMF number is:  4 , neuron number is:  14 , RMSE_Validate:  0.06684103053584656 ,RMSE_Predict_Validate:  0.039692842956220956\n",
      "IMF number is:  4 , neuron number is:  14 , RMSE_Test:  0.06112589063336275 ,RMSE_Predict_Test:  0.03330649361702906\n",
      "IMF number is:  5 , neuron number is:  6 , RMSE_Train:  0.04288220055201644 ,RMSE_Predict_Train:  0.024437514775565626\n",
      "IMF number is:  5 , neuron number is:  6 , RMSE_Validate:  0.05303170451281651 ,RMSE_Predict_Validate:  0.03162523547210121\n",
      "IMF number is:  5 , neuron number is:  6 , RMSE_Test:  0.027139481426111296 ,RMSE_Predict_Test:  0.02523356226102463\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "IMF number is:  5 , neuron number is:  6 , RMSE_Predict_Validate_Min:  0.03162523547210121\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "IMF number is:  5 , neuron number is:  7 , RMSE_Train:  0.04288220055201644 ,RMSE_Predict_Train:  0.023838822196450463\n",
      "IMF number is:  5 , neuron number is:  7 , RMSE_Validate:  0.05303170451281651 ,RMSE_Predict_Validate:  0.031674744848899906\n",
      "IMF number is:  5 , neuron number is:  7 , RMSE_Test:  0.027139481426111296 ,RMSE_Predict_Test:  0.025476392008275194\n",
      "IMF number is:  5 , neuron number is:  8 , RMSE_Train:  0.04288220055201644 ,RMSE_Predict_Train:  0.025366983055150442\n",
      "IMF number is:  5 , neuron number is:  8 , RMSE_Validate:  0.05303170451281651 ,RMSE_Predict_Validate:  0.03249807530853627\n",
      "IMF number is:  5 , neuron number is:  8 , RMSE_Test:  0.027139481426111296 ,RMSE_Predict_Test:  0.02786837495043075\n",
      "IMF number is:  5 , neuron number is:  9 , RMSE_Train:  0.04288220055201644 ,RMSE_Predict_Train:  0.024108146603409996\n",
      "IMF number is:  5 , neuron number is:  9 , RMSE_Validate:  0.05303170451281651 ,RMSE_Predict_Validate:  0.03179126535318627\n",
      "IMF number is:  5 , neuron number is:  9 , RMSE_Test:  0.027139481426111296 ,RMSE_Predict_Test:  0.024476961546768313\n",
      "IMF number is:  5 , neuron number is:  10 , RMSE_Train:  0.04288220055201644 ,RMSE_Predict_Train:  0.02423646706968378\n",
      "IMF number is:  5 , neuron number is:  10 , RMSE_Validate:  0.05303170451281651 ,RMSE_Predict_Validate:  0.03169541956719318\n",
      "IMF number is:  5 , neuron number is:  10 , RMSE_Test:  0.027139481426111296 ,RMSE_Predict_Test:  0.024289409447614117\n",
      "IMF number is:  5 , neuron number is:  11 , RMSE_Train:  0.04288220055201644 ,RMSE_Predict_Train:  0.023981202902461942\n",
      "IMF number is:  5 , neuron number is:  11 , RMSE_Validate:  0.05303170451281651 ,RMSE_Predict_Validate:  0.031166360749792926\n",
      "IMF number is:  5 , neuron number is:  11 , RMSE_Test:  0.027139481426111296 ,RMSE_Predict_Test:  0.02392566265374172\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "IMF number is:  5 , neuron number is:  11 , RMSE_Predict_Validate_Min:  0.031166360749792926\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "IMF number is:  5 , neuron number is:  12 , RMSE_Train:  0.04288220055201644 ,RMSE_Predict_Train:  0.02414359794015975\n",
      "IMF number is:  5 , neuron number is:  12 , RMSE_Validate:  0.05303170451281651 ,RMSE_Predict_Validate:  0.03121013915426924\n",
      "IMF number is:  5 , neuron number is:  12 , RMSE_Test:  0.027139481426111296 ,RMSE_Predict_Test:  0.023543066739226667\n",
      "IMF number is:  5 , neuron number is:  13 , RMSE_Train:  0.04288220055201644 ,RMSE_Predict_Train:  0.024227799293933608\n",
      "IMF number is:  5 , neuron number is:  13 , RMSE_Validate:  0.05303170451281651 ,RMSE_Predict_Validate:  0.031380663929323004\n",
      "IMF number is:  5 , neuron number is:  13 , RMSE_Test:  0.027139481426111296 ,RMSE_Predict_Test:  0.02361365314475762\n",
      "IMF number is:  5 , neuron number is:  14 , RMSE_Train:  0.04288220055201644 ,RMSE_Predict_Train:  0.024019329256550346\n",
      "IMF number is:  5 , neuron number is:  14 , RMSE_Validate:  0.05303170451281651 ,RMSE_Predict_Validate:  0.03120863581571458\n",
      "IMF number is:  5 , neuron number is:  14 , RMSE_Test:  0.027139481426111296 ,RMSE_Predict_Test:  0.024454685738423066\n",
      "IMF number is:  6 , neuron number is:  6 , RMSE_Train:  0.04777263812752444 ,RMSE_Predict_Train:  0.017888609463246965\n",
      "IMF number is:  6 , neuron number is:  6 , RMSE_Validate:  0.052455634577940634 ,RMSE_Predict_Validate:  0.01911580175437408\n",
      "IMF number is:  6 , neuron number is:  6 , RMSE_Test:  0.04802122450373484 ,RMSE_Predict_Test:  0.02084977413415991\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "IMF number is:  6 , neuron number is:  6 , RMSE_Predict_Validate_Min:  0.01911580175437408\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "IMF number is:  6 , neuron number is:  7 , RMSE_Train:  0.04777263812752444 ,RMSE_Predict_Train:  0.018202400940027515\n",
      "IMF number is:  6 , neuron number is:  7 , RMSE_Validate:  0.052455634577940634 ,RMSE_Predict_Validate:  0.024793642078116858\n",
      "IMF number is:  6 , neuron number is:  7 , RMSE_Test:  0.04802122450373484 ,RMSE_Predict_Test:  0.019976102816880115\n",
      "IMF number is:  6 , neuron number is:  8 , RMSE_Train:  0.04777263812752444 ,RMSE_Predict_Train:  0.022851374235794846\n",
      "IMF number is:  6 , neuron number is:  8 , RMSE_Validate:  0.052455634577940634 ,RMSE_Predict_Validate:  0.026062378694547812\n",
      "IMF number is:  6 , neuron number is:  8 , RMSE_Test:  0.04802122450373484 ,RMSE_Predict_Test:  0.02647362854107893\n",
      "IMF number is:  6 , neuron number is:  9 , RMSE_Train:  0.04777263812752444 ,RMSE_Predict_Train:  0.022932784114719974\n",
      "IMF number is:  6 , neuron number is:  9 , RMSE_Validate:  0.052455634577940634 ,RMSE_Predict_Validate:  0.030249486458075927\n",
      "IMF number is:  6 , neuron number is:  9 , RMSE_Test:  0.04802122450373484 ,RMSE_Predict_Test:  0.025320527690526444\n",
      "IMF number is:  6 , neuron number is:  10 , RMSE_Train:  0.04777263812752444 ,RMSE_Predict_Train:  0.019325480875623413\n",
      "IMF number is:  6 , neuron number is:  10 , RMSE_Validate:  0.052455634577940634 ,RMSE_Predict_Validate:  0.025902537379153615\n",
      "IMF number is:  6 , neuron number is:  10 , RMSE_Test:  0.04802122450373484 ,RMSE_Predict_Test:  0.02280800893875107\n",
      "IMF number is:  6 , neuron number is:  11 , RMSE_Train:  0.04777263812752444 ,RMSE_Predict_Train:  0.018777601692570065\n",
      "IMF number is:  6 , neuron number is:  11 , RMSE_Validate:  0.052455634577940634 ,RMSE_Predict_Validate:  0.024355098866649952\n",
      "IMF number is:  6 , neuron number is:  11 , RMSE_Test:  0.04802122450373484 ,RMSE_Predict_Test:  0.01943031935003637\n",
      "IMF number is:  6 , neuron number is:  12 , RMSE_Train:  0.04777263812752444 ,RMSE_Predict_Train:  0.014654574028058328\n",
      "IMF number is:  6 , neuron number is:  12 , RMSE_Validate:  0.052455634577940634 ,RMSE_Predict_Validate:  0.016894702295045\n",
      "IMF number is:  6 , neuron number is:  12 , RMSE_Test:  0.04802122450373484 ,RMSE_Predict_Test:  0.01477184271808534\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "IMF number is:  6 , neuron number is:  12 , RMSE_Predict_Validate_Min:  0.016894702295045\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "IMF number is:  6 , neuron number is:  13 , RMSE_Train:  0.04777263812752444 ,RMSE_Predict_Train:  0.01148772739915234\n",
      "IMF number is:  6 , neuron number is:  13 , RMSE_Validate:  0.052455634577940634 ,RMSE_Predict_Validate:  0.014736668410235803\n",
      "IMF number is:  6 , neuron number is:  13 , RMSE_Test:  0.04802122450373484 ,RMSE_Predict_Test:  0.012162078651104555\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "IMF number is:  6 , neuron number is:  13 , RMSE_Predict_Validate_Min:  0.014736668410235803\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "IMF number is:  6 , neuron number is:  14 , RMSE_Train:  0.04777263812752444 ,RMSE_Predict_Train:  0.010308767654125174\n",
      "IMF number is:  6 , neuron number is:  14 , RMSE_Validate:  0.052455634577940634 ,RMSE_Predict_Validate:  0.012953452198520756\n",
      "IMF number is:  6 , neuron number is:  14 , RMSE_Test:  0.04802122450373484 ,RMSE_Predict_Test:  0.009571202881115513\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "IMF number is:  6 , neuron number is:  14 , RMSE_Predict_Validate_Min:  0.012953452198520756\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "spend time is  2.037336826324463s\n",
      "Neuron_Predict_All : [ 9.  7.  6.  8. 11. 14.]\n"
     ]
    }
   ],
   "source": [
    "starttime = time.time()\n",
    "for n in range(6):\n",
    "    ## 归一化\n",
    "    # 训练集\n",
    "    Scaler_Input = MinMaxScaler(feature_range = (-1, 1) ) # 初始化输入的MinMaxScaler对象\n",
    "    Input_Train_Scaler[n,:,:] = Scaler_Input.fit_transform(IMFs_Historical_Compose_3D_Train[n,:,:]) # 输入训练集归一化数组\n",
    "    Scaler_Output = MinMaxScaler(feature_range = (-1, 1) ) # 初始化输出的MinMaxScaler对象\n",
    "    Output_Train_Scaler[n,:,:] = Scaler_Output.fit_transform(IMFs_ERSST_Compose_3D_Train[n,:,:]) # 输出训练集归一化数组\n",
    "    Input_Validate_Scaler[n,:,:] = Scaler_Input.transform(IMFs_Historical_Compose_3D_Validate[n,:,:])  # 依据训练集最大最小值，对输入验证集归一化\n",
    "    Input_Test_Scaler[n,:,:] = Scaler_Input.transform(IMFs_Historical_Compose_3D_Test[n,:,:])  # 依据训练集最大最小值，对输入测试集归一化\n",
    "    Input_Forecast126_Scaler[n,:,:] =  Scaler_Input.transform(IMFs_SSP126_Compose_3D[n,:,:]) # 依据训练集最大最小值，对输入未来预估低排放数据集归一化\n",
    "    Input_Forecast245_Scaler[n,:,:] =  Scaler_Input.transform(IMFs_SSP245_Compose_3D[n,:,:]) # 依据训练集最大最小值，对输入未来预估中等排放数据集归一化\n",
    "    Input_Forecast585_Scaler[n,:,:] =  Scaler_Input.transform(IMFs_SSP585_Compose_3D[n,:,:]) # 依据训练集最大最小值，对输入未来预估高排放数据集归一化\n",
    "\n",
    "    ## 训练模型，尝试不同隐层神经元\n",
    "    for number in range(6,15):  # 从6到15对隐藏层神经元调试\n",
    "        # 建立模型\n",
    "        Model_MLPR = MLPRegressor(solver = 'sgd',  # 权重优化的求解器，选择的是随机梯度下降法\n",
    "                                  activation = 'relu',  # 隐藏层的激活函数，选择relu函数\n",
    "                                  alpha = 1e-4, # L2惩罚（正则项）参数\n",
    "                                  learning_rate_init = 0.01, # 使用的初始学习率。\n",
    "                                  max_iter = 200, # 最大迭代次数。\n",
    "                                  hidden_layer_sizes = (number), # 隐藏层神经元数目\n",
    "                                  random_state = 1  ) # 决定用于权重和偏差初始化的随机数生成\n",
    "        # 训练网络\n",
    "        Model_MLPR.fit( Input_Train_Scaler[n,:,:], Output_Train_Scaler[n,:,:] )  # 输入: (样本条数, 输入层神经元数); 输出：(样本条数, 输出层神经元数)\n",
    "        Predict_Train_Scaler = Model_MLPR.predict(Input_Train_Scaler[n, :, :])  # (训练样本年份数, 输入神经元数)\n",
    "        # 反归一化\n",
    "        Predict_Train_Real = Scaler_Output.inverse_transform( Predict_Train_Scaler )   # (训练样本年份数, 输入神经元数)\n",
    "        Predict_Train_Real_1D = Predict_Train_Real.reshape(-1)   # (训练样本月份数, )\n",
    "        # 计算训练RMSE\n",
    "        RMSE_Train = rmse(IMFs_Historical_Compose_2D_Train[n, :], IMFs_ERSST_Compose_2D_Train[n,:] )\n",
    "        RMSE_Predict_Train_All[n, number-6] = rmse(Predict_Train_Real_1D, IMFs_ERSST_Compose_2D_Train[n,:] )\n",
    "        print('IMF number is: ', n + 1, ', neuron number is: ',number,  ', RMSE_Train: ', RMSE_Train, ',RMSE_Predict_Train: ', RMSE_Predict_Train_All[n, number-6])\n",
    "       \n",
    "        ## 验证集\n",
    "        Predict_Validate_Scaler = Model_MLPR.predict(Input_Validate_Scaler[n, :, :])  # (验证样本年份数,输出层神经元数 )\n",
    "        # 反归一化\n",
    "        Predict_Validate_Real = Scaler_Output.inverse_transform( Predict_Validate_Scaler )   # (验证样本年份数, 输出层神经元数)\n",
    "        Predict_Validate_Real_1D = Predict_Validate_Real.reshape(-1)  # (验证样本月份数, )\n",
    "        # 计算验证集RMSE\n",
    "        RMSE_Validate = rmse(IMFs_Historical_Compose_2D_Validate[n, :], IMFs_ERSST_Compose_2D_Validate[n,:] )\n",
    "        RMSE_Predict_Validate_All[n, number - 6] = rmse(Predict_Validate_Real_1D, IMFs_ERSST_Compose_2D_Validate[n, :])\n",
    "        print('IMF number is: ', n + 1, ', neuron number is: ',number, ', RMSE_Validate: ', RMSE_Validate, ',RMSE_Predict_Validate: ', RMSE_Predict_Validate_All[n, number-6])\n",
    "        \n",
    "        ## 测试集\n",
    "        Predict_Test_Scaler = Model_MLPR.predict(Input_Test_Scaler[n, :, :])  # (测试样本年份数, 输出层神经元数)\n",
    "        # 反归一化\n",
    "        Predict_Test_Real = Scaler_Output.inverse_transform(Predict_Test_Scaler)  # (测试样本年份数, 输出层神经元数)\n",
    "        Predict_Test_Real_1D = Predict_Test_Real.reshape(-1)  # (测试样本月份数, )\n",
    "        # 计算测试集RMSE\n",
    "        RMSE_Test = rmse(IMFs_Historical_Compose_2D_Test[n, :], IMFs_ERSST_Compose_2D_Test[n, :])\n",
    "        RMSE_Predict_Test_All[n, number - 6] = rmse(Predict_Test_Real_1D, IMFs_ERSST_Compose_2D_Test[n, :])\n",
    "        print('IMF number is: ', n + 1, ', neuron number is: ',number,  ', RMSE_Test: ', RMSE_Test, ',RMSE_Predict_Test: ', RMSE_Predict_Test_All[n, number - 6])\n",
    "        \n",
    "        ## SSP：未来预估订正\n",
    "        Predict_SSP126_Scaler = Model_MLPR.predict(Input_Forecast126_Scaler[n, :, :])  # (未来预估年份数, 输出层神经元数)\n",
    "        Predict_SSP245_Scaler = Model_MLPR.predict(Input_Forecast245_Scaler[n, :, :])  # (未来预估年份数, 输出层神经元数)\n",
    "        Predict_SSP585_Scaler = Model_MLPR.predict(Input_Forecast585_Scaler[n, :, :])  # (未来预估年份数, 输出层神经元数)\n",
    "        # 反归一化\n",
    "        Predict_SSP126_Real = Scaler_Output.inverse_transform(Predict_SSP126_Scaler)  # (未来预估年份数, 输出层神经元数)\n",
    "        Predict_SSP245_Real = Scaler_Output.inverse_transform(Predict_SSP245_Scaler)  # (未来预估年份数, 输出层神经元数)\n",
    "        Predict_SSP585_Real = Scaler_Output.inverse_transform(Predict_SSP585_Scaler)  # (未来预估年份数, 输出层神经元数)\n",
    "\n",
    "        ## 找到验证集最小的RMSE及其对应的隐层神经元数，以保存所有集合的订正结果\n",
    "        if number == 6:\n",
    "            RMSE_Predict_Validate_Min = rmse(Predict_Validate_Real_1D, IMFs_ERSST_Compose_2D_Validate[n, :] )\n",
    "            print('--------------------------------------------------------------------------------------------------------------------------------')\n",
    "            print('IMF number is: ', n + 1, ', neuron number is: ',number,  ', RMSE_Predict_Validate_Min: ', RMSE_Predict_Validate_Min)\n",
    "            print('--------------------------------------------------------------------------------------------------------------------------------')\n",
    "            Neuron_Predict_All[n] = number # 保存隐藏层神经元数，由于6是第一个测试数据，先当作误差最小时的保存下来，后面遇到误差更小的再把6替换\n",
    "            BP_Output_Train[n,:,:] = Predict_Train_Real # 保存模型预测的就是订正的结果\n",
    "            BP_Output_Validate[n,:,:] = Predict_Validate_Real # 保存验证集\n",
    "            BP_Output_Test[n,:,:] = Predict_Test_Real # 保存测试集\n",
    "            BP_Output_SSP126[n,:,:] = Predict_SSP126_Real # 保存未来预估的低排放情景ssp1-2.6\n",
    "            BP_Output_SSP245[n,:,:] = Predict_SSP245_Real # 保存未来预估的中等排放情景ssp2-4.5\n",
    "            BP_Output_SSP585[n,:,:] = Predict_SSP585_Real  # 保存未来预估的高排放情景ssp5-8.5\n",
    "            exec('Model_MLPR_IMF_%s = Model_MLPR'%(n + 1) )\n",
    "            exec(\"pickle.dump(Model_MLPR_IMF_%s, open(Path_SaveModel + 'Model_MLPR_IMF_%s', 'wb') )\"%(n + 1, n + 1) )\n",
    "        elif number >= 7: # 开始对大于6的隐层判断误差是否有比之前更小的\n",
    "            RMSE_Predict_Validate_Current = rmse(Predict_Validate_Real_1D, IMFs_ERSST_Compose_2D_Validate[n, :] )\n",
    "            if RMSE_Predict_Validate_Current < RMSE_Predict_Validate_Min: # 如果当前验证集误差比已经存在的最小误差更小，那就替换成最小误差\n",
    "                RMSE_Predict_Validate_Min = RMSE_Predict_Validate_Current\n",
    "                print('--------------------------------------------------------------------------------------------------------------------------------')\n",
    "                print('IMF number is: ', n + 1, ', neuron number is: ', number, ', RMSE_Predict_Validate_Min: ', RMSE_Predict_Validate_Min)\n",
    "                print('--------------------------------------------------------------------------------------------------------------------------------')\n",
    "                Neuron_Predict_All[n] = number # 记录替换后的隐藏层神经元数目\n",
    "                BP_Output_Train[n, :, :] = Predict_Train_Real\n",
    "                BP_Output_Validate[n, :, :] = Predict_Validate_Real\n",
    "                BP_Output_Test[n, :, :] = Predict_Test_Real\n",
    "                BP_Output_SSP126[n, :, :] = Predict_SSP126_Real\n",
    "                BP_Output_SSP245[n, :, :] = Predict_SSP245_Real\n",
    "                BP_Output_SSP585[n, :, :] = Predict_SSP585_Real\n",
    "                exec('Model_MLPR_IMF_%s = Model_MLPR' % (n + 1))\n",
    "                exec(\"pickle.dump(Model_MLPR_IMF_%s, open(Path_SaveModel + 'Model_MLPR_IMF_%s', 'wb') )\"%(n + 1, n + 1) )\n",
    "\n",
    "\n",
    "endtime = time.time()\n",
    "print('spend time is ', str(endtime - starttime) + \"s\")\n",
    "print('Neuron_Predict_All :', Neuron_Predict_All)  # 打印输出各个组合最佳隐层数目"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "62EB569918164B7780FFCAE30018B4A1",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 5.2.6 处理模型输出数据并保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "id": "4E850A801BAB427284E37C0C0C56395F",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./project/SaveData/Model/ successfully build!\n"
     ]
    }
   ],
   "source": [
    "# 按时间顺序重新排列修正数据\n",
    "BP_Output_All = np.zeros(IMFs_ERSST_Compose_3D.shape)\n",
    "BP_Output_All[:, 0:Num_Year_Train, :] = BP_Output_Train\n",
    "BP_Output_All[:, Num_Year_Train:Num_Year_Train +\n",
    "              Num_Year_Validate, :] = BP_Output_Validate\n",
    "BP_Output_All[:, -Num_Year_Test::, :] = BP_Output_Test\n",
    "\n",
    "BP_Output_All_Chronological = np.zeros(IMFs_ERSST_Compose_3D.shape)\n",
    "for n in range(Num_Year):\n",
    "    Index_Year_Real = Index_Year_Random[n]\n",
    "    BP_Output_All_Chronological[:, Index_Year_Real, :] = BP_Output_All[:, n, :]\n",
    "\n",
    "# 保存数据\n",
    "Path_Pre = './project/SaveData/'\n",
    "Path_SaveModelData = Path_Pre + 'Model/'\n",
    "isExists = os.path.exists(Path_SaveModelData)\n",
    "if not isExists:\n",
    "    os.makedirs(Path_Pre + 'Model/')\n",
    "    print(Path_SaveModelData + ' successfully build!')\n",
    "else:\n",
    "    print(Path_SaveModelData + ' has been existed!')\n",
    "\n",
    "np.save(\n",
    "    Path_SaveModelData +\n",
    "    'BP_Output_All_Chronological.npy',\n",
    "    BP_Output_All_Chronological)\n",
    "np.save(Path_SaveModelData + 'BP_Output_SSP126.npy', BP_Output_SSP126)\n",
    "np.save(Path_SaveModelData + 'BP_Output_SSP245.npy', BP_Output_SSP245)\n",
    "np.save(Path_SaveModelData + 'BP_Output_SSP585.npy', BP_Output_SSP585)\n",
    "\n",
    "# 加载模型，可不运行，后续不再调用模型了。\n",
    "# for n in range(6):\n",
    "# exec(\"Model_MLPR_IMF_%s = pickle.load( open(Path_SaveModel + 'Model_MLPR_IMF_%s', 'rb') )\" % (n + 1, n + 1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31409DA046D94AC68D002B111FAFC185",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "\n",
    "## 5.3 BPNN订正结果分析\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "83AB7B7C3FDC419995767657AA050E1E",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 5.3.1 导入数据\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FFFBF6E32CED4A278D211F6AC13C2E84",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**原始数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "id": "519D4C7F51B24C5F8E5AA04CB94C9B3A",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Path_SaveData_Original = './project/SaveData/Original/'\n",
    "SST_ERSST_AreaMean = np.load(Path_SaveData_Original + 'SST_ERSST_AreaMean.npy')\n",
    "SST_Historical_AreaMean = np.load(\n",
    "    Path_SaveData_Original +\n",
    "    'SST_Historical_AreaMean.npy')\n",
    "SST_SSP126 = np.load(Path_SaveData_Original + 'SST_SSP126_AreaMean.npy')\n",
    "SST_SSP245 = np.load(Path_SaveData_Original + 'SST_SSP245_AreaMean.npy')\n",
    "SST_SSP585 = np.load(Path_SaveData_Original + 'SST_SSP585_AreaMean.npy')\n",
    "Time_ERSST = np.load(Path_SaveData_Original + 'Time_ERSST.npy')\n",
    "Time_SSP = np.load(Path_SaveData_Original + 'Time_SSP.npy')\n",
    "# 数据集划分\n",
    "Num_Year = 86\n",
    "Num_Year_Train = 70\n",
    "Num_Year_Validate = 8\n",
    "Num_Year_Test = 8\n",
    "Num_Sample_SST = Num_Year*12\n",
    "Num_Sample_Train = Num_Year_Train*12\n",
    "Num_Sample_Validate = Num_Year_Validate*12\n",
    "Num_Sample_Test = Num_Year_Test*12\n",
    "Time_SST = np.arange(0, Num_Sample_SST)\n",
    "Time_ERSST = Time_ERSST[-Num_Sample_SST::]\n",
    "SST_ERSST = SST_ERSST_AreaMean[-Num_Sample_SST::]\n",
    "SST_Historical = SST_Historical_AreaMean[-Num_Sample_SST::]\n",
    "SST_ERSST_2D = SST_ERSST.reshape((Num_Year, 12))\n",
    "SST_Historical_2D = SST_Historical.reshape((Num_Year, 12))\n",
    "# 随机数\n",
    "random.seed(1)\n",
    "Index_Year = list(range(Num_Year))\n",
    "Index_Year_Random = list(range(Num_Year))\n",
    "random.shuffle(Index_Year_Random)\n",
    "Index_Year_Train = Index_Year_Random[0:Num_Year_Train]\n",
    "Index_Year_Validate = Index_Year_Random[Num_Year_Train:Num_Year_Train +\n",
    "                                        Num_Year_Validate]\n",
    "Index_Year_Test = Index_Year_Random[-Num_Year_Test::]\n",
    "# 原始数据：2维（年份数，12）\n",
    "SST_ERSST_Train_2D = SST_ERSST_2D[Index_Year_Train, :]\n",
    "SST_ERSST_Validate_2D = SST_ERSST_2D[Index_Year_Validate, :]\n",
    "SST_ERSST_Test_2D = SST_ERSST_2D[Index_Year_Test, :]\n",
    "SST_Historical_Train_2D = SST_Historical_2D[Index_Year_Train, :]\n",
    "SST_Historical_Validate_2D = SST_Historical_2D[Index_Year_Validate, :]\n",
    "SST_Historical_Test_2D = SST_Historical_2D[Index_Year_Test, :]\n",
    "# 原始数据：1维（月份数，）\n",
    "SST_ERSST_All_1D = SST_ERSST_2D.reshape(-1)\n",
    "SST_ERSST_Train_1D = SST_ERSST_Train_2D.reshape(-1)\n",
    "SST_ERSST_Validate_1D = SST_ERSST_Validate_2D.reshape(-1)\n",
    "SST_ERSST_Test_1D = SST_ERSST_Test_2D.reshape(-1)\n",
    "SST_Historical_All_1D = SST_Historical_2D.reshape(-1)\n",
    "SST_Historical_Train_1D = SST_Historical_Train_2D.reshape(-1)\n",
    "SST_Historical_Validate_1D = SST_Historical_Validate_2D.reshape(-1)\n",
    "SST_Historical_Test_1D = SST_Historical_Test_2D.reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9F764A1C3D154B7381614894E8B9458D",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**EEMD分解的数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "id": "F1476BC58C8544C7BBFE3EAB7E0FDB22",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Path_SaveData_EEMD = './project/SaveData/EEMD/'\n",
    "IMFs_ERSST_Compose = np.load(Path_SaveData_EEMD + 'IMFs_ERSST_Compose.npy')\n",
    "IMFs_Historical_Compose = np.load(\n",
    "    Path_SaveData_EEMD +\n",
    "    'IMFs_Historical_Compose.npy')\n",
    "IMFs_SSP126_Compose = np.load(Path_SaveData_EEMD + 'IMFs_SSP126_Compose.npy')\n",
    "IMFs_SSP245_Compose = np.load(Path_SaveData_EEMD + 'IMFs_SSP245_Compose.npy')\n",
    "IMFs_SSP585_Compose = np.load(Path_SaveData_EEMD + 'IMFs_SSP585_Compose.npy')\n",
    "# IMF: 2维 (6, 月份数)\n",
    "IMFs_ERSST_Compose_3D = IMFs_ERSST_Compose.reshape((6, Num_Year, 12))\n",
    "IMFs_ERSST_Compose_All_2D = IMFs_ERSST_Compose_3D.reshape((6, -1))\n",
    "IMFs_ERSST_Compose_Train_2D = IMFs_ERSST_Compose_3D[:, Index_Year_Train, :].reshape(\n",
    "    (6, -1))\n",
    "IMFs_ERSST_Compose_Validate_2D = IMFs_ERSST_Compose_3D[:, Index_Year_Validate, :].reshape(\n",
    "    (6, -1))\n",
    "IMFs_ERSST_Compose_Test_2D = IMFs_ERSST_Compose_3D[:, Index_Year_Test, :].reshape(\n",
    "    (6, -1))\n",
    "IMFs_Historical_Compose_3D = IMFs_Historical_Compose.reshape((6, Num_Year, 12))\n",
    "IMFs_Historical_Compose_All_2D = IMFs_Historical_Compose_3D.reshape((6, -1))\n",
    "IMFs_Historical_Compose_Train_2D = IMFs_Historical_Compose_3D[:, Index_Year_Train, :].reshape(\n",
    "    (6, -1))\n",
    "IMFs_Historical_Compose_Validate_2D = IMFs_Historical_Compose_3D[:, Index_Year_Validate, :].reshape(\n",
    "    (6, -1))\n",
    "IMFs_Historical_Compose_Test_2D = IMFs_Historical_Compose_3D[:, Index_Year_Test, :].reshape(\n",
    "    (6, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7B6383847708441E89C0CC20788FC1F8",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**BPNN输出数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "id": "150BE0E026E549138D874839B69FC9A1",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Path_SaveData_Model = './project/SaveData/Model/'\n",
    "IMFs_Historical_Compose_Correct_3D = np.load(\n",
    "    Path_SaveData_Model + 'BP_Output_All_Chronological.npy')\n",
    "IMFs_SSP126_Compose_Correct_3D = np.load(\n",
    "    Path_SaveData_Model + 'BP_Output_SSP126.npy')\n",
    "IMFs_SSP245_Compose_Correct_3D = np.load(\n",
    "    Path_SaveData_Model + 'BP_Output_SSP245.npy')\n",
    "IMFs_SSP585_Compose_Correct_3D = np.load(\n",
    "    Path_SaveData_Model + 'BP_Output_SSP585.npy')\n",
    "# 订正后IMF: 2维 (6,年份数)\n",
    "IMFs_Historical_Compose_Correct_All_2D = IMFs_Historical_Compose_Correct_3D.reshape(\n",
    "    (6, -1))\n",
    "IMFs_Historical_Compose_Correct_Train_2D = IMFs_Historical_Compose_Correct_3D[:, Index_Year_Train, :].reshape(\n",
    "    (6, -1))\n",
    "IMFs_Historical_Compose_Correct_Validate_2D = IMFs_Historical_Compose_Correct_3D[:, Index_Year_Validate, :].reshape(\n",
    "    (6, -1))\n",
    "IMFs_Historical_Compose_Correct_Test_2D = IMFs_Historical_Compose_Correct_3D[:, Index_Year_Test, :].reshape(\n",
    "    (6, -1))\n",
    "# 重构的订正IMF: 1维 (月份数,)\n",
    "SST_Historical_Correct_All_1D = np.sum(\n",
    "    IMFs_Historical_Compose_Correct_All_2D, 0)\n",
    "SST_Historical_Correct_Train_1D = np.sum(\n",
    "    IMFs_Historical_Compose_Correct_Train_2D, 0)\n",
    "SST_Historical_Correct_Validate_1D = np.sum(\n",
    "    IMFs_Historical_Compose_Correct_Validate_2D, 0)\n",
    "SST_Historical_Correct_Test_1D = np.sum(\n",
    "    IMFs_Historical_Compose_Correct_Test_2D, 0)\n",
    "SST_SSP126_Correct_1D = np.sum(\n",
    "    IMFs_SSP126_Compose_Correct_3D.reshape(\n",
    "        (6, -1)), 0)\n",
    "SST_SSP245_Correct_1D = np.sum(\n",
    "    IMFs_SSP245_Compose_Correct_3D.reshape(\n",
    "        (6, -1)), 0)\n",
    "SST_SSP585_Correct_1D = np.sum(\n",
    "    IMFs_SSP585_Compose_Correct_3D.reshape(\n",
    "        (6, -1)), 0)\n",
    "# 重构的订正IMF: 2维 (年份数, 12)\n",
    "SST_Historical_Correct_All_2D = SST_Historical_Correct_All_1D.reshape((-1, 12))\n",
    "SST_Historical_Correct_Train_2D = SST_Historical_Correct_Train_1D.reshape(\n",
    "    (-1, 12))\n",
    "SST_Historical_Correct_Validate_2D = SST_Historical_Correct_Validate_1D.reshape(\n",
    "    (-1, 12))\n",
    "SST_Historical_Correct_Test_2D = SST_Historical_Correct_Test_1D.reshape(\n",
    "    (-1, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31E739CD732642E78C2C507C5A04FA6E",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 5.3.2 结果分析\n",
    "对订正结果，我们首先是想知道偏差订正了多少，这里我们用到基本的评价指标：相关系数和均方根误差来评价订正结果。评价顺序这里，我们先来看一下历史时期的原始及误差时间序列，再来具体看看各个月份的误差条形统计图，最后画出未来预估的订正结果。即以下三部分\n",
    "####  &emsp;&emsp; 1）历史时期的时间序列\n",
    "####  &emsp;&emsp; 2）逐月误差条形统计图\n",
    "####  &emsp;&emsp; 3）未来预估的时间序列\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B69306D4D3F043CF837904EF6988A29C",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### 5.3.2.1. 历史时期的时间序列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8EF7E8E8A36F4F7FA4030BD0E0D67EFA",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "** SST的IMF：修正前/后，训练集/验证集/测试集/全时段**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "id": "30E29FF926554EED94C2F9766F46049C",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### 计算SST IMF的： 均方根误差（RMSE）/相关系数（R）\n",
    "## 均方根误差\n",
    "RMSE_IMFs_Historical_Compose_Train = np.zeros(6)\n",
    "RMSE_IMFs_Historical_Compose_Validate = np.zeros(6)\n",
    "RMSE_IMFs_Historical_Compose_Test = np.zeros(6)\n",
    "RMSE_IMFs_Historical_Compose_All = np.zeros(6)\n",
    "RMSE_IMFs_Historical_Compose_Correct_Train = np.zeros(6)\n",
    "RMSE_IMFs_Historical_Compose_Correct_Validate = np.zeros(6)\n",
    "RMSE_IMFs_Historical_Compose_Correct_Test = np.zeros(6)\n",
    "RMSE_IMFs_Historical_Compose_Correct_All = np.zeros(6)\n",
    "for n in range(6):\n",
    "    # 原始\n",
    "    RMSE_IMFs_Historical_Compose_Train[n] = rmse( IMFs_Historical_Compose_Train_2D[n,:], IMFs_ERSST_Compose_Train_2D[n,:] )\n",
    "    RMSE_IMFs_Historical_Compose_Validate[n] = rmse( IMFs_Historical_Compose_Validate_2D[n,:], IMFs_ERSST_Compose_Validate_2D[n,:] )\n",
    "    RMSE_IMFs_Historical_Compose_Test[n] = rmse( IMFs_Historical_Compose_Test_2D[n,:], IMFs_ERSST_Compose_Test_2D[n,:] )\n",
    "    RMSE_IMFs_Historical_Compose_All[n] = rmse( IMFs_Historical_Compose_All_2D[n,:], IMFs_ERSST_Compose_All_2D[n,:] )\n",
    "    # 订正\n",
    "    RMSE_IMFs_Historical_Compose_Correct_Train[n] = rmse( IMFs_Historical_Compose_Correct_Train_2D[n,:], IMFs_ERSST_Compose_Train_2D[n,:] )\n",
    "    RMSE_IMFs_Historical_Compose_Correct_Validate[n] = rmse( IMFs_Historical_Compose_Correct_Validate_2D[n,:], IMFs_ERSST_Compose_Validate_2D[n,:] )\n",
    "    RMSE_IMFs_Historical_Compose_Correct_Test[n] = rmse( IMFs_Historical_Compose_Correct_Test_2D[n,:], IMFs_ERSST_Compose_Test_2D[n,:] )\n",
    "    RMSE_IMFs_Historical_Compose_Correct_All[n] = rmse( IMFs_Historical_Compose_Correct_All_2D[n,:], IMFs_ERSST_Compose_All_2D[n,:] )\n",
    "\n",
    "## 相关系数\n",
    "R_IMFs_Historical_Compose_Train = np.zeros( (6,2) )\n",
    "R_IMFs_Historical_Compose_Validate = np.zeros( (6,2) )\n",
    "R_IMFs_Historical_Compose_Test = np.zeros( (6,2) )\n",
    "R_IMFs_Historical_Compose_All = np.zeros( (6,2) )\n",
    "R_IMFs_Historical_Compose_Correct_Train = np.zeros( (6,2) )\n",
    "R_IMFs_Historical_Compose_Correct_Validate = np.zeros( (6,2) )\n",
    "R_IMFs_Historical_Compose_Correct_Test = np.zeros( (6,2) )\n",
    "R_IMFs_Historical_Compose_Correct_All = np.zeros( (6,2) )\n",
    "for n in range(6):\n",
    "    # 原始\n",
    "    R_IMFs_Historical_Compose_Train[n,:] = scipy.stats.pearsonr( IMFs_Historical_Compose_Train_2D[n,:], IMFs_ERSST_Compose_Train_2D[n,:] )[:]\n",
    "    R_IMFs_Historical_Compose_Validate[n,:] = scipy.stats.pearsonr( IMFs_Historical_Compose_Validate_2D[n,:], IMFs_ERSST_Compose_Validate_2D[n,:] )[:]\n",
    "    R_IMFs_Historical_Compose_Test[n,:] = scipy.stats.pearsonr( IMFs_Historical_Compose_Test_2D[n,:], IMFs_ERSST_Compose_Test_2D[n,:] )[:]\n",
    "    R_IMFs_Historical_Compose_All[n,:] = scipy.stats.pearsonr( IMFs_Historical_Compose_All_2D[n,:], IMFs_ERSST_Compose_All_2D[n,:] )[:]\n",
    "    # 订正\n",
    "    R_IMFs_Historical_Compose_Correct_Train[n,:] = scipy.stats.pearsonr( IMFs_Historical_Compose_Correct_Train_2D[n,:], IMFs_ERSST_Compose_Train_2D[n,:] )[:]\n",
    "    R_IMFs_Historical_Compose_Correct_Validate[n,:] = scipy.stats.pearsonr( IMFs_Historical_Compose_Correct_Validate_2D[n,:], IMFs_ERSST_Compose_Validate_2D[n,:] )[:]\n",
    "    R_IMFs_Historical_Compose_Correct_Test[n,:] = scipy.stats.pearsonr( IMFs_Historical_Compose_Correct_Test_2D[n,:], IMFs_ERSST_Compose_Test_2D[n,:] )[:]\n",
    "    R_IMFs_Historical_Compose_Correct_All[n,:] = scipy.stats.pearsonr( IMFs_Historical_Compose_Correct_All_2D[n,:], IMFs_ERSST_Compose_All_2D[n,:] )[:]\n",
    "## 结果较多，大家可打印自行查看"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6138E56A888D4E388B8DE9E8BE735D09",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**重构的SST：修正前/后，训练集/验证集/测试集/全时段**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "id": "E17BBB4589444D9D824B792F66E7B772",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20784581370243535 0.22257860044431999 0.2133404373631007 0.20977381961027866\n",
      "0.10053041885793738 0.1443042559570034 0.11073906087398842 0.10632007518038103\n",
      "(0.7279122407416198, 1.7470650216429933e-139) (0.6571257905729102, 3.56328932044392e-13) (0.6957722332701931, 3.611407039770055e-15) (0.7216456050215255, 1.0369404819037778e-166)\n",
      "(0.9155161903209507, 0.0) (0.8066538387212107, 3.435826527987728e-23) (0.8556195169101555, 1.2478972512739245e-28) (0.9025459185953143, 0.0)\n"
     ]
    }
   ],
   "source": [
    "### 计算重构SST的均方根误差/相关系数\n",
    "## 均方根误差\n",
    "RMSE_SST_Historical_Train = rmse( SST_Historical_Train_1D, SST_ERSST_Train_1D )\n",
    "RMSE_SST_Historical_Validate = rmse( SST_Historical_Validate_1D, SST_ERSST_Validate_1D )\n",
    "RMSE_SST_Historical_Test = rmse( SST_Historical_Test_1D, SST_ERSST_Test_1D )\n",
    "RMSE_SST_Historical_All = rmse( SST_Historical_All_1D, SST_ERSST_All_1D )\n",
    "RMSE_SST_Historical_Correct_Train = rmse( SST_Historical_Correct_Train_1D, SST_ERSST_Train_1D )\n",
    "RMSE_SST_Historical_Correct_Validate = rmse( SST_Historical_Correct_Validate_1D, SST_ERSST_Validate_1D )\n",
    "RMSE_SST_Historical_Correct_Test = rmse( SST_Historical_Correct_Test_1D, SST_ERSST_Test_1D )\n",
    "RMSE_SST_Historical_Correct_All = rmse( SST_Historical_Correct_All_1D, SST_ERSST_All_1D )\n",
    "# 打印查看订正前后均方根误差\n",
    "print(RMSE_SST_Historical_Train, RMSE_SST_Historical_Validate, RMSE_SST_Historical_Test, RMSE_SST_Historical_All)\n",
    "print(RMSE_SST_Historical_Correct_Train, RMSE_SST_Historical_Correct_Validate, RMSE_SST_Historical_Correct_Test, RMSE_SST_Historical_Correct_All)\n",
    "\n",
    "## 相关系数\n",
    "R_SST_Historical_Train = scipy.stats.pearsonr( SST_Historical_Train_1D, SST_ERSST_Train_1D )[:]\n",
    "R_SST_Historical_Validate = scipy.stats.pearsonr( SST_Historical_Validate_1D, SST_ERSST_Validate_1D )[:]\n",
    "R_SST_Historical_Test = scipy.stats.pearsonr( SST_Historical_Test_1D, SST_ERSST_Test_1D )[:]\n",
    "R_SST_Historical_All = scipy.stats.pearsonr( SST_Historical_All_1D, SST_ERSST_All_1D )[:]\n",
    "R_SST_Historical_Correct_Train = scipy.stats.pearsonr( SST_Historical_Correct_Train_1D, SST_ERSST_Train_1D )[:]\n",
    "R_SST_Historical_Correct_Validate = scipy.stats.pearsonr( SST_Historical_Correct_Validate_1D, SST_ERSST_Validate_1D )[:]\n",
    "R_SST_Historical_Correct_Test = scipy.stats.pearsonr( SST_Historical_Correct_Test_1D, SST_ERSST_Test_1D )[:]\n",
    "R_SST_Historical_Correct_All = scipy.stats.pearsonr( SST_Historical_Correct_All_1D, SST_ERSST_All_1D )[:]\n",
    "# 打印查看订正前后相关系数\n",
    "print(R_SST_Historical_Train, R_SST_Historical_Validate, R_SST_Historical_Test, R_SST_Historical_All)\n",
    "print(R_SST_Historical_Correct_Train, R_SST_Historical_Correct_Validate, R_SST_Historical_Correct_Test, R_SST_Historical_Correct_All)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8FCEEAA2686A497A83EFEE21A85855E0",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "可以看到订正前后三个集合的均方根误差均有所减少，**减少了30%-50%**，它们按时间顺序排列的全序列，均方根误差也**减少了50%左右**。三个集合的相关系数都提升到**0.78以上**，时间排序的全序列从0.72提升到了**0.90**。\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "662AD09E9ABF4B388422BD2284064FAD",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**画图看一看重构后的全时段时间序列**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "id": "A7DF3E4D47E446318267B29A7E096D1E",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 144, 288, 432, 576, 720, 864, 1008]\n",
      "[17.0, 17.5, 18.0, 18.5, 19.0]\n",
      "['17.0', '17.5', '18.0', '18.5', '19.0']\n",
      "./project/Figures/Model/ has been existed!\n"
     ]
    }
   ],
   "source": [
    "### 画重构SST\n",
    "## 预设\n",
    "fontsizenum = 16  \n",
    "markersizenum = 6\n",
    "Num_Year = 2014-1929+1\n",
    "Num_Sample_SST = Num_Year*12\n",
    "X_Time = np.arange(0, Num_Sample_SST )\n",
    "Time_SST = np.array(Time_ERSST[-Num_Sample_SST::])\n",
    "xtick_SST_interval = 12*12\n",
    "xticklabel_SST = list(range(0, Num_Sample_SST, xtick_SST_interval)); print(xticklabel_SST)\n",
    "xticklabels_SST = Time_SST[xticklabel_SST[0::]].astype('str').tolist()\n",
    "ylim_sst_max = 19\n",
    "ylim_sst_min = 17\n",
    "delta_ylim_sst = ylim_sst_max - ylim_sst_min\n",
    "yticklabel_SST = np.linspace(ylim_sst_min, ylim_sst_max, num = 5).tolist()\n",
    "yticklabel_SST = [round(i,1) for i in yticklabel_SST]; print(yticklabel_SST)\n",
    "yticklabels_SST = [str(i) for i in yticklabel_SST]; print(yticklabels_SST)\n",
    "## 画\n",
    "fig, ax = plt.subplots(1, 1, figsize = (16,9), dpi = 600)\n",
    "ax.plot(X_Time, SST_Historical_All_1D, 'b-', linewidth = 2, marker = '.', markersize = markersizenum, mfc = 'blue', label = 'FIO-ESM v2')\n",
    "ax.plot(X_Time, SST_Historical_Correct_All_1D, 'r-', linewidth = 2, marker = '.', markersize = markersizenum, mfc = 'red', label = 'EEMD-BPNN')\n",
    "ax.plot(X_Time, SST_ERSST_All_1D, 'k-', linewidth = 2, marker = '.', markersize = markersizenum, mfc = 'black', label = 'ERSST')\n",
    "ax.set_xlim(0, Num_Sample_SST)\n",
    "ax.set_ylim(ylim_sst_min, ylim_sst_max)  \n",
    "ax.set_xticks(xticklabel_SST)\n",
    "ax.set_yticks(yticklabel_SST)  \n",
    "ax.set_xticklabels(xticklabels_SST, fontsize = fontsizenum)\n",
    "ax.set_yticklabels(yticklabels_SST, fontsize = fontsizenum)\n",
    "ax.set_xlabel('Time', fontsize=fontsizenum)\n",
    "ax.set_ylabel('SST(℃)', fontsize = fontsizenum)\n",
    "legend_font = { 'weight': 'normal', 'size': fontsizenum}\n",
    "ax.legend(loc = 'upper left', frameon = False, prop = legend_font, ncol = 1)\n",
    "ax.grid(linestyle='-.')\n",
    "## 保存图片\n",
    "Path_Pre = './project/Figures/'\n",
    "Path_SaveFigures =  Path_Pre + 'Model/'\n",
    "isExists = os.path.exists(Path_SaveFigures)\n",
    "if not isExists:\n",
    "    os.makedirs(Path_Pre + 'Model/')\n",
    "    print( Path_SaveFigures +  ' successfully build!')\n",
    "else:\n",
    "    print( Path_SaveFigures + ' has been existed!')\n",
    "\n",
    "fns = os.path.join(Path_SaveFigures, 'SST_Historical_Correct_ERSST.png')\n",
    "plt.savefig(fns, dpi = 600, bbox_inches = 'tight')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BBD8C9F6F2A54D4EB99E09F9DC95EE6E",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "上图是模式（蓝色），订正后（红色）和观测（黑色）的时间序列。从上图可以看出，较原始模式FIO-ESM v2，基于EEMD-BPNN组合的订正结果更加靠近观测ERSST的时间序列。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49A390E38AA64AD19ADAF48AC6E0626A",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**重构的SST偏差：修正前/后，训练集/验证集/测试集/全时段**\n",
    "再来看一下订正前后偏差的情况，看偏差也是更为直观的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "id": "E36FD79C6ED04C358A5E2F765EE40553",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 144, 288, 432, 576, 720, 864, 1008]\n",
      "[-0.6, -0.4, -0.2, 0.0, 0.2, 0.4, 0.6]\n",
      "['-0.6', '-0.4', '-0.2', '0.0', '0.2', '0.4', '0.6']\n"
     ]
    }
   ],
   "source": [
    "Bias_Historical_Train_1D = SST_Historical_Train_1D - SST_ERSST_Train_1D\n",
    "Bias_Historical_Validate_1D = SST_Historical_Validate_1D - SST_ERSST_Validate_1D\n",
    "Bias_Historical_Test_1D = SST_Historical_Test_1D - SST_ERSST_Test_1D\n",
    "Bias_Historical_All_1D = SST_Historical_All_1D - SST_ERSST_All_1D\n",
    "Bias_Historical_Correct_Train_1D = SST_Historical_Correct_Train_1D - SST_ERSST_Train_1D\n",
    "Bias_Historical_Correct_Validate_1D = SST_Historical_Correct_Validate_1D - SST_ERSST_Validate_1D\n",
    "Bias_Historical_Correct_Test_1D = SST_Historical_Correct_Test_1D - SST_ERSST_Test_1D\n",
    "Bias_Historical_Correct_All_1D = SST_Historical_Correct_All_1D - SST_ERSST_All_1D\n",
    "### 计算重构的SST偏差: 最小值（Min）/最大值（Max）/平均偏差（Mean Bias）/标准差（Std），这些指标大家可以打印查看\n",
    "## 最小值\n",
    "Min_Bias_Historical_Train_1D = np.min(Bias_Historical_Train_1D)\n",
    "Min_Bias_Historical_Validate_1D = np.min(Bias_Historical_Validate_1D)\n",
    "Min_Bias_Historical_Test_1D = np.min(Bias_Historical_Test_1D)\n",
    "Min_Bias_Historical_All_1D = np.min(Bias_Historical_All_1D)\n",
    "Min_Bias_Historical_Correct_Train_1D = np.min(Bias_Historical_Correct_Train_1D)\n",
    "Min_Bias_Historical_Correct_Validate_1D = np.min(Bias_Historical_Validate_1D)\n",
    "Min_Bias_Historical_Correct_Test_1D = np.min(Bias_Historical_Correct_Test_1D)\n",
    "Min_Bias_Historical_Correct_All_1D = np.min(Bias_Historical_Correct_All_1D)\n",
    "## 最大值\n",
    "Max_Bias_Historical_Train_1D = np.max(Bias_Historical_Train_1D)\n",
    "Max_Bias_Historical_Validate_1D = np.max(Bias_Historical_Validate_1D)\n",
    "Max_Bias_Historical_Test_1D = np.max(Bias_Historical_Test_1D)\n",
    "Max_Bias_Historical_All_1D = np.max(Bias_Historical_All_1D)\n",
    "Max_Bias_Historical_Correct_Train_1D = np.max(Bias_Historical_Correct_Train_1D)\n",
    "Max_Bias_Historical_Correct_Validate_1D = np.max(Bias_Historical_Validate_1D)\n",
    "Max_Bias_Historical_Correct_Test_1D = np.max(Bias_Historical_Correct_Test_1D)\n",
    "Max_Bias_Historical_Correct_All_1D = np.max(Bias_Historical_Correct_All_1D)\n",
    "# 平均偏差\n",
    "Mean_Bias_Historical_Train_1D = np.mean(Bias_Historical_Train_1D)\n",
    "Mean_Bias_Historical_Validate_1D = np.mean(Bias_Historical_Validate_1D)\n",
    "Mean_Bias_Historical_Test_1D = np.mean(Bias_Historical_Test_1D)\n",
    "Mean_Bias_Historical_All_1D = np.mean(Bias_Historical_All_1D)\n",
    "Mean_Bias_Historical_Correct_Train_1D = np.mean(Bias_Historical_Correct_Train_1D)\n",
    "Mean_Bias_Historical_Correct_Validate_1D = np.mean(Bias_Historical_Validate_1D)\n",
    "Mean_Bias_Historical_Correct_Test_1D = np.mean(Bias_Historical_Correct_Test_1D)\n",
    "Mean_Bias_Historical_Correct_All_1D = np.mean(Bias_Historical_Correct_All_1D)\n",
    "# 标准差\n",
    "Std_Bias_Historical_Train_1D = np.std(Bias_Historical_Train_1D, ddof = 0)\n",
    "Std_Bias_Historical_Validate_1D = np.std(Bias_Historical_Validate_1D, ddof = 0)\n",
    "Std_Bias_Historical_Test_1D = np.std(Bias_Historical_Test_1D, ddof = 0)\n",
    "Std_Bias_Historical_All_1D = np.std(Bias_Historical_All_1D, ddof = 0)\n",
    "Std_Bias_Historical_Correct_Train_1D = np.std(Bias_Historical_Correct_Train_1D, ddof = 0)\n",
    "Std_Bias_Historical_Correct_Validate_1D = np.std(Bias_Historical_Validate_1D, ddof = 0)\n",
    "Std_Bias_Historical_Correct_Test_1D = np.std(Bias_Historical_Correct_Test_1D, ddof = 0)\n",
    "Std_Bias_Historical_Correct_All_1D = np.std(Bias_Historical_Correct_All_1D, ddof = 0)\n",
    "\n",
    "###  画重构的SST偏差\n",
    "## 预设\n",
    "fontsizenum = 16 \n",
    "markersizenum = 6\n",
    "Num_Year = 2014-1929+1\n",
    "Num_Sample_Bias = Num_Year*12\n",
    "X_Time = np.arange(0, Num_Sample_Bias )\n",
    "Time_Bias = np.array(Time_ERSST[-Num_Sample_Bias::])\n",
    "xtick_Bias_interval = 12*12\n",
    "xticklabel_Bias = list(range(0, Num_Sample_Bias, xtick_Bias_interval)); print(xticklabel_Bias)\n",
    "xticklabels_Bias = Time_Bias[xticklabel_Bias[0::]].astype('str').tolist()\n",
    "ylim_bias_max = 0.6\n",
    "ylim_bias_min = -0.6\n",
    "delta_ylim_bias = ylim_bias_max - ylim_bias_min\n",
    "yticklabel_Bias = np.linspace(ylim_bias_min, ylim_bias_max, num = 7).tolist()\n",
    "yticklabel_Bias = [round(i,1) for i in yticklabel_Bias]; print(yticklabel_Bias)\n",
    "yticklabels_Bias = [str(i) for i in yticklabel_Bias]; print(yticklabels_Bias)\n",
    "### 画\n",
    "fig, ax = plt.subplots(1, 1, figsize = (16,9), dpi = 600)\n",
    "ax.plot(X_Time, Bias_Historical_All_1D, 'b-', linewidth = 2, marker = '.', markersize = markersizenum, mfc = 'blue', label = 'FIO-ESM v2')\n",
    "ax.plot(X_Time, Bias_Historical_Correct_All_1D, 'r-', linewidth = 2, marker = '.', markersize = markersizenum, mfc = 'red', label = 'EEMD-BPNN')\n",
    "plt.axhline(y = 0 , c = 'k', ls = '--', lw = 3)\n",
    "ax.set_xlim(0, Num_Sample_Bias)\n",
    "ax.set_ylim(ylim_bias_min, ylim_bias_max)  \n",
    "ax.set_xticks(xticklabel_Bias)\n",
    "ax.set_yticks(yticklabel_Bias)  \n",
    "ax.set_xticklabels(xticklabels_Bias, fontsize = fontsizenum)\n",
    "ax.set_yticklabels(yticklabels_Bias, fontsize = fontsizenum)\n",
    "ax.set_xlabel('Time', fontsize=fontsizenum)\n",
    "ax.set_ylabel('SST Bias(℃)', fontsize = fontsizenum)\n",
    "legend_font = { 'weight': 'normal', 'size': fontsizenum}\n",
    "ax.legend(loc = 'upper left', frameon = False, prop = legend_font, ncol = 1)\n",
    "ax.grid(linestyle='-.')\n",
    "## 保存图片\n",
    "fns = os.path.join(Path_SaveFigures, 'SSTBias_Historical_Correct.png')\n",
    "plt.savefig(fns, dpi = 600, bbox_inches = 'tight')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57F34B0FD95E43128749F92FA9CA57B6",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "上图是订正前（蓝色）、后（红色）的模式模拟全球平均SST偏差时间序列。我们可以很明显地看到订正后的红色序列更加趋近于偏差等于0的直线。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66A8D6182AC04F33BAAC851D13218C28",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### 5.4.2.2. 逐月误差条形统计图\n",
    "看完整体的时间序列结果，我们还可以看看订正前后的逐月偏差表现。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "148B587C849244568677D4A0152B3865",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**重构的SST：修正前/后，训练集/验证集/测试集/全时段**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "id": "02B20F09B7C145998C26BA1D4B8A344E",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19498177 0.1950517  0.16868618 0.1516922  0.12982823 0.13920275\n",
      " 0.2280399  0.31332147 0.31419389 0.23615461 0.17752383 0.16770578]\n",
      "[0.11809566 0.11227667 0.10865488 0.10622012 0.09938984 0.09789643\n",
      " 0.09355061 0.09419723 0.09857831 0.10428939 0.11392125 0.1238845 ]\n",
      "[[7.26889347e-01 2.31192034e-15]\n",
      " [7.53750539e-01 5.51990233e-17]\n",
      " [7.93474324e-01 8.32068454e-20]\n",
      " [8.08324620e-01 5.03126134e-21]\n",
      " [8.30400201e-01 4.78380599e-23]\n",
      " [8.53433260e-01 1.71393500e-25]\n",
      " [8.83863112e-01 1.86870077e-29]\n",
      " [8.97805952e-01 1.16565372e-31]\n",
      " [8.71509756e-01 1.00291798e-27]\n",
      " [8.26196218e-01 1.22063667e-22]\n",
      " [7.60342006e-01 2.05033005e-17]\n",
      " [7.24486452e-01 3.16033702e-15]]\n",
      "[[8.33370394e-01 2.42982805e-23]\n",
      " [8.53099329e-01 1.87233284e-25]\n",
      " [8.64419872e-01 8.22547299e-27]\n",
      " [8.75900037e-01 2.55711587e-28]\n",
      " [8.91370267e-01 1.32316686e-30]\n",
      " [9.09909855e-01 7.54141100e-34]\n",
      " [9.21925503e-01 2.37271806e-36]\n",
      " [9.17183146e-01 2.55835975e-35]\n",
      " [8.99127783e-01 6.93712206e-32]\n",
      " [8.70705542e-01 1.28122132e-27]\n",
      " [8.42115831e-01 3.05225200e-24]\n",
      " [8.18130513e-01 6.87686042e-22]]\n",
      "[0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]\n",
      "['0.0', '0.05', '0.1', '0.15', '0.2', '0.25', '0.3', '0.35', '0.4']\n",
      "[0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]\n",
      "['0.7', '0.75', '0.8', '0.85', '0.9', '0.95', '1.0']\n"
     ]
    }
   ],
   "source": [
    "### 均方根误差\n",
    "RMSE_SST_Historical_12Month_All = np.zeros(12)\n",
    "RMSE_SST_Historical_12Month_Correct_All = np.zeros(12)\n",
    "for month in range(12):\n",
    "    RMSE_SST_Historical_12Month_All[month] = rmse(SST_Historical_2D[:,month], SST_ERSST_2D[:,month])\n",
    "    RMSE_SST_Historical_12Month_Correct_All[month] = rmse(SST_Historical_Correct_All_2D[:,month], SST_ERSST_2D[:,month])\n",
    "print(RMSE_SST_Historical_12Month_All)\n",
    "print(RMSE_SST_Historical_12Month_Correct_All)\n",
    "### 相关系数\n",
    "R_SST_Historical_12Month_All = np.zeros( (12,2) )\n",
    "R_SST_Historical_12Month_Correct_All = np.zeros( (12,2) )\n",
    "for month in range(12):\n",
    "    R_SST_Historical_12Month_All[month,:] = scipy.stats.pearsonr(SST_Historical_2D[:,month], SST_ERSST_2D[:,month])[:]\n",
    "    R_SST_Historical_12Month_Correct_All[month,:] = scipy.stats.pearsonr(SST_Historical_Correct_All_2D[:,month], SST_ERSST_2D[:,month])[:]\n",
    "print(R_SST_Historical_12Month_All)\n",
    "print(R_SST_Historical_12Month_Correct_All)\n",
    "\n",
    "### 画图：重构SST的逐月表现（均方根误差/相关系数）\n",
    "## 预设\n",
    "str_panels = ['a)RMSE', 'b)R']\n",
    "fontsizenum = 16  \n",
    "barwidthnum = 0.3\n",
    "X_Month = np.arange(1,13)\n",
    "xticklabel_Month = list(range(0,14))\n",
    "xticklabels_Month = ['','Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec','']\n",
    "## 均方根误差\n",
    "ylim_rmse_max = 0.4\n",
    "ylim_rmse_min = 0\n",
    "delta_rmse_bias = ylim_rmse_max - ylim_rmse_min\n",
    "yticklabel_RMSE = np.linspace(ylim_rmse_min, ylim_rmse_max, num = 9).tolist()\n",
    "yticklabel_RMSE = [round(i,2) for i in yticklabel_RMSE]; print(yticklabel_RMSE)\n",
    "yticklabels_RMSE = [str(i) for i in yticklabel_RMSE]; print(yticklabels_RMSE)\n",
    "## 相关系数\n",
    "ylim_R_max = 1.0\n",
    "ylim_R_min = 0.7\n",
    "delta_R_bias = ylim_R_max - ylim_R_min\n",
    "yticklabel_R = np.linspace(ylim_R_min, ylim_R_max, num = 7).tolist()\n",
    "yticklabel_R = [round(i,2) for i in yticklabel_R]; print(yticklabel_R)\n",
    "yticklabels_R = [str(i) for i in yticklabel_R]; print(yticklabels_R)\n",
    "\n",
    "## 画图\n",
    "fig, ax = plt.subplots(2, 1, figsize = (16,9), dpi = 600)\n",
    "# 均方根误差\n",
    "ax = plt.subplot(2, 1, 1)\n",
    "bar1 = ax.bar(X_Month - barwidthnum, RMSE_SST_Historical_12Month_All, color = 'blue',  alpha = 1,  width = barwidthnum, edgecolor = 'black', linewidth = 1.5, bottom = 0, align = 'edge') # label = 'FIO-ESM v2'\n",
    "bar2 = ax.bar(X_Month, RMSE_SST_Historical_12Month_Correct_All, color = 'red',  alpha = 1,  width = barwidthnum, edgecolor = 'black', linewidth = 1.5, bottom = 0, align = 'edge') # label = 'EEMD-BPNN'\n",
    "for month in range(12):\n",
    "    Y_Month = np.round( RMSE_SST_Historical_12Month_All[month], 3)\n",
    "    Y_Month_Correct = np.round( RMSE_SST_Historical_12Month_Correct_All[month], 3)\n",
    "    Str_Y_Month = str(Y_Month)\n",
    "    Str_Y_Month_Correct = str(Y_Month_Correct)\n",
    "    ax.text(X_Month[month] - barwidthnum/2, Y_Month + 0.01, Str_Y_Month, horizontalalignment ='center', fontsize = 10 )\n",
    "    ax.text(X_Month[month] + barwidthnum/2, Y_Month_Correct + 0.01, Str_Y_Month_Correct, horizontalalignment ='center', fontsize = 10 )\n",
    "plot1 = plt.axhline(y = RMSE_SST_Historical_All , c = 'blue', ls = '-', lw = 2)\n",
    "plot2 = plt.axhline(y = RMSE_SST_Historical_Correct_All , c = 'red', ls = '-', lw = 2)\n",
    "Y_Month = np.round(RMSE_SST_Historical_All, 3); Str_Y_Month = str(Y_Month)\n",
    "Y_Month_Correct = np.round(RMSE_SST_Historical_Correct_All, 3); Str_Y_Month_Correct = str(Y_Month_Correct)\n",
    "ax.text(0.3, Y_Month + 0.01, Str_Y_Month, horizontalalignment='center', fontsize = 14)\n",
    "ax.text(0.3, Y_Month_Correct + 0.01, Str_Y_Month_Correct, horizontalalignment='center', fontsize = 14)\n",
    "ax.text(0, ylim_rmse_min + delta_rmse_bias*0.92, str_panels[0], fontsize=fontsizenum)   # color = 'black'\n",
    "ax.set(xlim = (0, 13), ylim = (ylim_rmse_min, ylim_rmse_max))\n",
    "ax.tick_params(axis = 'both', which = 'both', direction = 'in')\n",
    "ax.set_xticks(xticklabel_Month)\n",
    "ax.set_yticks(yticklabel_RMSE)\n",
    "ax.set_xticklabels(xticklabels_Month, fontsize = fontsizenum)\n",
    "ax.set_yticklabels(yticklabels_RMSE, fontsize = fontsizenum)\n",
    "ax.set_xlabel('Month', fontsize=fontsizenum)\n",
    "ax.set_ylabel('RMSE(℃)', fontsize = fontsizenum)\n",
    "ax.grid(axis = 'y', linestyle = '--', lw = 1)  # color='grey', alpha=0.5\n",
    "legend_font = {'weight': 'normal', 'size': fontsizenum}\n",
    "plt.legend([bar1, bar2, plot1, plot2], [\"FIO-ESM v2\", \"EEMD-BPNN\", \"FIO-ESM v2(All Time)\",\"EEMD-BPNN(All Time)\"],\n",
    "           bbox_to_anchor = (0.3, 1.0), loc = 'upper center', ncol = 2, frameon = False, prop = legend_font)\n",
    "\n",
    "# 相关系数\n",
    "ax = plt.subplot(2, 1, 2)\n",
    "bar1 = ax.bar(X_Month - barwidthnum, R_SST_Historical_12Month_All[:,0], color = 'blue',  alpha = 1,  width = barwidthnum, edgecolor = 'black', linewidth = 1.5, bottom = 0, align = 'edge') # label = 'FIO-EM v2'\n",
    "bar2 = ax.bar(X_Month, R_SST_Historical_12Month_Correct_All[:,0], color = 'red',  alpha = 1,  width = barwidthnum, edgecolor = 'black', linewidth = 1.5, bottom = 0, align = 'edge') # label = 'FIO-EM v2'\n",
    "for month in range(12):\n",
    "    Y_Month = np.round( R_SST_Historical_12Month_All[month,0], 3)\n",
    "    Y_Month_Correct = np.round( R_SST_Historical_12Month_Correct_All[month,0], 3)\n",
    "    Str_Y_Month = str(Y_Month)\n",
    "    Str_Y_Month_Correct = str(Y_Month_Correct)\n",
    "    ax.text(X_Month[month] - barwidthnum/2, Y_Month + 0.01, Str_Y_Month, horizontalalignment ='center', fontsize = 10 )\n",
    "    ax.text(X_Month[month] + barwidthnum/2, Y_Month_Correct + 0.01, Str_Y_Month_Correct, horizontalalignment ='center', fontsize = 10 )\n",
    "plt.axhline(y = R_SST_Historical_All[0] , c = 'blue', ls = '-', lw = 2)\n",
    "plt.axhline(y = R_SST_Historical_Correct_All[0] , c = 'red', ls = '-', lw = 2)\n",
    "Y_Month = np.round(R_SST_Historical_All[0], 3); Str_Y_Month = str(Y_Month)\n",
    "Y_Month_Correct = np.round(R_SST_Historical_Correct_All[0], 3); Str_Y_Month_Correct = str(Y_Month_Correct)\n",
    "ax.text(0.3, Y_Month + 0.01, Str_Y_Month, horizontalalignment='center', fontsize = 14)\n",
    "ax.text(0.3, Y_Month_Correct + 0.01, Str_Y_Month_Correct, horizontalalignment='center', fontsize = 14)\n",
    "ax.text(0, ylim_R_min + delta_R_bias*0.92, str_panels[1], fontsize=fontsizenum)   # color = 'black'\n",
    "ax.set(xlim = (0, 13), ylim = (ylim_R_min, ylim_R_max))\n",
    "ax.tick_params(axis='both', which='both', direction='in')\n",
    "ax.set_xticks(xticklabel_Month)\n",
    "ax.set_yticks(yticklabel_R)\n",
    "ax.set_xticklabels(xticklabels_Month, fontsize = fontsizenum)\n",
    "ax.set_yticklabels(yticklabels_R, fontsize = fontsizenum)\n",
    "ax.set_xlabel('Month', fontsize=fontsizenum)\n",
    "ax.set_ylabel('R',fontsize = fontsizenum)\n",
    "ax.grid(axis = 'y', linestyle = '--', lw = 1)  # color='grey', alpha=0.5\n",
    "## 保存图片\n",
    "fns = os.path.join(Path_SaveFigures, 'Bar_Historical-Correct_12Month.png')\n",
    "plt.savefig(fns, dpi = 600, bbox_inches = 'tight')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8E8A501F94FC449E997547F1FA9B89F9",
    "jupyter": {},
    "mdEditEnable": true,
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "上图是订正前后各个月的模式全球平均SST结果与观测的a) 相关系数，b)均方根误差。其中，条形图代表各月的相关系数或均方根误差，蓝色：订正前，红色：订正后；横线代表全时段的相关系数或均方根误差，蓝色：订正前，红色：订正后。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3EF7254EF2B645A887FE443187303A28",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### 5.4.2.3. 未来预估的时间序列\n",
    "基于历史订正结果，我们将模型应用到未来预估的订正上。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "81EF2214B96E46FCA311D39716A273EF",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**重构的SST：修正前/后，SSP126/245/585**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "id": "C784368B6D4542299C3A2822BF88A92E",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 144, 288, 432, 576, 720, 864, 1008]\n",
      "[18.0, 19.0, 20.0, 21.0, 22.0]\n",
      "['18.0', '19.0', '20.0', '21.0', '22.0']\n",
      "[18.0, 19.0, 20.0, 21.0, 22.0]\n",
      "['18.0', '19.0', '20.0', '21.0', '22.0']\n",
      "[18.0, 19.0, 20.0, 21.0, 22.0]\n",
      "['18.0', '19.0', '20.0', '21.0', '22.0']\n"
     ]
    }
   ],
   "source": [
    "### 预设\n",
    "fontsizenum = 16  \n",
    "markersizenum = 4\n",
    "Num_Year = 2100-2015+1\n",
    "Num_Sample_SSP = Num_Year*12\n",
    "X_Time = np.arange(0, Num_Sample_SSP )\n",
    "Time_SSP = np.array(Time_SSP)\n",
    "xtick_SSP_interval = 12*12\n",
    "## SSP126\n",
    "model_1 = LinearRegression(); model_2 = LinearRegression()\n",
    "X_Time_2D = X_Time.reshape((-1, 1))\n",
    "SST_SSP126_2D = SST_SSP126.reshape((-1, 1)); SST_SSP126_Correct_2D = SST_SSP126_Correct_1D.reshape((-1, 1))\n",
    "model_1.fit(X_Time_2D, SST_SSP126_2D); model_2.fit(X_Time_2D, SST_SSP126_Correct_2D)\n",
    "Regress_SST_SSP126 = model_1.predict(X_Time_2D); Regress_SST_SSP126_Correct = model_2.predict(X_Time_2D)\n",
    "xticklabel_SSP = list(range(0, Num_Sample_SSP, xtick_SSP_interval))\n",
    "print(xticklabel_SSP)\n",
    "xticklabels_SSP = Time_SSP[xticklabel_SSP[0::]].astype('str').tolist()\n",
    "ylim_ssp126_max = 22\n",
    "ylim_ssp126_min = 18\n",
    "delta_ylim_ssp126 = ylim_ssp126_max - ylim_ssp126_min\n",
    "yticklabel_SSP126 = np.linspace(ylim_ssp126_min, ylim_ssp126_max, num = 5).tolist()\n",
    "yticklabel_SSP126 = [round(i,1) for i in yticklabel_SSP126]\n",
    "print(yticklabel_SSP126)\n",
    "yticklabels_SSP126 = [str(i) for i in yticklabel_SSP126]\n",
    "print(yticklabels_SSP126)\n",
    "## SSP245\n",
    "model_1 = LinearRegression(); model_2 = LinearRegression()\n",
    "X_Time_2D = X_Time.reshape((-1, 1))\n",
    "SST_SSP245_2D = SST_SSP245.reshape((-1, 1)); SST_SSP245_Correct_2D = SST_SSP245_Correct_1D.reshape((-1, 1))\n",
    "model_1.fit(X_Time_2D, SST_SSP245_2D); model_2.fit(X_Time_2D, SST_SSP245_Correct_2D)\n",
    "Regress_SST_SSP245 = model_1.predict(X_Time_2D); Regress_SST_SSP245_Correct = model_2.predict(X_Time_2D)\n",
    "ylim_ssp245_max = 22\n",
    "ylim_ssp245_min = 18\n",
    "delta_ylim_ssp245 = ylim_ssp245_max - ylim_ssp245_min\n",
    "yticklabel_SSP245 = np.linspace(ylim_ssp245_min, ylim_ssp245_max, num = 5).tolist()\n",
    "yticklabel_SSP245 = [round(i,1) for i in yticklabel_SSP245]\n",
    "print(yticklabel_SSP245)\n",
    "yticklabels_SSP245 = [str(i) for i in yticklabel_SSP245]\n",
    "print(yticklabels_SSP245)\n",
    "## SSP585\n",
    "model_1 = LinearRegression(); model_2 = LinearRegression()\n",
    "X_Time_2D = X_Time.reshape((-1, 1))\n",
    "SST_SSP585_2D = SST_SSP585.reshape((-1, 1)); SST_SSP585_Correct_2D = SST_SSP585_Correct_1D.reshape((-1, 1))\n",
    "model_1.fit(X_Time_2D, SST_SSP585_2D); model_2.fit(X_Time_2D, SST_SSP585_Correct_2D)\n",
    "Regress_SST_SSP585 = model_1.predict(X_Time_2D); Regress_SST_SSP585_Correct = model_2.predict(X_Time_2D)\n",
    "ylim_ssp585_max = 22\n",
    "ylim_ssp585_min = 18\n",
    "delta_ylim_ssp585 = ylim_ssp585_max - ylim_ssp585_min\n",
    "yticklabel_SSP585 = np.linspace(ylim_ssp585_min, ylim_ssp585_max, num = 5).tolist()\n",
    "yticklabel_SSP585 = [round(i,1) for i in yticklabel_SSP585]\n",
    "print(yticklabel_SSP585)\n",
    "yticklabels_SSP585 = [str(i) for i in yticklabel_SSP585]\n",
    "print(yticklabels_SSP585)\n",
    "str_panels = ['a)SSP1-2.6 ', 'b)SSP2-4.5', 'c)SSP5-8.5']\n",
    "\n",
    "### 画图\n",
    "fig, ax = plt.subplots(3, 1, figsize = (16,9), dpi = 600)\n",
    "## SSP126\n",
    "ax = plt.subplot(3, 1, 1)\n",
    "plot1, = ax.plot(X_Time, SST_SSP126, 'b-', linewidth = 2, marker = '.', markersize = markersizenum, mfc = 'blue' )\n",
    "plot2, = ax.plot(X_Time, SST_SSP126_Correct_1D, 'r-', linewidth = 2, marker = '.', markersize = markersizenum, mfc = 'red' )\n",
    "# ax.plot(X_Time, Regress_SST_SSP126.squeeze(), 'b--', linewidth = 2)\n",
    "# ax.plot(X_Time, Regress_SST_SSP126_Correct.squeeze(), 'r--', linewidth = 2)\n",
    "ax.text(1, ylim_ssp126_min + delta_ylim_ssp126*0.9, str_panels[0], fontsize = fontsizenum)\n",
    "ax.set_xlim(0, Num_Sample_SSP)\n",
    "ax.set_ylim(ylim_ssp126_min, ylim_ssp126_max)  \n",
    "ax.set_xticks(xticklabel_SSP)\n",
    "ax.set_yticks(yticklabel_SSP126) \n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels(yticklabels_SSP126 , fontsize = fontsizenum)\n",
    "# ax.set_xlabel('Time', fontfamily='Times New Roman', fontsize=fontsizenum)\n",
    "ax.set_ylabel('SST(℃)', fontsize = fontsizenum)\n",
    "ax.grid(linestyle='-.')\n",
    "legend_font = { 'weight': 'normal', 'size': fontsizenum}\n",
    "plt.legend([plot1, plot2], [\"FIO-ESM v2\", \"EEMD-BPNN\"], loc = 'upper right', ncol = 1, frameon = False, prop = legend_font) # bbox_to_anchor = (0.3, 1.0),\n",
    "\n",
    "## SSP245\n",
    "ax = plt.subplot(3, 1, 2)\n",
    "ax.plot(X_Time, SST_SSP245, 'b-', linewidth = 2, marker = '.', markersize = markersizenum, mfc = 'blue' )\n",
    "ax.plot(X_Time, SST_SSP245_Correct_1D, 'r-', linewidth = 2, marker = '.', markersize = markersizenum, mfc = 'red' )\n",
    "ax.text(1, ylim_ssp245_min + delta_ylim_ssp245*0.9, str_panels[1], fontsize = fontsizenum)\n",
    "ax.set_xlim(0, Num_Sample_SSP)\n",
    "ax.set_ylim(ylim_ssp245_min, ylim_ssp245_max) \n",
    "ax.set_xticks(xticklabel_SSP)\n",
    "ax.set_yticks(yticklabel_SSP245)  \n",
    "ax.set_xticklabels([], fontsize = fontsizenum)\n",
    "ax.set_yticklabels(yticklabels_SSP245, fontsize = fontsizenum)\n",
    "ax.set_ylabel('SST(℃)', fontsize = fontsizenum)\n",
    "ax.grid(linestyle='-.')\n",
    "\n",
    "## SSP585\n",
    "ax = plt.subplot(3, 1, 3)\n",
    "ax.plot(X_Time, SST_SSP585, 'b-', linewidth = 2, marker = '.', markersize = markersizenum, mfc = 'blue' )\n",
    "ax.plot(X_Time, SST_SSP585_Correct_1D, 'r-', linewidth = 2, marker = '.', markersize = markersizenum, mfc = 'red' )\n",
    "ax.text(1, ylim_ssp585_min + delta_ylim_ssp585*0.9, str_panels[2], fontsize = fontsizenum)\n",
    "ax.set_xlim(0, Num_Sample_SSP)\n",
    "ax.set_ylim(ylim_ssp585_min, ylim_ssp585_max)  \n",
    "ax.set_xticks(xticklabel_SSP)\n",
    "ax.set_yticks(yticklabel_SSP585)  \n",
    "ax.set_xticklabels(xticklabels_SSP, fontsize = fontsizenum)\n",
    "ax.set_yticklabels(yticklabels_SSP585,  fontsize = fontsizenum)\n",
    "ax.set_xlabel('Time', fontsize=fontsizenum)\n",
    "ax.set_ylabel('SST(℃)', fontsize = fontsizenum)\n",
    "ax.grid(linestyle='-.')\n",
    "## 保存图片\n",
    "fns = os.path.join(Path_SaveFigures, 'SST_SSP_Correct.png')\n",
    "plt.savefig(fns, dpi = 600, bbox_inches = 'tight')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05D1DB5909FE432F83C9ABF659519D70",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "上图是订正前后三种未来预估情景的全球平均SST时间序列。a）低排放预估情景SSP1-2.6，b）中等排放预估情景SSP2-4.5, c）高排放预估情景SSP5-8.5。蓝色代表订正前，红色代表订正后。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "332D2CAB03924DF08465367095728A43",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**计算SST增长: 修正前/后，SSP126/245/585**\n",
    "基于订正前后的模式未来预估全球平均SST，我们计算一下本世纪末20年（2081-2100）相对于最近20年（1995-2014）的增长情况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "id": "2F19FDDC26034A288D4F34EDC839AE08",
    "jupyter": {
     "outputs_hidden": false
    },
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSP1-2.6:  订正前： 0.8341953582201391 订正后： 0.7326348564934939\n",
      "SSP2-4.5:  订正前： 1.5437369682519702 订正后： 1.3381051084507085\n",
      "SSP5-8.5:  订正前： 2.90624493579967 订正后： 2.5231582284102494\n"
     ]
    }
   ],
   "source": [
    "# ssp126\n",
    "SST_ERSST_End20 = SST_ERSST[-20*12::]  # 1995-2014\n",
    "SST_SSP126_End20 = Regress_SST_SSP126[-20*12::]  # 2081-2100\n",
    "SST_SSP126_Correct_End20 = Regress_SST_SSP126_Correct[-20*12::]  # 2081-2100\n",
    "Delta_SST_SSP126 = np.mean(SST_SSP126_End20) - np.mean(SST_ERSST_End20)\n",
    "Delta_SST_SSP126_Correct = np.mean(SST_SSP126_Correct_End20) - np.mean(SST_ERSST_End20)\n",
    "print('SSP1-2.6: ','订正前：', Delta_SST_SSP126,'订正后：', Delta_SST_SSP126_Correct)\n",
    "# ssp245\n",
    "SST_SSP245_End20 = Regress_SST_SSP245[-20*12::]  # 2081-2100\n",
    "SST_SSP245_Correct_End20 = Regress_SST_SSP245_Correct[-20*12::]  # 2081-2100\n",
    "Delta_SST_SSP245 = np.mean(SST_SSP245_End20) - np.mean(SST_ERSST_End20)\n",
    "Delta_SST_SSP245_Correct = np.mean(SST_SSP245_Correct_End20) - np.mean(SST_ERSST_End20)\n",
    "print('SSP2-4.5: ','订正前：', Delta_SST_SSP245,'订正后：', Delta_SST_SSP245_Correct)\n",
    "\n",
    "# ssp585\n",
    "SST_SSP585_End20 = Regress_SST_SSP585[-20*12::]  # 2081-2100\n",
    "SST_SSP585_Correct_End20 = Regress_SST_SSP585_Correct[-20*12::]  # 2081-2100\n",
    "Delta_SST_SSP585 = np.mean(SST_SSP585_End20) - np.mean(SST_ERSST_End20)\n",
    "Delta_SST_SSP585_Correct = np.mean(SST_SSP585_Correct_End20) - np.mean(SST_ERSST_End20)\n",
    "print('SSP5-8.5: ','订正前：', Delta_SST_SSP585,'订正后：', Delta_SST_SSP585_Correct)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBF3616782DC49D68ABD321F58762DAD",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "从上述3种未来预估情景订正前后的全球平均SST增长情况来看，订正后均比订正前有更小的增长，说明订正模型从历史偏差中学习到了模式相对观测偏高的规律，也就是我们的模式高估了气候变暖，所以订正模型对未来预估的结果都“往下拉了一下”。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7BB2D02420AC43A2926E2C88D8F61D64",
    "jupyter": {},
    "mdEditEnable": false,
    "notebookId": "62dd5acf3915ed2e06c67b20",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 小结\n",
    "这一章我们带领大家了解了用到的BPNN机器学习模型，然后介绍了建模的基本步骤，之后对模式模拟的历史全球平均SST的进行了建模订正，最后对未来预估结果做了订正。\n",
    "截至到目前，我们的项目教学内容就结束了，希望大家能认真研读，有所收获，为了让大家进一步巩固学习内容，我们还在下一章给大家设置了两个小作业，相信大家已经迫不及待去动手实践了，一起去完成吧。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
